{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hannah Command Line Interface - Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//: Permission denied.\n",
      ".\n",
      "├── augmentation\n",
      "├── config.yaml\n",
      "├── datasets\n",
      "├── experiment\n",
      "├── hannah_config.ipynb\n",
      "├── README.md\n",
      "├── scripts\n",
      "└── trained_models\n",
      "\n",
      "5 directories, 3 files\n"
     ]
    }
   ],
   "source": [
    "!tree -L 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main configuration ``config.yaml` composes the configurations from preset configuration files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//: Permission denied.\n",
      "defaults:\n",
      "    - base_config\n",
      "    - override dataset: cifar10          # Dataset configuration name\n",
      "    - override features: identity        # Feature extractor configuration name (use identity for vision datasets)\n",
      "    - override model: timm_resnet18      #timm_mobilenetv3_small_100      # Neural network name (for now timm_resnet50 or timm_efficientnet_lite1)\n",
      "    - override optimizer: sgd          # Optimizer config name\n",
      "    - override normalizer: null          # Feature normalizer (used for quantized neural networks)\n",
      "    - override module: image_classifier  # Lightning module config for the training loop (image classifier for image classification tasks)\n",
      "    - override augmentation: cifar_augment\n",
      "    - _self_\n",
      "\n",
      "\n",
      "monitor:\n",
      "  metric: val_accuracy\n",
      "  direction: maximize\n",
      "\n",
      "module:\n",
      "  batch_size: 2048\n",
      "\n",
      "trainer:\n",
      "  max_epochs: 50\n",
      "  precision: 16\n",
      "\n",
      "optimizer:\n",
      "  lr: 0.3\n"
     ]
    }
   ],
   "source": [
    "!cat config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configs are composed from the config group entries in the defaults list, and show highlevel components.\n",
    "The config group defaults are set from the corrsponding yaml files in the directory with the configuration tasks.  \n",
    "\n",
    "e.g. data augmentation is from the corresponding subdirectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//: Permission denied.\n",
      "augmentation\n",
      "└── cifar_augment.yaml\n",
      "\n",
      "0 directories, 1 file\n"
     ]
    }
   ],
   "source": [
    "!tree augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The composed configuration can be shown using the command `hannah-train --cfg job`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//: Permission denied.\n",
      "dataset:\n",
      "  data_folder: ${hydra:runtime.cwd}/datasets/\n",
      "  cls: hannah.datasets.vision.Cifar10Dataset\n",
      "  dataset: cifar10\n",
      "  val_percent: 0.1\n",
      "features:\n",
      "  _target_: torch.nn.Identity\n",
      "model:\n",
      "  _target_: hannah.models.timm.TimmModel\n",
      "  name: resnet18\n",
      "scheduler:\n",
      "  _target_: torch.optim.lr_scheduler.OneCycleLR\n",
      "  max_lr: ${optimizer.lr}\n",
      "  pct_start: 0.3\n",
      "  anneal_strategy: cos\n",
      "  cycle_momentum: true\n",
      "  base_momentum: 0.85\n",
      "  max_momentum: 0.95\n",
      "  div_factor: 25.0\n",
      "  final_div_factor: 10000.0\n",
      "  last_epoch: -1\n",
      "optimizer:\n",
      "  _target_: torch.optim.sgd.SGD\n",
      "  lr: 0.3\n",
      "  momentum: 0.9\n",
      "  dampening: 0\n",
      "  weight_decay: 0.0005\n",
      "  nesterov: false\n",
      "module:\n",
      "  _target_: hannah.modules.vision.ImageClassifierModule\n",
      "  num_workers: 0\n",
      "  batch_size: 2048\n",
      "  shuffle_all_dataloaders: false\n",
      "trainer:\n",
      "  _target_: pytorch_lightning.trainer.Trainer\n",
      "  accelerator: auto\n",
      "  devices: 1\n",
      "  limit_train_batches: 1.0\n",
      "  limit_val_batches: 1.0\n",
      "  limit_test_batches: 1.0\n",
      "  max_epochs: 50\n",
      "  default_root_dir: .\n",
      "  fast_dev_run: false\n",
      "  overfit_batches: 0.0\n",
      "  benchmark: false\n",
      "  deterministic: warn\n",
      "  gradient_clip_val: 0\n",
      "  accumulate_grad_batches: 1\n",
      "  plugins: null\n",
      "  strategy: auto\n",
      "  reload_dataloaders_every_n_epochs: 0\n",
      "  precision: 16\n",
      "  enable_model_summary: false\n",
      "checkpoint:\n",
      "  _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
      "  dirpath: checkpoints\n",
      "  save_top_k: 1\n",
      "  verbose: true\n",
      "  monitor: val_error\n",
      "  mode: min\n",
      "  save_last: true\n",
      "augmentation:\n",
      "  batch_augment:\n",
      "    pipeline: null\n",
      "    transforms:\n",
      "      RandomHorizontalFlip:\n",
      "        p: 0.5\n",
      "      RandomAffine:\n",
      "        degrees:\n",
      "        - -15\n",
      "        - 15\n",
      "        translate:\n",
      "        - 0.1\n",
      "        - 0.1\n",
      "        scale:\n",
      "        - 0.9\n",
      "        - 1.1\n",
      "        shear:\n",
      "        - -5\n",
      "        - 5\n",
      "        p: 0.5\n",
      "      RandomCrop:\n",
      "        size:\n",
      "        - 32\n",
      "        - 32\n",
      "        padding: 4\n",
      "      RandomErasing:\n",
      "        p: 0.5\n",
      "experiment_id: test\n",
      "output_dir: trained_models\n",
      "auto_lr: false\n",
      "resume: false\n",
      "fx_mac_summary: false\n",
      "skip_test: false\n",
      "skip_val: false\n",
      "seed:\n",
      "- 1234\n",
      "validate_output: false\n",
      "monitor:\n",
      "  metric: val_accuracy\n",
      "  direction: maximize\n"
     ]
    }
   ],
   "source": [
    "!hannah-train --cfg job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "Experiment configurations are stored in a special \n",
    "\n",
    "Thy can define sweeps over the parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//: Permission denied.\n",
      "sweep_lr.yaml  sweep_models.yaml\n"
     ]
    }
   ],
   "source": [
    "!ls experiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//: Permission denied.\n",
      "# @package _global_\n",
      "experiment_id: sweep_models\n",
      "hydra:\n",
      "  mode: MULTIRUN\n",
      "  sweep:\n",
      "    subdir: ${model.name}\n",
      "  sweeper:\n",
      "    params:\n",
      "      model: timm_resnet18,timm_mobilenetv3_small_075,timm_mobilenetv3_small_100,kakao_resnet8 \n"
     ]
    }
   ],
   "source": [
    "!cat experiment/sweep_models.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment configs can need to be used with hannah-train and the `+experiment` switch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//: Permission denied.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-29 14:28:40,402][HYDRA] Launching 4 jobs locally\n",
      "[2024-02-29 14:28:40,402][HYDRA] \t#0 : model=timm_resnet18 +experiment=sweep_models\n",
      "\n",
      " **                                            **\n",
      "/**                                           /**\n",
      "/**       ******   *******  *******   ******  /**\n",
      "/******  //////** //**///**//**///** //////** /******\n",
      "/**///**  *******  /**  /** /**  /**  ******* /**///**\n",
      "/**  /** **////**  /**  /** /**  /** **////** /**  /**\n",
      "/**  /**//******** ***  /** ***  /**//********/**  /**\n",
      "//   //  //////// ///   // ///   //  //////// //   //\n",
      "\n",
      "[\u001b[36m2024-02-29 14:28:43,069\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] - Environment info:\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:43,171\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   Number of GPUs: 2\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:43,172\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   CUDA version: 12.1\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:43,174\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   CUDNN version: 8907\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:43,175\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   Kernel: 4.18.0-513.11.1.el8_9.x86_64\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:43,175\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:43,175\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   PyTorch: 2.1.2+cu121\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:43,175\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   Pytorch Lightning: 2.1.3\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:43,175\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   Numpy: 1.23.5\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:43,175\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   Hannah version info:\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:43,176\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -     Cannot find a Git repository.  You probably downloaded an archive\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:43,177\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train +experiment=sweep_models\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:43,177\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   \u001b[0m\n",
      "INFO: Seed set to 1234\n",
      "[\u001b[36m2024-02-29 14:28:43,178\u001b[0m][\u001b[34mlightning.fabric.utilities.seed\u001b[0m][\u001b[32mINFO\u001b[0m] - Seed set to 1234\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:43,179\u001b[0m][\u001b[34mroot\u001b[0m][\u001b[32mINFO\u001b[0m] - Configuration: \u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:43,182\u001b[0m][\u001b[34mroot\u001b[0m][\u001b[32mINFO\u001b[0m] - dataset:\n",
      "  data_folder: ${hydra:runtime.cwd}/datasets/\n",
      "  cls: hannah.datasets.vision.Cifar10Dataset\n",
      "  dataset: cifar10\n",
      "  val_percent: 0.1\n",
      "features:\n",
      "  _target_: torch.nn.Identity\n",
      "model:\n",
      "  _target_: hannah.models.timm.TimmModel\n",
      "  name: resnet18\n",
      "scheduler:\n",
      "  _target_: torch.optim.lr_scheduler.OneCycleLR\n",
      "  max_lr: ${optimizer.lr}\n",
      "  pct_start: 0.3\n",
      "  anneal_strategy: cos\n",
      "  cycle_momentum: true\n",
      "  base_momentum: 0.85\n",
      "  max_momentum: 0.95\n",
      "  div_factor: 25.0\n",
      "  final_div_factor: 10000.0\n",
      "  last_epoch: -1\n",
      "optimizer:\n",
      "  _target_: torch.optim.sgd.SGD\n",
      "  lr: 0.3\n",
      "  momentum: 0.9\n",
      "  dampening: 0\n",
      "  weight_decay: 0.0005\n",
      "  nesterov: false\n",
      "module:\n",
      "  _target_: hannah.modules.vision.ImageClassifierModule\n",
      "  num_workers: 0\n",
      "  batch_size: 2048\n",
      "  shuffle_all_dataloaders: false\n",
      "trainer:\n",
      "  _target_: pytorch_lightning.trainer.Trainer\n",
      "  accelerator: auto\n",
      "  devices: 1\n",
      "  limit_train_batches: 1.0\n",
      "  limit_val_batches: 1.0\n",
      "  limit_test_batches: 1.0\n",
      "  max_epochs: 50\n",
      "  default_root_dir: .\n",
      "  fast_dev_run: false\n",
      "  overfit_batches: 0.0\n",
      "  benchmark: false\n",
      "  deterministic: warn\n",
      "  gradient_clip_val: 0\n",
      "  accumulate_grad_batches: 1\n",
      "  plugins: null\n",
      "  strategy: auto\n",
      "  reload_dataloaders_every_n_epochs: 0\n",
      "  precision: 16\n",
      "  enable_model_summary: false\n",
      "checkpoint:\n",
      "  _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
      "  dirpath: checkpoints\n",
      "  save_top_k: 1\n",
      "  verbose: true\n",
      "  monitor: val_error\n",
      "  mode: min\n",
      "  save_last: true\n",
      "augmentation:\n",
      "  batch_augment:\n",
      "    pipeline: null\n",
      "    transforms:\n",
      "      RandomHorizontalFlip:\n",
      "        p: 0.5\n",
      "      RandomAffine:\n",
      "        degrees:\n",
      "        - -15\n",
      "        - 15\n",
      "        translate:\n",
      "        - 0.1\n",
      "        - 0.1\n",
      "        scale:\n",
      "        - 0.9\n",
      "        - 1.1\n",
      "        shear:\n",
      "        - -5\n",
      "        - 5\n",
      "        p: 0.5\n",
      "      RandomCrop:\n",
      "        size:\n",
      "        - 32\n",
      "        - 32\n",
      "        padding: 4\n",
      "      RandomErasing:\n",
      "        p: 0.5\n",
      "experiment_id: sweep_models\n",
      "output_dir: trained_models\n",
      "auto_lr: false\n",
      "resume: false\n",
      "fx_mac_summary: false\n",
      "skip_test: false\n",
      "skip_val: false\n",
      "seed:\n",
      "- 1234\n",
      "validate_output: false\n",
      "monitor:\n",
      "  metric: val_accuracy\n",
      "  direction: maximize\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:43,182\u001b[0m][\u001b[34mroot\u001b[0m][\u001b[32mINFO\u001b[0m] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:44,121\u001b[0m][\u001b[34mhannah.callbacks.optimization\u001b[0m][\u001b[32mINFO\u001b[0m] - Monitoring the following values for optimization\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:44,121\u001b[0m][\u001b[34mhannah.callbacks.optimization\u001b[0m][\u001b[32mINFO\u001b[0m] -   - val_accuracy direction: maximize(-1)\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:44,190\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:558: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:44,214\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Using 16bit Automatic Mixed Precision (AMP)\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:44,221\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - GPU available: True (cuda), used: True\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:44,221\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - TPU available: False, using: 0 TPU cores\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:44,221\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - IPU available: False, using: 0 IPUs\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:44,221\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - HPU available: False, using: 0 HPUs\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:44,221\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:44,221\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:44,221\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:44,221\u001b[0m][\u001b[34mroot\u001b[0m][\u001b[32mINFO\u001b[0m] - Starting training\u001b[0m\n",
      "Files already downloaded and verified\n",
      "[\u001b[36m2024-02-29 14:28:45,740\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/hannah/hannah/modules/vision/base.py:66: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None\n",
      "  warnings.warn(\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:45,740\u001b[0m][\u001b[34mhannah.modules.vision.base\u001b[0m][\u001b[32mINFO\u001b[0m] - Dataset lengths:\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:45,740\u001b[0m][\u001b[34mhannah.modules.vision.base\u001b[0m][\u001b[32mINFO\u001b[0m] -   Train Set (Labeled): 45000\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:45,740\u001b[0m][\u001b[34mhannah.modules.vision.base\u001b[0m][\u001b[32mINFO\u001b[0m] -   Train Set (Unlabled): 0\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:45,740\u001b[0m][\u001b[34mhannah.modules.vision.base\u001b[0m][\u001b[32mINFO\u001b[0m] -   Dev Set: 5000\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:45,740\u001b[0m][\u001b[34mhannah.modules.vision.base\u001b[0m][\u001b[32mINFO\u001b[0m] -   Test Set: 10000\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:45,741\u001b[0m][\u001b[34mhannah.modules.vision.base\u001b[0m][\u001b[32mINFO\u001b[0m] - Setting up model resnet18\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:45,882\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:803: UserWarning: Overwriting focalnet_tiny_srf in registry with hannah.models._vendor.focalnet.focalnet_tiny_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:45,882\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:824: UserWarning: Overwriting focalnet_small_srf in registry with hannah.models._vendor.focalnet.focalnet_small_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:45,882\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:843: UserWarning: Overwriting focalnet_base_srf in registry with hannah.models._vendor.focalnet.focalnet_base_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:45,882\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:862: UserWarning: Overwriting focalnet_tiny_lrf in registry with hannah.models._vendor.focalnet.focalnet_tiny_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:45,882\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:885: UserWarning: Overwriting focalnet_small_lrf in registry with hannah.models._vendor.focalnet.focalnet_small_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:45,882\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:906: UserWarning: Overwriting focalnet_base_lrf in registry with hannah.models._vendor.focalnet.focalnet_base_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:45,882\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1010: UserWarning: Overwriting focalnet_large_fl3 in registry with hannah.models._vendor.focalnet.focalnet_large_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:45,883\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1031: UserWarning: Overwriting focalnet_large_fl4 in registry with hannah.models._vendor.focalnet.focalnet_large_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:45,883\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1052: UserWarning: Overwriting focalnet_xlarge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:45,883\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1073: UserWarning: Overwriting focalnet_xlarge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:45,883\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1094: UserWarning: Overwriting focalnet_huge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:45,883\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1115: UserWarning: Overwriting focalnet_huge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:46,010\u001b[0m][\u001b[34mhannah.models.timm\u001b[0m][\u001b[32mINFO\u001b[0m] - Using default logger for automatic stem creation\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:46,010\u001b[0m][\u001b[34mhannah.models.timm\u001b[0m][\u001b[32mINFO\u001b[0m] - Small input size detected trying to adopt small input size\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:46,035\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:46,676\u001b[0m][\u001b[34mhannah.modules.vision.base\u001b[0m][\u001b[32mINFO\u001b[0m] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:46,683\u001b[0m][\u001b[34mhannah.modules.vision.base\u001b[0m][\u001b[32mINFO\u001b[0m] - Running dummy forward to initialize lazy modules\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:47,183\u001b[0m][\u001b[34mpytorch_lightning.accelerators.cuda\u001b[0m][\u001b[32mINFO\u001b[0m] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:47,185\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading `train_dataloader` to estimate number of stepping batches.\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:47,185\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=191` in the `DataLoader` to improve performance.\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:47,210\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:47,954\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/hannah/hannah/models/timm.py:313: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  decoded = torch.tensor([])\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:47,954\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/hannah/hannah/models/timm.py:317: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  logits = torch.tensor([])\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:47,975\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/hannah/hannah/models/timm.py:321: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  projection = torch.tensor([])\n",
      "\u001b[0m\n",
      "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s][\u001b[36m2024-02-29 14:28:48,289\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=191` in the `DataLoader` to improve performance.\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:49,024\u001b[0m][\u001b[34mhannah.callbacks.summaries\u001b[0m][\u001b[32mINFO\u001b[0m] - \n",
      "+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+\n",
      "|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |\n",
      "|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|\n",
      "|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |\n",
      "|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |\n",
      "|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |\n",
      "| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |\n",
      "| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |\n",
      "| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |\n",
      "| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |\n",
      "| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |\n",
      "| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |\n",
      "| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |\n",
      "| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |\n",
      "| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |\n",
      "| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |\n",
      "| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |\n",
      "| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |\n",
      "| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |\n",
      "| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |\n",
      "| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |\n",
      "| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |\n",
      "| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |\n",
      "| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |\n",
      "| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |\n",
      "| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |\n",
      "| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |\n",
      "+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:49,026\u001b[0m][\u001b[34mhannah.callbacks.summaries\u001b[0m][\u001b[32mINFO\u001b[0m] - Total MACs: 555,422,720\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:49,026\u001b[0m][\u001b[34mhannah.callbacks.summaries\u001b[0m][\u001b[32mINFO\u001b[0m] - Total Weights: 11,164,352\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:49,026\u001b[0m][\u001b[34mhannah.callbacks.summaries\u001b[0m][\u001b[32mINFO\u001b[0m] - Total Activations: 2,813,972\u001b[0m\n",
      "[\u001b[36m2024-02-29 14:28:49,026\u001b[0m][\u001b[34mhannah.callbacks.summaries\u001b[0m][\u001b[32mINFO\u001b[0m] - Estimated Activations: 131,072\u001b[0m\n",
      "Epoch 0: 100%|████| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=2.120]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00,  8.05it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  6.46it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 21/21 [01:12<00:00,  0.29it/s, v_num=logs, train_loss=2.120, va\u001b[A[\u001b[36m2024-02-29 14:30:02,014\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 0, global step 21: 'val_error' reached 0.78833 (best 0.78833), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=0-step=21.ckpt' as top 1\u001b[0m\n",
      "Epoch 1: 100%|█| 21/21 [01:11<00:00,  0.30it/s, v_num=logs, train_loss=1.990, va\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 12.76it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  8.11it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=1.990, va\u001b[A[\u001b[36m2024-02-29 14:31:14,413\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 1, global step 42: 'val_error' reached 0.72827 (best 0.72827), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=1-step=42.ckpt' as top 1\u001b[0m\n",
      "Epoch 2: 100%|█| 21/21 [00:55<00:00,  0.38it/s, v_num=logs, train_loss=1.910, va\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 11.19it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  7.19it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 21/21 [00:56<00:00,  0.37it/s, v_num=logs, train_loss=1.910, va\u001b[A[\u001b[36m2024-02-29 14:32:11,758\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 2, global step 63: 'val_error' reached 0.68970 (best 0.68970), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=2-step=63.ckpt' as top 1\u001b[0m\n",
      "Epoch 3: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=1.860, va\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 13.58it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00, 10.33it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=1.860, va\u001b[A[\u001b[36m2024-02-29 14:33:24,309\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 3, global step 84: 'val_error' reached 0.67529 (best 0.67529), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=3-step=84.ckpt' as top 1\u001b[0m\n",
      "Epoch 4: 100%|█| 21/21 [01:11<00:00,  0.30it/s, v_num=logs, train_loss=1.790, va\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00,  8.73it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  7.07it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=1.790, va\u001b[A[\u001b[36m2024-02-29 14:34:36,942\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 4, global step 105: 'val_error' reached 0.66064 (best 0.66064), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=4-step=105.ckpt' as top 1\u001b[0m\n",
      "Epoch 5: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=1.680, va\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00,  8.34it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  7.18it/s]\u001b[A\n",
      "Epoch 5: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=1.680, va\u001b[A[\u001b[36m2024-02-29 14:35:49,702\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 5, global step 126: 'val_error' reached 0.64038 (best 0.64038), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=5-step=126.ckpt' as top 1\u001b[0m\n",
      "Epoch 6: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=1.650, va\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00,  9.34it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  6.98it/s]\u001b[A\n",
      "Epoch 6: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=1.650, va\u001b[A[\u001b[36m2024-02-29 14:37:02,446\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 6, global step 147: 'val_error' reached 0.59717 (best 0.59717), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=6-step=147.ckpt' as top 1\u001b[0m\n",
      "Epoch 7: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=1.550, va\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 16.63it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00, 10.00it/s]\u001b[A\n",
      "Epoch 7: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=1.550, va\u001b[A[\u001b[36m2024-02-29 14:38:15,141\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 7, global step 168: 'val_error' reached 0.57471 (best 0.57471), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=7-step=168.ckpt' as top 1\u001b[0m\n",
      "Epoch 8: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=1.470, va\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 16.49it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  8.37it/s]\u001b[A\n",
      "Epoch 8: 100%|█| 21/21 [01:10<00:00,  0.30it/s, v_num=logs, train_loss=1.470, va\u001b[A[\u001b[36m2024-02-29 14:39:26,371\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 8, global step 189: 'val_error' reached 0.50024 (best 0.50024), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=8-step=189.ckpt' as top 1\u001b[0m\n",
      "Epoch 9: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=1.430, va\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 15.19it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  9.59it/s]\u001b[A\n",
      "Epoch 9: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=1.430, va\u001b[A[\u001b[36m2024-02-29 14:40:36,538\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 9, global step 210: 'val_error' was not in top 1\u001b[0m\n",
      "Epoch 10: 100%|█| 21/21 [00:59<00:00,  0.35it/s, v_num=logs, train_loss=1.370, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 13.57it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  9.04it/s]\u001b[A\n",
      "Epoch 10: 100%|█| 21/21 [00:59<00:00,  0.35it/s, v_num=logs, train_loss=1.370, v\u001b[A[\u001b[36m2024-02-29 14:41:37,419\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 10, global step 231: 'val_error' was not in top 1\u001b[0m\n",
      "Epoch 11: 100%|█| 21/21 [00:33<00:00,  0.63it/s, v_num=logs, train_loss=1.440, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00,  8.55it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  6.20it/s]\u001b[A\n",
      "Epoch 11: 100%|█| 21/21 [00:33<00:00,  0.62it/s, v_num=logs, train_loss=1.440, v\u001b[A[\u001b[36m2024-02-29 14:42:12,004\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 11, global step 252: 'val_error' was not in top 1\u001b[0m\n",
      "Epoch 12: 100%|█| 21/21 [01:10<00:00,  0.30it/s, v_num=logs, train_loss=1.250, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 13.25it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  9.61it/s]\u001b[A\n",
      "Epoch 12: 100%|█| 21/21 [01:10<00:00,  0.30it/s, v_num=logs, train_loss=1.250, v\u001b[A[\u001b[36m2024-02-29 14:43:23,399\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 12, global step 273: 'val_error' reached 0.46338 (best 0.46338), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=12-step=273.ckpt' as top 1\u001b[0m\n",
      "Epoch 13: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=1.130, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 12.20it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  7.95it/s]\u001b[A\n",
      "Epoch 13: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=1.130, v\u001b[A[\u001b[36m2024-02-29 14:44:36,378\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 13, global step 294: 'val_error' was not in top 1\u001b[0m\n",
      "Epoch 14: 100%|█| 21/21 [01:11<00:00,  0.30it/s, v_num=logs, train_loss=1.060, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00,  7.43it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  6.21it/s]\u001b[A\n",
      "Epoch 14: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=1.060, v\u001b[A[\u001b[36m2024-02-29 14:45:48,805\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 14, global step 315: 'val_error' reached 0.44116 (best 0.44116), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=14-step=315.ckpt' as top 1\u001b[0m\n",
      "Epoch 15: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=1.030, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00,  7.56it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  6.29it/s]\u001b[A\n",
      "Epoch 15: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=1.030, v\u001b[A[\u001b[36m2024-02-29 14:47:01,594\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 15, global step 336: 'val_error' reached 0.35498 (best 0.35498), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=15-step=336.ckpt' as top 1\u001b[0m\n",
      "Epoch 16: 100%|█| 21/21 [01:11<00:00,  0.30it/s, v_num=logs, train_loss=0.986, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 13.26it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  8.30it/s]\u001b[A\n",
      "Epoch 16: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.986, v\u001b[A[\u001b[36m2024-02-29 14:48:14,128\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 16, global step 357: 'val_error' was not in top 1\u001b[0m\n",
      "Epoch 17: 100%|█| 21/21 [01:11<00:00,  0.30it/s, v_num=logs, train_loss=0.885, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00,  8.74it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  6.31it/s]\u001b[A\n",
      "Epoch 17: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.885, v\u001b[A[\u001b[36m2024-02-29 14:49:26,496\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 17, global step 378: 'val_error' was not in top 1\u001b[0m\n",
      "Epoch 18: 100%|█| 21/21 [01:11<00:00,  0.30it/s, v_num=logs, train_loss=0.905, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 11.86it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  7.87it/s]\u001b[A\n",
      "Epoch 18: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.905, v\u001b[A[\u001b[36m2024-02-29 14:50:38,771\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 18, global step 399: 'val_error' was not in top 1\u001b[0m\n",
      "Epoch 19: 100%|█| 21/21 [01:04<00:00,  0.32it/s, v_num=logs, train_loss=0.816, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 20.69it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00, 11.86it/s]\u001b[A\n",
      "Epoch 19: 100%|█| 21/21 [01:05<00:00,  0.32it/s, v_num=logs, train_loss=0.816, v\u001b[A[\u001b[36m2024-02-29 14:51:44,728\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 19, global step 420: 'val_error' reached 0.34741 (best 0.34741), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=19-step=420.ckpt' as top 1\u001b[0m\n",
      "Epoch 20: 100%|█| 21/21 [01:03<00:00,  0.33it/s, v_num=logs, train_loss=0.790, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 10.70it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  8.03it/s]\u001b[A\n",
      "Epoch 20: 100%|█| 21/21 [01:04<00:00,  0.33it/s, v_num=logs, train_loss=0.790, v\u001b[A[\u001b[36m2024-02-29 14:52:49,858\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 20, global step 441: 'val_error' reached 0.32007 (best 0.32007), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=20-step=441.ckpt' as top 1\u001b[0m\n",
      "Epoch 21: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.752, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00,  7.10it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  6.12it/s]\u001b[A\n",
      "Epoch 21: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.752, v\u001b[A[\u001b[36m2024-02-29 14:54:02,849\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 21, global step 462: 'val_error' reached 0.31006 (best 0.31006), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=21-step=462.ckpt' as top 1\u001b[0m\n",
      "Epoch 22: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.731, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00,  8.75it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  7.71it/s]\u001b[A\n",
      "Epoch 22: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.731, v\u001b[A[\u001b[36m2024-02-29 14:55:15,547\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 22, global step 483: 'val_error' reached 0.24170 (best 0.24170), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=22-step=483.ckpt' as top 1\u001b[0m\n",
      "Epoch 23: 100%|█| 21/21 [01:10<00:00,  0.30it/s, v_num=logs, train_loss=0.751, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 10.50it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  7.34it/s]\u001b[A\n",
      "Epoch 23: 100%|█| 21/21 [01:11<00:00,  0.30it/s, v_num=logs, train_loss=0.751, v\u001b[A[\u001b[36m2024-02-29 14:56:27,728\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 23, global step 504: 'val_error' was not in top 1\u001b[0m\n",
      "Epoch 24: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.673, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00,  8.82it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  6.37it/s]\u001b[A\n",
      "Epoch 24: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.673, v\u001b[A[\u001b[36m2024-02-29 14:57:40,354\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 24, global step 525: 'val_error' reached 0.21069 (best 0.21069), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=24-step=525.ckpt' as top 1\u001b[0m\n",
      "Epoch 25: 100%|█| 21/21 [01:10<00:00,  0.30it/s, v_num=logs, train_loss=0.659, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 12.94it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  8.12it/s]\u001b[A\n",
      "Epoch 25: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.659, v\u001b[A[\u001b[36m2024-02-29 14:58:52,657\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 25, global step 546: 'val_error' was not in top 1\u001b[0m\n",
      "Epoch 26: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=0.613, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00,  8.15it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  7.20it/s]\u001b[A\n",
      "Epoch 26: 100%|█| 21/21 [01:10<00:00,  0.30it/s, v_num=logs, train_loss=0.613, v\u001b[A[\u001b[36m2024-02-29 15:00:03,818\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 26, global step 567: 'val_error' was not in top 1\u001b[0m\n",
      "Epoch 27: 100%|█| 21/21 [01:05<00:00,  0.32it/s, v_num=logs, train_loss=0.571, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 30.22it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00, 12.62it/s]\u001b[A\n",
      "Epoch 27: 100%|█| 21/21 [01:05<00:00,  0.32it/s, v_num=logs, train_loss=0.571, v\u001b[A[\u001b[36m2024-02-29 15:01:10,595\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 27, global step 588: 'val_error' was not in top 1\u001b[0m\n",
      "Epoch 28: 100%|█| 21/21 [00:29<00:00,  0.70it/s, v_num=logs, train_loss=0.558, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 29.91it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00, 12.57it/s]\u001b[A\n",
      "Epoch 28: 100%|█| 21/21 [00:30<00:00,  0.70it/s, v_num=logs, train_loss=0.558, v\u001b[A[\u001b[36m2024-02-29 15:01:41,863\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 28, global step 609: 'val_error' was not in top 1\u001b[0m\n",
      "Epoch 29: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=0.564, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 13.15it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  7.93it/s]\u001b[A\n",
      "Epoch 29: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=0.564, v\u001b[A[\u001b[36m2024-02-29 15:02:52,447\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 29, global step 630: 'val_error' was not in top 1\u001b[0m\n",
      "Epoch 30: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.517, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 10.18it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  6.21it/s]\u001b[A\n",
      "Epoch 30: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.517, v\u001b[A[\u001b[36m2024-02-29 15:04:05,319\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 30, global step 651: 'val_error' was not in top 1\u001b[0m\n",
      "Epoch 31: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.515, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 10.14it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  8.38it/s]\u001b[A\n",
      "Epoch 31: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.515, v\u001b[A[\u001b[36m2024-02-29 15:05:17,777\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 31, global step 672: 'val_error' reached 0.19019 (best 0.19019), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=31-step=672.ckpt' as top 1\u001b[0m\n",
      "Epoch 32: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.463, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 13.41it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  8.13it/s]\u001b[A\n",
      "Epoch 32: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.463, v\u001b[A[\u001b[36m2024-02-29 15:06:30,540\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 32, global step 693: 'val_error' was not in top 1\u001b[0m\n",
      "Epoch 33: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.471, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00,  8.78it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  8.52it/s]\u001b[A\n",
      "Epoch 33: 100%|█| 21/21 [01:12<00:00,  0.29it/s, v_num=logs, train_loss=0.471, v\u001b[A[\u001b[36m2024-02-29 15:07:43,579\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 33, global step 714: 'val_error' reached 0.18042 (best 0.18042), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=33-step=714.ckpt' as top 1\u001b[0m\n",
      "Epoch 34: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.474, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00,  6.87it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  6.48it/s]\u001b[A\n",
      "Epoch 34: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.474, v\u001b[A[\u001b[36m2024-02-29 15:08:56,453\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 34, global step 735: 'val_error' reached 0.14722 (best 0.14722), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=34-step=735.ckpt' as top 1\u001b[0m\n",
      "Epoch 35: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.406, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00,  8.03it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  6.49it/s]\u001b[A\n",
      "Epoch 35: 100%|█| 21/21 [01:12<00:00,  0.29it/s, v_num=logs, train_loss=0.406, v\u001b[A[\u001b[36m2024-02-29 15:10:09,732\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 35, global step 756: 'val_error' was not in top 1\u001b[0m\n",
      "Epoch 36: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=0.418, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 14.53it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  9.32it/s]\u001b[A\n",
      "Epoch 36: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=0.418, v\u001b[A[\u001b[36m2024-02-29 15:11:20,184\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 36, global step 777: 'val_error' was not in top 1\u001b[0m\n",
      "Epoch 37: 100%|█| 21/21 [00:56<00:00,  0.37it/s, v_num=logs, train_loss=0.412, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00,  8.91it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  6.92it/s]\u001b[A\n",
      "Epoch 37: 100%|█| 21/21 [00:56<00:00,  0.37it/s, v_num=logs, train_loss=0.412, v\u001b[A[\u001b[36m2024-02-29 15:12:17,890\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 37, global step 798: 'val_error' reached 0.13843 (best 0.13843), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=37-step=798.ckpt' as top 1\u001b[0m\n",
      "Epoch 38: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.378, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00,  8.73it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  7.11it/s]\u001b[A\n",
      "Epoch 38: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.378, v\u001b[A[\u001b[36m2024-02-29 15:13:30,709\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 38, global step 819: 'val_error' was not in top 1\u001b[0m\n",
      "Epoch 39: 100%|█| 21/21 [01:10<00:00,  0.30it/s, v_num=logs, train_loss=0.313, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 14.29it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  9.62it/s]\u001b[A\n",
      "Epoch 39: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.313, v\u001b[A[\u001b[36m2024-02-29 15:14:42,916\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 39, global step 840: 'val_error' reached 0.13599 (best 0.13599), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=39-step=840.ckpt' as top 1\u001b[0m\n",
      "Epoch 40: 100%|█| 21/21 [01:10<00:00,  0.30it/s, v_num=logs, train_loss=0.339, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00,  6.68it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  6.02it/s]\u001b[A\n",
      "Epoch 40: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.339, v\u001b[A[\u001b[36m2024-02-29 15:15:55,437\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 40, global step 861: 'val_error' was not in top 1\u001b[0m\n",
      "Epoch 41: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.335, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00,  6.75it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  7.18it/s]\u001b[A\n",
      "Epoch 41: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.335, v\u001b[A[\u001b[36m2024-02-29 15:17:08,346\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 41, global step 882: 'val_error' reached 0.11792 (best 0.11792), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=41-step=882.ckpt' as top 1\u001b[0m\n",
      "Epoch 42: 100%|█| 21/21 [01:11<00:00,  0.30it/s, v_num=logs, train_loss=0.318, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00,  8.77it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  6.00it/s]\u001b[A\n",
      "Epoch 42: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.318, v\u001b[A[\u001b[36m2024-02-29 15:18:20,891\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 42, global step 903: 'val_error' reached 0.11548 (best 0.11548), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=42-step=903.ckpt' as top 1\u001b[0m\n",
      "Epoch 43: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=0.323, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 18.59it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  8.09it/s]\u001b[A\n",
      "Epoch 43: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=0.323, v\u001b[A[\u001b[36m2024-02-29 15:19:31,508\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 43, global step 924: 'val_error' reached 0.10962 (best 0.10962), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=43-step=924.ckpt' as top 1\u001b[0m\n",
      "Epoch 44: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=0.270, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00,  9.54it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  6.73it/s]\u001b[A\n",
      "Epoch 44: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=0.270, v\u001b[A[\u001b[36m2024-02-29 15:20:41,395\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 44, global step 945: 'val_error' reached 0.10938 (best 0.10938), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=44-step=945.ckpt' as top 1\u001b[0m\n",
      "Epoch 45: 100%|█| 21/21 [00:48<00:00,  0.44it/s, v_num=logs, train_loss=0.280, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 30.55it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00, 14.44it/s]\u001b[A\n",
      "Epoch 45: 100%|█| 21/21 [00:48<00:00,  0.43it/s, v_num=logs, train_loss=0.280, v\u001b[A[\u001b[36m2024-02-29 15:21:30,772\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 45, global step 966: 'val_error' reached 0.10889 (best 0.10889), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=45-step=966.ckpt' as top 1\u001b[0m\n",
      "Epoch 46: 100%|█| 21/21 [00:44<00:00,  0.47it/s, v_num=logs, train_loss=0.255, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 10.29it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  8.10it/s]\u001b[A\n",
      "Epoch 46: 100%|█| 21/21 [00:44<00:00,  0.47it/s, v_num=logs, train_loss=0.255, v\u001b[A[\u001b[36m2024-02-29 15:22:16,516\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 46, global step 987: 'val_error' reached 0.09985 (best 0.09985), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=46-step=987.ckpt' as top 1\u001b[0m\n",
      "Epoch 47: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.263, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 15.28it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00, 10.45it/s]\u001b[A\n",
      "Epoch 47: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.263, v\u001b[A[\u001b[36m2024-02-29 15:23:29,124\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 47, global step 1008: 'val_error' was not in top 1\u001b[0m\n",
      "Epoch 48: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.259, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00,  8.88it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  7.16it/s]\u001b[A\n",
      "Epoch 48: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.259, v\u001b[A[\u001b[36m2024-02-29 15:24:41,687\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 48, global step 1029: 'val_error' reached 0.09961 (best 0.09961), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=48-step=1029.ckpt' as top 1\u001b[0m\n",
      "Epoch 49: 100%|█| 21/21 [01:11<00:00,  0.30it/s, v_num=logs, train_loss=0.246, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00,  7.30it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  6.15it/s]\u001b[A\n",
      "Epoch 49: 100%|█| 21/21 [01:11<00:00,  0.29it/s, v_num=logs, train_loss=0.246, v\u001b[A[\u001b[36m2024-02-29 15:25:54,345\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 49, global step 1050: 'val_error' reached 0.09937 (best 0.09937), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=49-step=1050.ckpt' as top 1\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:54,505\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - `Trainer.fit` stopped: `max_epochs=50` reached.\u001b[0m\n",
      "Epoch 49: 100%|█| 21/21 [01:12<00:00,  0.29it/s, v_num=logs, train_loss=0.246, v\n",
      "INFO: Seed set to 1234\n",
      "[\u001b[36m2024-02-29 15:25:54,567\u001b[0m][\u001b[34mlightning.fabric.utilities.seed\u001b[0m][\u001b[32mINFO\u001b[0m] - Seed set to 1234\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:54,567\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:54,569\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=49-step=1050.ckpt\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:55,186\u001b[0m][\u001b[34mpytorch_lightning.accelerators.cuda\u001b[0m][\u001b[32mINFO\u001b[0m] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:55,569\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=49-step=1050.ckpt\u001b[0m\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  5.82it/s]\n",
      "INFO: Seed set to 1234\n",
      "[\u001b[36m2024-02-29 15:25:56,044\u001b[0m][\u001b[34mlightning.fabric.utilities.seed\u001b[0m][\u001b[32mINFO\u001b[0m] - Seed set to 1234\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:56,044\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:56,046\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=49-step=1050.ckpt\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:56,627\u001b[0m][\u001b[34mpytorch_lightning.accelerators.cuda\u001b[0m][\u001b[32mINFO\u001b[0m] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:57,266\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/resnet18/checkpoints/epoch=49-step=1050.ckpt\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:57,268\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=191` in the `DataLoader` to improve performance.\n",
      "\u001b[0m\n",
      "Testing DataLoader 0: 100%|███████████████████████| 4/4 [00:00<00:00,  5.09it/s][\u001b[36m2024-02-29 15:25:58,183\u001b[0m][\u001b[34mhannah.callbacks.summaries\u001b[0m][\u001b[32mINFO\u001b[0m] - \n",
      "+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+\n",
      "|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |\n",
      "|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|\n",
      "|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |\n",
      "|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |\n",
      "|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |\n",
      "| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |\n",
      "| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |\n",
      "| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |\n",
      "| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |\n",
      "| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |\n",
      "| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |\n",
      "| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |\n",
      "| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |\n",
      "| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |\n",
      "| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |\n",
      "| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |\n",
      "| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |\n",
      "| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |\n",
      "| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |\n",
      "| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |\n",
      "| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |\n",
      "| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |\n",
      "| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |\n",
      "| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |\n",
      "| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |\n",
      "| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |\n",
      "| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |\n",
      "| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |\n",
      "| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |\n",
      "| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |\n",
      "+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:58,184\u001b[0m][\u001b[34mhannah.callbacks.summaries\u001b[0m][\u001b[32mINFO\u001b[0m] - Total MACs: 555,422,720\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:58,185\u001b[0m][\u001b[34mhannah.callbacks.summaries\u001b[0m][\u001b[32mINFO\u001b[0m] - Total Weights: 11,164,352\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:58,185\u001b[0m][\u001b[34mhannah.callbacks.summaries\u001b[0m][\u001b[32mINFO\u001b[0m] - Total Activations: 2,813,972\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:58,185\u001b[0m][\u001b[34mhannah.callbacks.summaries\u001b[0m][\u001b[32mINFO\u001b[0m] - Estimated Activations: 131,072\u001b[0m\n",
      "Testing DataLoader 0: 100%|███████████████████████| 4/4 [00:00<00:00,  4.83it/s]\n",
      "[\u001b[36m2024-02-29 15:25:58,185\u001b[0m][\u001b[34mhannah.datasets.base\u001b[0m][\u001b[33mWARNING\u001b[0m] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:58,186\u001b[0m][\u001b[34mhannah.datasets.base\u001b[0m][\u001b[33mWARNING\u001b[0m] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:58,516\u001b[0m][\u001b[34mhannah.datasets.base\u001b[0m][\u001b[33mWARNING\u001b[0m] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:58,668\u001b[0m][\u001b[34mhannah.datasets.base\u001b[0m][\u001b[33mWARNING\u001b[0m] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:58,885\u001b[0m][\u001b[34mhannah.train\u001b[0m][\u001b[32mINFO\u001b[0m] - Averaged Result Metrics:\n",
      "| Metric               |     Mean |   Std |   Count |\n",
      "|----------------------|----------|-------|---------|\n",
      "| test_classifier_loss | 0.308465 |     0 |       1 |\n",
      "| test_accuracy        | 0.899048 |     0 |       1 |\n",
      "| test_error           | 0.100952 |     0 |       1 |\n",
      "| test_f1              | 0.899273 |     0 |       1 |\n",
      "| test_precision       | 0.899287 |     0 |       1 |\n",
      "| test_recall          | 0.899381 |     0 |       1 |\n",
      "| test_loss            | 0.308465 |     0 |       1 |\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:58,896\u001b[0m][\u001b[34mhannah.train\u001b[0m][\u001b[32mINFO\u001b[0m] - Averaged Result Metrics:\n",
      "| Metric              |      Mean |   Std |   Count |\n",
      "|---------------------|-----------|-------|---------|\n",
      "| val_classifier_loss | 0.316974  |     0 |       1 |\n",
      "| val_accuracy        | 0.900635  |     0 |       1 |\n",
      "| val_error           | 0.0993652 |     0 |       1 |\n",
      "| val_f1              | 0.900035  |     0 |       1 |\n",
      "| val_precision       | 0.900657  |     0 |       1 |\n",
      "| val_recall          | 0.899864  |     0 |       1 |\n",
      "| val_loss            | 0.316974  |     0 |       1 |\u001b[0m\n",
      "[2024-02-29 15:25:58,900][HYDRA] \t#1 : model=timm_mobilenetv3_small_075 +experiment=sweep_models\n",
      "\n",
      " **                                            **\n",
      "/**                                           /**\n",
      "/**       ******   *******  *******   ******  /**\n",
      "/******  //////** //**///**//**///** //////** /******\n",
      "/**///**  *******  /**  /** /**  /**  ******* /**///**\n",
      "/**  /** **////**  /**  /** /**  /** **////** /**  /**\n",
      "/**  /**//******** ***  /** ***  /**//********/**  /**\n",
      "//   //  //////// ///   // ///   //  //////// //   //\n",
      "\n",
      "[\u001b[36m2024-02-29 15:25:59,011\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] - Environment info:\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:59,011\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   Number of GPUs: 2\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:59,011\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   CUDA version: 12.1\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:59,011\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   CUDNN version: 8907\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:59,012\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   Kernel: 4.18.0-513.11.1.el8_9.x86_64\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:59,012\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:59,012\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   PyTorch: 2.1.2+cu121\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:59,012\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   Pytorch Lightning: 2.1.3\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:59,012\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   Numpy: 1.23.5\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:59,012\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   Hannah version info:\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:59,012\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -     Cannot find a Git repository.  You probably downloaded an archive\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:59,012\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train +experiment=sweep_models\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:59,012\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   \u001b[0m\n",
      "INFO: Seed set to 1234\n",
      "[\u001b[36m2024-02-29 15:25:59,012\u001b[0m][\u001b[34mlightning.fabric.utilities.seed\u001b[0m][\u001b[32mINFO\u001b[0m] - Seed set to 1234\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:59,013\u001b[0m][\u001b[34mroot\u001b[0m][\u001b[32mINFO\u001b[0m] - Configuration: \u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:59,015\u001b[0m][\u001b[34mroot\u001b[0m][\u001b[32mINFO\u001b[0m] - dataset:\n",
      "  data_folder: ${hydra:runtime.cwd}/datasets/\n",
      "  cls: hannah.datasets.vision.Cifar10Dataset\n",
      "  dataset: cifar10\n",
      "  val_percent: 0.1\n",
      "features:\n",
      "  _target_: torch.nn.Identity\n",
      "model:\n",
      "  _target_: hannah.models.timm.TimmModel\n",
      "  name: mobilenetv3_small_075\n",
      "  drop_rate: 0.3\n",
      "  drop_path_rate: 0.2\n",
      "scheduler:\n",
      "  _target_: torch.optim.lr_scheduler.OneCycleLR\n",
      "  max_lr: ${optimizer.lr}\n",
      "  pct_start: 0.3\n",
      "  anneal_strategy: cos\n",
      "  cycle_momentum: true\n",
      "  base_momentum: 0.85\n",
      "  max_momentum: 0.95\n",
      "  div_factor: 25.0\n",
      "  final_div_factor: 10000.0\n",
      "  last_epoch: -1\n",
      "optimizer:\n",
      "  _target_: torch.optim.sgd.SGD\n",
      "  lr: 0.3\n",
      "  momentum: 0.9\n",
      "  dampening: 0\n",
      "  weight_decay: 0.0005\n",
      "  nesterov: false\n",
      "module:\n",
      "  _target_: hannah.modules.vision.ImageClassifierModule\n",
      "  num_workers: 0\n",
      "  batch_size: 2048\n",
      "  shuffle_all_dataloaders: false\n",
      "trainer:\n",
      "  _target_: pytorch_lightning.trainer.Trainer\n",
      "  accelerator: auto\n",
      "  devices: 1\n",
      "  limit_train_batches: 1.0\n",
      "  limit_val_batches: 1.0\n",
      "  limit_test_batches: 1.0\n",
      "  max_epochs: 50\n",
      "  default_root_dir: .\n",
      "  fast_dev_run: false\n",
      "  overfit_batches: 0.0\n",
      "  benchmark: false\n",
      "  deterministic: warn\n",
      "  gradient_clip_val: 0\n",
      "  accumulate_grad_batches: 1\n",
      "  plugins: null\n",
      "  strategy: auto\n",
      "  reload_dataloaders_every_n_epochs: 0\n",
      "  precision: 16\n",
      "  enable_model_summary: false\n",
      "checkpoint:\n",
      "  _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
      "  dirpath: checkpoints\n",
      "  save_top_k: 1\n",
      "  verbose: true\n",
      "  monitor: val_error\n",
      "  mode: min\n",
      "  save_last: true\n",
      "augmentation:\n",
      "  batch_augment:\n",
      "    pipeline: null\n",
      "    transforms:\n",
      "      RandomHorizontalFlip:\n",
      "        p: 0.5\n",
      "      RandomAffine:\n",
      "        degrees:\n",
      "        - -15\n",
      "        - 15\n",
      "        translate:\n",
      "        - 0.1\n",
      "        - 0.1\n",
      "        scale:\n",
      "        - 0.9\n",
      "        - 1.1\n",
      "        shear:\n",
      "        - -5\n",
      "        - 5\n",
      "        p: 0.5\n",
      "      RandomCrop:\n",
      "        size:\n",
      "        - 32\n",
      "        - 32\n",
      "        padding: 4\n",
      "      RandomErasing:\n",
      "        p: 0.5\n",
      "experiment_id: sweep_models\n",
      "output_dir: trained_models\n",
      "auto_lr: false\n",
      "resume: false\n",
      "fx_mac_summary: false\n",
      "skip_test: false\n",
      "skip_val: false\n",
      "seed:\n",
      "- 1234\n",
      "validate_output: false\n",
      "monitor:\n",
      "  metric: val_accuracy\n",
      "  direction: maximize\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:59,015\u001b[0m][\u001b[34mroot\u001b[0m][\u001b[32mINFO\u001b[0m] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:59,022\u001b[0m][\u001b[34mhannah.callbacks.optimization\u001b[0m][\u001b[32mINFO\u001b[0m] - Monitoring the following values for optimization\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:59,022\u001b[0m][\u001b[34mhannah.callbacks.optimization\u001b[0m][\u001b[32mINFO\u001b[0m] -   - val_accuracy direction: maximize(-1)\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:59,025\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:558: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:59,026\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Using 16bit Automatic Mixed Precision (AMP)\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:59,033\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - GPU available: True (cuda), used: True\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:59,033\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - TPU available: False, using: 0 TPU cores\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:59,033\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - IPU available: False, using: 0 IPUs\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:59,033\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - HPU available: False, using: 0 HPUs\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:59,033\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:59,033\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:59,033\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:25:59,033\u001b[0m][\u001b[34mroot\u001b[0m][\u001b[32mINFO\u001b[0m] - Starting training\u001b[0m\n",
      "Files already downloaded and verified\n",
      "[\u001b[36m2024-02-29 15:26:00,233\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/hannah/hannah/modules/vision/base.py:66: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None\n",
      "  warnings.warn(\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:26:00,233\u001b[0m][\u001b[34mhannah.modules.vision.base\u001b[0m][\u001b[32mINFO\u001b[0m] - Dataset lengths:\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:26:00,234\u001b[0m][\u001b[34mhannah.modules.vision.base\u001b[0m][\u001b[32mINFO\u001b[0m] -   Train Set (Labeled): 45000\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:26:00,234\u001b[0m][\u001b[34mhannah.modules.vision.base\u001b[0m][\u001b[32mINFO\u001b[0m] -   Train Set (Unlabled): 0\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:26:00,234\u001b[0m][\u001b[34mhannah.modules.vision.base\u001b[0m][\u001b[32mINFO\u001b[0m] -   Dev Set: 5000\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:26:00,234\u001b[0m][\u001b[34mhannah.modules.vision.base\u001b[0m][\u001b[32mINFO\u001b[0m] -   Test Set: 10000\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:26:00,234\u001b[0m][\u001b[34mhannah.modules.vision.base\u001b[0m][\u001b[32mINFO\u001b[0m] - Setting up model mobilenetv3_small_075\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:26:00,254\u001b[0m][\u001b[34mhannah.models.timm\u001b[0m][\u001b[32mINFO\u001b[0m] - Using default logger for automatic stem creation\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:26:00,254\u001b[0m][\u001b[34mhannah.models.timm\u001b[0m][\u001b[32mINFO\u001b[0m] - Small input size detected trying to adopt small input size\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:26:00,266\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:26:00,267\u001b[0m][\u001b[34mhannah.modules.vision.base\u001b[0m][\u001b[32mINFO\u001b[0m] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:26:00,272\u001b[0m][\u001b[34mhannah.modules.vision.base\u001b[0m][\u001b[32mINFO\u001b[0m] - Running dummy forward to initialize lazy modules\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:26:00,711\u001b[0m][\u001b[34mpytorch_lightning.accelerators.cuda\u001b[0m][\u001b[32mINFO\u001b[0m] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:26:00,713\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading `train_dataloader` to estimate number of stepping batches.\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:26:00,713\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=191` in the `DataLoader` to improve performance.\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:26:00,729\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:26:01,040\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/hannah/hannah/models/timm.py:313: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  decoded = torch.tensor([])\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:26:01,041\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/hannah/hannah/models/timm.py:317: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  logits = torch.tensor([])\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:26:01,042\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/hannah/hannah/models/timm.py:321: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  projection = torch.tensor([])\n",
      "\u001b[0m\n",
      "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s][\u001b[36m2024-02-29 15:26:01,574\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=191` in the `DataLoader` to improve performance.\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:26:02,380\u001b[0m][\u001b[34mhannah.callbacks.summaries\u001b[0m][\u001b[32mINFO\u001b[0m] - \n",
      "+-----+-----------------------------------+------------------------+---------------------------------------------------+-----------------+--------------+-----------------+--------------+------------------+---------+\n",
      "|     | Name                              | Type                   | Attrs                                             | IFM             |   IFM volume | OFM             |   OFM volume |   Weights volume |    MACs |\n",
      "|-----+-----------------------------------+------------------------+---------------------------------------------------+-----------------+--------------+-----------------+--------------+------------------+---------|\n",
      "|   0 | encoder.conv_stem                 | Conv2d                 | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 3, 32, 32)  |         3072 | (1, 16, 32, 32) |        16384 |              432 |  442368 |\n",
      "|   1 | encoder.bn1.drop                  | Identity               |                                                   | (1, 16, 32, 32) |        16384 | (1, 16, 32, 32) |        16384 |                0 |       0 |\n",
      "|   2 | encoder.bn1.act                   | Hardswish              |                                                   | (1, 16, 32, 32) |        16384 | (1, 16, 32, 32) |        16384 |                0 |       0 |\n",
      "|   3 | encoder.bn1                       | BatchNormAct2d         |                                                   | (1, 16, 32, 32) |        16384 | (1, 16, 32, 32) |        16384 |                0 |       0 |\n",
      "|   4 | encoder.blocks.0.0.conv_dw        | Conv2d                 | k=(3, 3), s=(2, 2), g=(16), dsc=(True), d=(1, 1)  | (1, 16, 32, 32) |        16384 | (1, 16, 16, 16) |         4096 |              144 |   36864 |\n",
      "|   5 | encoder.blocks.0.0.bn1.drop       | Identity               |                                                   | (1, 16, 16, 16) |         4096 | (1, 16, 16, 16) |         4096 |                0 |       0 |\n",
      "|   6 | encoder.blocks.0.0.bn1.act        | ReLU                   |                                                   | (1, 16, 16, 16) |         4096 | (1, 16, 16, 16) |         4096 |                0 |       0 |\n",
      "|   7 | encoder.blocks.0.0.bn1            | BatchNormAct2d         |                                                   | (1, 16, 16, 16) |         4096 | (1, 16, 16, 16) |         4096 |                0 |       0 |\n",
      "|   8 | encoder.blocks.0.0.se.conv_reduce | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 16, 1, 1)   |           16 | (1, 8, 1, 1)    |            8 |              128 |     128 |\n",
      "|   9 | encoder.blocks.0.0.se.act1        | ReLU                   |                                                   | (1, 8, 1, 1)    |            8 | (1, 8, 1, 1)    |            8 |                0 |       0 |\n",
      "|  10 | encoder.blocks.0.0.se.conv_expand | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 8, 1, 1)    |            8 | (1, 16, 1, 1)   |           16 |              128 |     128 |\n",
      "|  11 | encoder.blocks.0.0.se.gate        | Hardsigmoid            |                                                   | (1, 16, 1, 1)   |           16 | (1, 16, 1, 1)   |           16 |                0 |       0 |\n",
      "|  12 | encoder.blocks.0.0.se             | SqueezeExcite          |                                                   | (1, 16, 16, 16) |         4096 | (1, 16, 16, 16) |         4096 |                0 |       0 |\n",
      "|  13 | encoder.blocks.0.0.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 16, 16, 16) |         4096 | (1, 16, 16, 16) |         4096 |              256 |   65536 |\n",
      "|  14 | encoder.blocks.0.0.bn2.drop       | Identity               |                                                   | (1, 16, 16, 16) |         4096 | (1, 16, 16, 16) |         4096 |                0 |       0 |\n",
      "|  15 | encoder.blocks.0.0.bn2.act        | Identity               |                                                   | (1, 16, 16, 16) |         4096 | (1, 16, 16, 16) |         4096 |                0 |       0 |\n",
      "|  16 | encoder.blocks.0.0.bn2            | BatchNormAct2d         |                                                   | (1, 16, 16, 16) |         4096 | (1, 16, 16, 16) |         4096 |                0 |       0 |\n",
      "|  17 | encoder.blocks.0.0                | DepthwiseSeparableConv |                                                   | (1, 16, 32, 32) |        16384 | (1, 16, 16, 16) |         4096 |                0 |       0 |\n",
      "|  18 | encoder.blocks.0                  | Sequential             |                                                   | (1, 16, 32, 32) |        16384 | (1, 16, 16, 16) |         4096 |                0 |       0 |\n",
      "|  19 | encoder.blocks.1.0.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 16, 16, 16) |         4096 | (1, 72, 16, 16) |        18432 |             1152 |  294912 |\n",
      "|  20 | encoder.blocks.1.0.bn1.drop       | Identity               |                                                   | (1, 72, 16, 16) |        18432 | (1, 72, 16, 16) |        18432 |                0 |       0 |\n",
      "|  21 | encoder.blocks.1.0.bn1.act        | ReLU                   |                                                   | (1, 72, 16, 16) |        18432 | (1, 72, 16, 16) |        18432 |                0 |       0 |\n",
      "|  22 | encoder.blocks.1.0.bn1            | BatchNormAct2d         |                                                   | (1, 72, 16, 16) |        18432 | (1, 72, 16, 16) |        18432 |                0 |       0 |\n",
      "|  23 | encoder.blocks.1.0.conv_dw        | Conv2d                 | k=(3, 3), s=(2, 2), g=(72), dsc=(True), d=(1, 1)  | (1, 72, 16, 16) |        18432 | (1, 72, 8, 8)   |         4608 |              648 |   41472 |\n",
      "|  24 | encoder.blocks.1.0.bn2.drop       | Identity               |                                                   | (1, 72, 8, 8)   |         4608 | (1, 72, 8, 8)   |         4608 |                0 |       0 |\n",
      "|  25 | encoder.blocks.1.0.bn2.act        | ReLU                   |                                                   | (1, 72, 8, 8)   |         4608 | (1, 72, 8, 8)   |         4608 |                0 |       0 |\n",
      "|  26 | encoder.blocks.1.0.bn2            | BatchNormAct2d         |                                                   | (1, 72, 8, 8)   |         4608 | (1, 72, 8, 8)   |         4608 |                0 |       0 |\n",
      "|  27 | encoder.blocks.1.0.se             | Identity               |                                                   | (1, 72, 8, 8)   |         4608 | (1, 72, 8, 8)   |         4608 |                0 |       0 |\n",
      "|  28 | encoder.blocks.1.0.conv_pwl       | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 72, 8, 8)   |         4608 | (1, 24, 8, 8)   |         1536 |             1728 |  110592 |\n",
      "|  29 | encoder.blocks.1.0.bn3.drop       | Identity               |                                                   | (1, 24, 8, 8)   |         1536 | (1, 24, 8, 8)   |         1536 |                0 |       0 |\n",
      "|  30 | encoder.blocks.1.0.bn3.act        | Identity               |                                                   | (1, 24, 8, 8)   |         1536 | (1, 24, 8, 8)   |         1536 |                0 |       0 |\n",
      "|  31 | encoder.blocks.1.0.bn3            | BatchNormAct2d         |                                                   | (1, 24, 8, 8)   |         1536 | (1, 24, 8, 8)   |         1536 |                0 |       0 |\n",
      "|  32 | encoder.blocks.1.0                | InvertedResidual       |                                                   | (1, 16, 16, 16) |         4096 | (1, 24, 8, 8)   |         1536 |                0 |       0 |\n",
      "|  33 | encoder.blocks.1.1.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 24, 8, 8)   |         1536 | (1, 88, 8, 8)   |         5632 |             2112 |  135168 |\n",
      "|  34 | encoder.blocks.1.1.bn1.drop       | Identity               |                                                   | (1, 88, 8, 8)   |         5632 | (1, 88, 8, 8)   |         5632 |                0 |       0 |\n",
      "|  35 | encoder.blocks.1.1.bn1.act        | ReLU                   |                                                   | (1, 88, 8, 8)   |         5632 | (1, 88, 8, 8)   |         5632 |                0 |       0 |\n",
      "|  36 | encoder.blocks.1.1.bn1            | BatchNormAct2d         |                                                   | (1, 88, 8, 8)   |         5632 | (1, 88, 8, 8)   |         5632 |                0 |       0 |\n",
      "|  37 | encoder.blocks.1.1.conv_dw        | Conv2d                 | k=(3, 3), s=(1, 1), g=(88), dsc=(True), d=(1, 1)  | (1, 88, 8, 8)   |         5632 | (1, 88, 8, 8)   |         5632 |              792 |   50688 |\n",
      "|  38 | encoder.blocks.1.1.bn2.drop       | Identity               |                                                   | (1, 88, 8, 8)   |         5632 | (1, 88, 8, 8)   |         5632 |                0 |       0 |\n",
      "|  39 | encoder.blocks.1.1.bn2.act        | ReLU                   |                                                   | (1, 88, 8, 8)   |         5632 | (1, 88, 8, 8)   |         5632 |                0 |       0 |\n",
      "|  40 | encoder.blocks.1.1.bn2            | BatchNormAct2d         |                                                   | (1, 88, 8, 8)   |         5632 | (1, 88, 8, 8)   |         5632 |                0 |       0 |\n",
      "|  41 | encoder.blocks.1.1.se             | Identity               |                                                   | (1, 88, 8, 8)   |         5632 | (1, 88, 8, 8)   |         5632 |                0 |       0 |\n",
      "|  42 | encoder.blocks.1.1.conv_pwl       | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 88, 8, 8)   |         5632 | (1, 24, 8, 8)   |         1536 |             2112 |  135168 |\n",
      "|  43 | encoder.blocks.1.1.bn3.drop       | Identity               |                                                   | (1, 24, 8, 8)   |         1536 | (1, 24, 8, 8)   |         1536 |                0 |       0 |\n",
      "|  44 | encoder.blocks.1.1.bn3.act        | Identity               |                                                   | (1, 24, 8, 8)   |         1536 | (1, 24, 8, 8)   |         1536 |                0 |       0 |\n",
      "|  45 | encoder.blocks.1.1.bn3            | BatchNormAct2d         |                                                   | (1, 24, 8, 8)   |         1536 | (1, 24, 8, 8)   |         1536 |                0 |       0 |\n",
      "|  46 | encoder.blocks.1.1.drop_path      | DropPath               |                                                   | (1, 24, 8, 8)   |         1536 | (1, 24, 8, 8)   |         1536 |                0 |       0 |\n",
      "|  47 | encoder.blocks.1.1                | InvertedResidual       |                                                   | (1, 24, 8, 8)   |         1536 | (1, 24, 8, 8)   |         1536 |                0 |       0 |\n",
      "|  48 | encoder.blocks.1                  | Sequential             |                                                   | (1, 16, 16, 16) |         4096 | (1, 24, 8, 8)   |         1536 |                0 |       0 |\n",
      "|  49 | encoder.blocks.2.0.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 24, 8, 8)   |         1536 | (1, 96, 8, 8)   |         6144 |             2304 |  147456 |\n",
      "|  50 | encoder.blocks.2.0.bn1.drop       | Identity               |                                                   | (1, 96, 8, 8)   |         6144 | (1, 96, 8, 8)   |         6144 |                0 |       0 |\n",
      "|  51 | encoder.blocks.2.0.bn1.act        | Hardswish              |                                                   | (1, 96, 8, 8)   |         6144 | (1, 96, 8, 8)   |         6144 |                0 |       0 |\n",
      "|  52 | encoder.blocks.2.0.bn1            | BatchNormAct2d         |                                                   | (1, 96, 8, 8)   |         6144 | (1, 96, 8, 8)   |         6144 |                0 |       0 |\n",
      "|  53 | encoder.blocks.2.0.conv_dw        | Conv2d                 | k=(5, 5), s=(2, 2), g=(96), dsc=(True), d=(1, 1)  | (1, 96, 8, 8)   |         6144 | (1, 96, 4, 4)   |         1536 |             2400 |   38400 |\n",
      "|  54 | encoder.blocks.2.0.bn2.drop       | Identity               |                                                   | (1, 96, 4, 4)   |         1536 | (1, 96, 4, 4)   |         1536 |                0 |       0 |\n",
      "|  55 | encoder.blocks.2.0.bn2.act        | Hardswish              |                                                   | (1, 96, 4, 4)   |         1536 | (1, 96, 4, 4)   |         1536 |                0 |       0 |\n",
      "|  56 | encoder.blocks.2.0.bn2            | BatchNormAct2d         |                                                   | (1, 96, 4, 4)   |         1536 | (1, 96, 4, 4)   |         1536 |                0 |       0 |\n",
      "|  57 | encoder.blocks.2.0.se.conv_reduce | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 96, 1, 1)   |           96 | (1, 24, 1, 1)   |           24 |             2304 |    2304 |\n",
      "|  58 | encoder.blocks.2.0.se.act1        | ReLU                   |                                                   | (1, 24, 1, 1)   |           24 | (1, 24, 1, 1)   |           24 |                0 |       0 |\n",
      "|  59 | encoder.blocks.2.0.se.conv_expand | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 24, 1, 1)   |           24 | (1, 96, 1, 1)   |           96 |             2304 |    2304 |\n",
      "|  60 | encoder.blocks.2.0.se.gate        | Hardsigmoid            |                                                   | (1, 96, 1, 1)   |           96 | (1, 96, 1, 1)   |           96 |                0 |       0 |\n",
      "|  61 | encoder.blocks.2.0.se             | SqueezeExcite          |                                                   | (1, 96, 4, 4)   |         1536 | (1, 96, 4, 4)   |         1536 |                0 |       0 |\n",
      "|  62 | encoder.blocks.2.0.conv_pwl       | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 96, 4, 4)   |         1536 | (1, 32, 4, 4)   |          512 |             3072 |   49152 |\n",
      "|  63 | encoder.blocks.2.0.bn3.drop       | Identity               |                                                   | (1, 32, 4, 4)   |          512 | (1, 32, 4, 4)   |          512 |                0 |       0 |\n",
      "|  64 | encoder.blocks.2.0.bn3.act        | Identity               |                                                   | (1, 32, 4, 4)   |          512 | (1, 32, 4, 4)   |          512 |                0 |       0 |\n",
      "|  65 | encoder.blocks.2.0.bn3            | BatchNormAct2d         |                                                   | (1, 32, 4, 4)   |          512 | (1, 32, 4, 4)   |          512 |                0 |       0 |\n",
      "|  66 | encoder.blocks.2.0                | InvertedResidual       |                                                   | (1, 24, 8, 8)   |         1536 | (1, 32, 4, 4)   |          512 |                0 |       0 |\n",
      "|  67 | encoder.blocks.2.1.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 32, 4, 4)   |          512 | (1, 192, 4, 4)  |         3072 |             6144 |   98304 |\n",
      "|  68 | encoder.blocks.2.1.bn1.drop       | Identity               |                                                   | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |                0 |       0 |\n",
      "|  69 | encoder.blocks.2.1.bn1.act        | Hardswish              |                                                   | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |                0 |       0 |\n",
      "|  70 | encoder.blocks.2.1.bn1            | BatchNormAct2d         |                                                   | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |                0 |       0 |\n",
      "|  71 | encoder.blocks.2.1.conv_dw        | Conv2d                 | k=(5, 5), s=(1, 1), g=(192), dsc=(True), d=(1, 1) | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |             4800 |   76800 |\n",
      "|  72 | encoder.blocks.2.1.bn2.drop       | Identity               |                                                   | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |                0 |       0 |\n",
      "|  73 | encoder.blocks.2.1.bn2.act        | Hardswish              |                                                   | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |                0 |       0 |\n",
      "|  74 | encoder.blocks.2.1.bn2            | BatchNormAct2d         |                                                   | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |                0 |       0 |\n",
      "|  75 | encoder.blocks.2.1.se.conv_reduce | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 192, 1, 1)  |          192 | (1, 48, 1, 1)   |           48 |             9216 |    9216 |\n",
      "|  76 | encoder.blocks.2.1.se.act1        | ReLU                   |                                                   | (1, 48, 1, 1)   |           48 | (1, 48, 1, 1)   |           48 |                0 |       0 |\n",
      "|  77 | encoder.blocks.2.1.se.conv_expand | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 48, 1, 1)   |           48 | (1, 192, 1, 1)  |          192 |             9216 |    9216 |\n",
      "|  78 | encoder.blocks.2.1.se.gate        | Hardsigmoid            |                                                   | (1, 192, 1, 1)  |          192 | (1, 192, 1, 1)  |          192 |                0 |       0 |\n",
      "|  79 | encoder.blocks.2.1.se             | SqueezeExcite          |                                                   | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |                0 |       0 |\n",
      "|  80 | encoder.blocks.2.1.conv_pwl       | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 192, 4, 4)  |         3072 | (1, 32, 4, 4)   |          512 |             6144 |   98304 |\n",
      "|  81 | encoder.blocks.2.1.bn3.drop       | Identity               |                                                   | (1, 32, 4, 4)   |          512 | (1, 32, 4, 4)   |          512 |                0 |       0 |\n",
      "|  82 | encoder.blocks.2.1.bn3.act        | Identity               |                                                   | (1, 32, 4, 4)   |          512 | (1, 32, 4, 4)   |          512 |                0 |       0 |\n",
      "|  83 | encoder.blocks.2.1.bn3            | BatchNormAct2d         |                                                   | (1, 32, 4, 4)   |          512 | (1, 32, 4, 4)   |          512 |                0 |       0 |\n",
      "|  84 | encoder.blocks.2.1.drop_path      | DropPath               |                                                   | (1, 32, 4, 4)   |          512 | (1, 32, 4, 4)   |          512 |                0 |       0 |\n",
      "|  85 | encoder.blocks.2.1                | InvertedResidual       |                                                   | (1, 32, 4, 4)   |          512 | (1, 32, 4, 4)   |          512 |                0 |       0 |\n",
      "|  86 | encoder.blocks.2.2.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 32, 4, 4)   |          512 | (1, 192, 4, 4)  |         3072 |             6144 |   98304 |\n",
      "|  87 | encoder.blocks.2.2.bn1.drop       | Identity               |                                                   | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |                0 |       0 |\n",
      "|  88 | encoder.blocks.2.2.bn1.act        | Hardswish              |                                                   | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |                0 |       0 |\n",
      "|  89 | encoder.blocks.2.2.bn1            | BatchNormAct2d         |                                                   | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |                0 |       0 |\n",
      "|  90 | encoder.blocks.2.2.conv_dw        | Conv2d                 | k=(5, 5), s=(1, 1), g=(192), dsc=(True), d=(1, 1) | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |             4800 |   76800 |\n",
      "|  91 | encoder.blocks.2.2.bn2.drop       | Identity               |                                                   | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |                0 |       0 |\n",
      "|  92 | encoder.blocks.2.2.bn2.act        | Hardswish              |                                                   | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |                0 |       0 |\n",
      "|  93 | encoder.blocks.2.2.bn2            | BatchNormAct2d         |                                                   | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |                0 |       0 |\n",
      "|  94 | encoder.blocks.2.2.se.conv_reduce | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 192, 1, 1)  |          192 | (1, 48, 1, 1)   |           48 |             9216 |    9216 |\n",
      "|  95 | encoder.blocks.2.2.se.act1        | ReLU                   |                                                   | (1, 48, 1, 1)   |           48 | (1, 48, 1, 1)   |           48 |                0 |       0 |\n",
      "|  96 | encoder.blocks.2.2.se.conv_expand | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 48, 1, 1)   |           48 | (1, 192, 1, 1)  |          192 |             9216 |    9216 |\n",
      "|  97 | encoder.blocks.2.2.se.gate        | Hardsigmoid            |                                                   | (1, 192, 1, 1)  |          192 | (1, 192, 1, 1)  |          192 |                0 |       0 |\n",
      "|  98 | encoder.blocks.2.2.se             | SqueezeExcite          |                                                   | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |                0 |       0 |\n",
      "|  99 | encoder.blocks.2.2.conv_pwl       | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 192, 4, 4)  |         3072 | (1, 32, 4, 4)   |          512 |             6144 |   98304 |\n",
      "| 100 | encoder.blocks.2.2.bn3.drop       | Identity               |                                                   | (1, 32, 4, 4)   |          512 | (1, 32, 4, 4)   |          512 |                0 |       0 |\n",
      "| 101 | encoder.blocks.2.2.bn3.act        | Identity               |                                                   | (1, 32, 4, 4)   |          512 | (1, 32, 4, 4)   |          512 |                0 |       0 |\n",
      "| 102 | encoder.blocks.2.2.bn3            | BatchNormAct2d         |                                                   | (1, 32, 4, 4)   |          512 | (1, 32, 4, 4)   |          512 |                0 |       0 |\n",
      "| 103 | encoder.blocks.2.2.drop_path      | DropPath               |                                                   | (1, 32, 4, 4)   |          512 | (1, 32, 4, 4)   |          512 |                0 |       0 |\n",
      "| 104 | encoder.blocks.2.2                | InvertedResidual       |                                                   | (1, 32, 4, 4)   |          512 | (1, 32, 4, 4)   |          512 |                0 |       0 |\n",
      "| 105 | encoder.blocks.2                  | Sequential             |                                                   | (1, 24, 8, 8)   |         1536 | (1, 32, 4, 4)   |          512 |                0 |       0 |\n",
      "| 106 | encoder.blocks.3.0.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 32, 4, 4)   |          512 | (1, 96, 4, 4)   |         1536 |             3072 |   49152 |\n",
      "| 107 | encoder.blocks.3.0.bn1.drop       | Identity               |                                                   | (1, 96, 4, 4)   |         1536 | (1, 96, 4, 4)   |         1536 |                0 |       0 |\n",
      "| 108 | encoder.blocks.3.0.bn1.act        | Hardswish              |                                                   | (1, 96, 4, 4)   |         1536 | (1, 96, 4, 4)   |         1536 |                0 |       0 |\n",
      "| 109 | encoder.blocks.3.0.bn1            | BatchNormAct2d         |                                                   | (1, 96, 4, 4)   |         1536 | (1, 96, 4, 4)   |         1536 |                0 |       0 |\n",
      "| 110 | encoder.blocks.3.0.conv_dw        | Conv2d                 | k=(5, 5), s=(1, 1), g=(96), dsc=(True), d=(1, 1)  | (1, 96, 4, 4)   |         1536 | (1, 96, 4, 4)   |         1536 |             2400 |   38400 |\n",
      "| 111 | encoder.blocks.3.0.bn2.drop       | Identity               |                                                   | (1, 96, 4, 4)   |         1536 | (1, 96, 4, 4)   |         1536 |                0 |       0 |\n",
      "| 112 | encoder.blocks.3.0.bn2.act        | Hardswish              |                                                   | (1, 96, 4, 4)   |         1536 | (1, 96, 4, 4)   |         1536 |                0 |       0 |\n",
      "| 113 | encoder.blocks.3.0.bn2            | BatchNormAct2d         |                                                   | (1, 96, 4, 4)   |         1536 | (1, 96, 4, 4)   |         1536 |                0 |       0 |\n",
      "| 114 | encoder.blocks.3.0.se.conv_reduce | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 96, 1, 1)   |           96 | (1, 24, 1, 1)   |           24 |             2304 |    2304 |\n",
      "| 115 | encoder.blocks.3.0.se.act1        | ReLU                   |                                                   | (1, 24, 1, 1)   |           24 | (1, 24, 1, 1)   |           24 |                0 |       0 |\n",
      "| 116 | encoder.blocks.3.0.se.conv_expand | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 24, 1, 1)   |           24 | (1, 96, 1, 1)   |           96 |             2304 |    2304 |\n",
      "| 117 | encoder.blocks.3.0.se.gate        | Hardsigmoid            |                                                   | (1, 96, 1, 1)   |           96 | (1, 96, 1, 1)   |           96 |                0 |       0 |\n",
      "| 118 | encoder.blocks.3.0.se             | SqueezeExcite          |                                                   | (1, 96, 4, 4)   |         1536 | (1, 96, 4, 4)   |         1536 |                0 |       0 |\n",
      "| 119 | encoder.blocks.3.0.conv_pwl       | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 96, 4, 4)   |         1536 | (1, 40, 4, 4)   |          640 |             3840 |   61440 |\n",
      "| 120 | encoder.blocks.3.0.bn3.drop       | Identity               |                                                   | (1, 40, 4, 4)   |          640 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "| 121 | encoder.blocks.3.0.bn3.act        | Identity               |                                                   | (1, 40, 4, 4)   |          640 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "| 122 | encoder.blocks.3.0.bn3            | BatchNormAct2d         |                                                   | (1, 40, 4, 4)   |          640 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "| 123 | encoder.blocks.3.0                | InvertedResidual       |                                                   | (1, 32, 4, 4)   |          512 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "| 124 | encoder.blocks.3.1.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 40, 4, 4)   |          640 | (1, 120, 4, 4)  |         1920 |             4800 |   76800 |\n",
      "| 125 | encoder.blocks.3.1.bn1.drop       | Identity               |                                                   | (1, 120, 4, 4)  |         1920 | (1, 120, 4, 4)  |         1920 |                0 |       0 |\n",
      "| 126 | encoder.blocks.3.1.bn1.act        | Hardswish              |                                                   | (1, 120, 4, 4)  |         1920 | (1, 120, 4, 4)  |         1920 |                0 |       0 |\n",
      "| 127 | encoder.blocks.3.1.bn1            | BatchNormAct2d         |                                                   | (1, 120, 4, 4)  |         1920 | (1, 120, 4, 4)  |         1920 |                0 |       0 |\n",
      "| 128 | encoder.blocks.3.1.conv_dw        | Conv2d                 | k=(5, 5), s=(1, 1), g=(120), dsc=(True), d=(1, 1) | (1, 120, 4, 4)  |         1920 | (1, 120, 4, 4)  |         1920 |             3000 |   48000 |\n",
      "| 129 | encoder.blocks.3.1.bn2.drop       | Identity               |                                                   | (1, 120, 4, 4)  |         1920 | (1, 120, 4, 4)  |         1920 |                0 |       0 |\n",
      "| 130 | encoder.blocks.3.1.bn2.act        | Hardswish              |                                                   | (1, 120, 4, 4)  |         1920 | (1, 120, 4, 4)  |         1920 |                0 |       0 |\n",
      "| 131 | encoder.blocks.3.1.bn2            | BatchNormAct2d         |                                                   | (1, 120, 4, 4)  |         1920 | (1, 120, 4, 4)  |         1920 |                0 |       0 |\n",
      "| 132 | encoder.blocks.3.1.se.conv_reduce | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 120, 1, 1)  |          120 | (1, 32, 1, 1)   |           32 |             3840 |    3840 |\n",
      "| 133 | encoder.blocks.3.1.se.act1        | ReLU                   |                                                   | (1, 32, 1, 1)   |           32 | (1, 32, 1, 1)   |           32 |                0 |       0 |\n",
      "| 134 | encoder.blocks.3.1.se.conv_expand | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 32, 1, 1)   |           32 | (1, 120, 1, 1)  |          120 |             3840 |    3840 |\n",
      "| 135 | encoder.blocks.3.1.se.gate        | Hardsigmoid            |                                                   | (1, 120, 1, 1)  |          120 | (1, 120, 1, 1)  |          120 |                0 |       0 |\n",
      "| 136 | encoder.blocks.3.1.se             | SqueezeExcite          |                                                   | (1, 120, 4, 4)  |         1920 | (1, 120, 4, 4)  |         1920 |                0 |       0 |\n",
      "| 137 | encoder.blocks.3.1.conv_pwl       | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 120, 4, 4)  |         1920 | (1, 40, 4, 4)   |          640 |             4800 |   76800 |\n",
      "| 138 | encoder.blocks.3.1.bn3.drop       | Identity               |                                                   | (1, 40, 4, 4)   |          640 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "| 139 | encoder.blocks.3.1.bn3.act        | Identity               |                                                   | (1, 40, 4, 4)   |          640 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "| 140 | encoder.blocks.3.1.bn3            | BatchNormAct2d         |                                                   | (1, 40, 4, 4)   |          640 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "| 141 | encoder.blocks.3.1.drop_path      | DropPath               |                                                   | (1, 40, 4, 4)   |          640 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "| 142 | encoder.blocks.3.1                | InvertedResidual       |                                                   | (1, 40, 4, 4)   |          640 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "| 143 | encoder.blocks.3                  | Sequential             |                                                   | (1, 32, 4, 4)   |          512 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "| 144 | encoder.blocks.4.0.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 40, 4, 4)   |          640 | (1, 240, 4, 4)  |         3840 |             9600 |  153600 |\n",
      "| 145 | encoder.blocks.4.0.bn1.drop       | Identity               |                                                   | (1, 240, 4, 4)  |         3840 | (1, 240, 4, 4)  |         3840 |                0 |       0 |\n",
      "| 146 | encoder.blocks.4.0.bn1.act        | Hardswish              |                                                   | (1, 240, 4, 4)  |         3840 | (1, 240, 4, 4)  |         3840 |                0 |       0 |\n",
      "| 147 | encoder.blocks.4.0.bn1            | BatchNormAct2d         |                                                   | (1, 240, 4, 4)  |         3840 | (1, 240, 4, 4)  |         3840 |                0 |       0 |\n",
      "| 148 | encoder.blocks.4.0.conv_dw        | Conv2d                 | k=(5, 5), s=(2, 2), g=(240), dsc=(True), d=(1, 1) | (1, 240, 4, 4)  |         3840 | (1, 240, 2, 2)  |          960 |             6000 |   24000 |\n",
      "| 149 | encoder.blocks.4.0.bn2.drop       | Identity               |                                                   | (1, 240, 2, 2)  |          960 | (1, 240, 2, 2)  |          960 |                0 |       0 |\n",
      "| 150 | encoder.blocks.4.0.bn2.act        | Hardswish              |                                                   | (1, 240, 2, 2)  |          960 | (1, 240, 2, 2)  |          960 |                0 |       0 |\n",
      "| 151 | encoder.blocks.4.0.bn2            | BatchNormAct2d         |                                                   | (1, 240, 2, 2)  |          960 | (1, 240, 2, 2)  |          960 |                0 |       0 |\n",
      "| 152 | encoder.blocks.4.0.se.conv_reduce | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 240, 1, 1)  |          240 | (1, 64, 1, 1)   |           64 |            15360 |   15360 |\n",
      "| 153 | encoder.blocks.4.0.se.act1        | ReLU                   |                                                   | (1, 64, 1, 1)   |           64 | (1, 64, 1, 1)   |           64 |                0 |       0 |\n",
      "| 154 | encoder.blocks.4.0.se.conv_expand | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 64, 1, 1)   |           64 | (1, 240, 1, 1)  |          240 |            15360 |   15360 |\n",
      "| 155 | encoder.blocks.4.0.se.gate        | Hardsigmoid            |                                                   | (1, 240, 1, 1)  |          240 | (1, 240, 1, 1)  |          240 |                0 |       0 |\n",
      "| 156 | encoder.blocks.4.0.se             | SqueezeExcite          |                                                   | (1, 240, 2, 2)  |          960 | (1, 240, 2, 2)  |          960 |                0 |       0 |\n",
      "| 157 | encoder.blocks.4.0.conv_pwl       | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 240, 2, 2)  |          960 | (1, 72, 2, 2)   |          288 |            17280 |   69120 |\n",
      "| 158 | encoder.blocks.4.0.bn3.drop       | Identity               |                                                   | (1, 72, 2, 2)   |          288 | (1, 72, 2, 2)   |          288 |                0 |       0 |\n",
      "| 159 | encoder.blocks.4.0.bn3.act        | Identity               |                                                   | (1, 72, 2, 2)   |          288 | (1, 72, 2, 2)   |          288 |                0 |       0 |\n",
      "| 160 | encoder.blocks.4.0.bn3            | BatchNormAct2d         |                                                   | (1, 72, 2, 2)   |          288 | (1, 72, 2, 2)   |          288 |                0 |       0 |\n",
      "| 161 | encoder.blocks.4.0                | InvertedResidual       |                                                   | (1, 40, 4, 4)   |          640 | (1, 72, 2, 2)   |          288 |                0 |       0 |\n",
      "| 162 | encoder.blocks.4.1.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 72, 2, 2)   |          288 | (1, 432, 2, 2)  |         1728 |            31104 |  124416 |\n",
      "| 163 | encoder.blocks.4.1.bn1.drop       | Identity               |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 164 | encoder.blocks.4.1.bn1.act        | Hardswish              |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 165 | encoder.blocks.4.1.bn1            | BatchNormAct2d         |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 166 | encoder.blocks.4.1.conv_dw        | Conv2d                 | k=(5, 5), s=(1, 1), g=(432), dsc=(True), d=(1, 1) | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |            10800 |   43200 |\n",
      "| 167 | encoder.blocks.4.1.bn2.drop       | Identity               |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 168 | encoder.blocks.4.1.bn2.act        | Hardswish              |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 169 | encoder.blocks.4.1.bn2            | BatchNormAct2d         |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 170 | encoder.blocks.4.1.se.conv_reduce | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 432, 1, 1)  |          432 | (1, 112, 1, 1)  |          112 |            48384 |   48384 |\n",
      "| 171 | encoder.blocks.4.1.se.act1        | ReLU                   |                                                   | (1, 112, 1, 1)  |          112 | (1, 112, 1, 1)  |          112 |                0 |       0 |\n",
      "| 172 | encoder.blocks.4.1.se.conv_expand | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 112, 1, 1)  |          112 | (1, 432, 1, 1)  |          432 |            48384 |   48384 |\n",
      "| 173 | encoder.blocks.4.1.se.gate        | Hardsigmoid            |                                                   | (1, 432, 1, 1)  |          432 | (1, 432, 1, 1)  |          432 |                0 |       0 |\n",
      "| 174 | encoder.blocks.4.1.se             | SqueezeExcite          |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 175 | encoder.blocks.4.1.conv_pwl       | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 432, 2, 2)  |         1728 | (1, 72, 2, 2)   |          288 |            31104 |  124416 |\n",
      "| 176 | encoder.blocks.4.1.bn3.drop       | Identity               |                                                   | (1, 72, 2, 2)   |          288 | (1, 72, 2, 2)   |          288 |                0 |       0 |\n",
      "| 177 | encoder.blocks.4.1.bn3.act        | Identity               |                                                   | (1, 72, 2, 2)   |          288 | (1, 72, 2, 2)   |          288 |                0 |       0 |\n",
      "| 178 | encoder.blocks.4.1.bn3            | BatchNormAct2d         |                                                   | (1, 72, 2, 2)   |          288 | (1, 72, 2, 2)   |          288 |                0 |       0 |\n",
      "| 179 | encoder.blocks.4.1.drop_path      | DropPath               |                                                   | (1, 72, 2, 2)   |          288 | (1, 72, 2, 2)   |          288 |                0 |       0 |\n",
      "| 180 | encoder.blocks.4.1                | InvertedResidual       |                                                   | (1, 72, 2, 2)   |          288 | (1, 72, 2, 2)   |          288 |                0 |       0 |\n",
      "| 181 | encoder.blocks.4.2.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 72, 2, 2)   |          288 | (1, 432, 2, 2)  |         1728 |            31104 |  124416 |\n",
      "| 182 | encoder.blocks.4.2.bn1.drop       | Identity               |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 183 | encoder.blocks.4.2.bn1.act        | Hardswish              |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 184 | encoder.blocks.4.2.bn1            | BatchNormAct2d         |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 185 | encoder.blocks.4.2.conv_dw        | Conv2d                 | k=(5, 5), s=(1, 1), g=(432), dsc=(True), d=(1, 1) | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |            10800 |   43200 |\n",
      "| 186 | encoder.blocks.4.2.bn2.drop       | Identity               |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 187 | encoder.blocks.4.2.bn2.act        | Hardswish              |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 188 | encoder.blocks.4.2.bn2            | BatchNormAct2d         |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 189 | encoder.blocks.4.2.se.conv_reduce | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 432, 1, 1)  |          432 | (1, 112, 1, 1)  |          112 |            48384 |   48384 |\n",
      "| 190 | encoder.blocks.4.2.se.act1        | ReLU                   |                                                   | (1, 112, 1, 1)  |          112 | (1, 112, 1, 1)  |          112 |                0 |       0 |\n",
      "| 191 | encoder.blocks.4.2.se.conv_expand | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 112, 1, 1)  |          112 | (1, 432, 1, 1)  |          432 |            48384 |   48384 |\n",
      "| 192 | encoder.blocks.4.2.se.gate        | Hardsigmoid            |                                                   | (1, 432, 1, 1)  |          432 | (1, 432, 1, 1)  |          432 |                0 |       0 |\n",
      "| 193 | encoder.blocks.4.2.se             | SqueezeExcite          |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 194 | encoder.blocks.4.2.conv_pwl       | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 432, 2, 2)  |         1728 | (1, 72, 2, 2)   |          288 |            31104 |  124416 |\n",
      "| 195 | encoder.blocks.4.2.bn3.drop       | Identity               |                                                   | (1, 72, 2, 2)   |          288 | (1, 72, 2, 2)   |          288 |                0 |       0 |\n",
      "| 196 | encoder.blocks.4.2.bn3.act        | Identity               |                                                   | (1, 72, 2, 2)   |          288 | (1, 72, 2, 2)   |          288 |                0 |       0 |\n",
      "| 197 | encoder.blocks.4.2.bn3            | BatchNormAct2d         |                                                   | (1, 72, 2, 2)   |          288 | (1, 72, 2, 2)   |          288 |                0 |       0 |\n",
      "| 198 | encoder.blocks.4.2.drop_path      | DropPath               |                                                   | (1, 72, 2, 2)   |          288 | (1, 72, 2, 2)   |          288 |                0 |       0 |\n",
      "| 199 | encoder.blocks.4.2                | InvertedResidual       |                                                   | (1, 72, 2, 2)   |          288 | (1, 72, 2, 2)   |          288 |                0 |       0 |\n",
      "| 200 | encoder.blocks.4                  | Sequential             |                                                   | (1, 40, 4, 4)   |          640 | (1, 72, 2, 2)   |          288 |                0 |       0 |\n",
      "| 201 | encoder.blocks.5.0.conv           | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 72, 2, 2)   |          288 | (1, 432, 2, 2)  |         1728 |            31104 |  124416 |\n",
      "| 202 | encoder.blocks.5.0.bn1.drop       | Identity               |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 203 | encoder.blocks.5.0.bn1.act        | Hardswish              |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 204 | encoder.blocks.5.0.bn1            | BatchNormAct2d         |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 205 | encoder.blocks.5.0                | ConvBnAct              |                                                   | (1, 72, 2, 2)   |          288 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 206 | encoder.blocks.5                  | Sequential             |                                                   | (1, 72, 2, 2)   |          288 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 207 | encoder.blocks                    | Sequential             |                                                   | (1, 16, 32, 32) |        16384 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 208 | encoder.global_pool.pool          | Identity               |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 209 | encoder.global_pool.flatten       | Identity               |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 210 | encoder.global_pool               | SelectAdaptivePool2d   |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 211 | encoder.conv_head                 | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 432, 2, 2)  |         1728 | (1, 1024, 2, 2) |         4096 |           442368 | 1769472 |\n",
      "| 212 | encoder.act2                      | Hardswish              |                                                   | (1, 1024, 2, 2) |         4096 | (1, 1024, 2, 2) |         4096 |                0 |       0 |\n",
      "| 213 | encoder.flatten                   | Identity               |                                                   | (1, 1024, 2, 2) |         4096 | (1, 1024, 2, 2) |         4096 |                0 |       0 |\n",
      "| 214 | encoder.classifier                | Identity               |                                                   | (1, 1024, 2, 2) |         4096 | (1, 1024, 2, 2) |         4096 |                0 |       0 |\n",
      "| 215 | encoder                           | MobileNetV3            |                                                   | (1, 3, 32, 32)  |         3072 | (1, 1024, 2, 2) |         4096 |                0 |       0 |\n",
      "| 216 | classifier.pooling                | AdaptiveAvgPool2d      |                                                   | (1, 1024, 2, 2) |         4096 | (1, 1024, 1, 1) |         1024 |                0 |       0 |\n",
      "| 217 | classifier.flatten                | Flatten                |                                                   | (1, 1024, 1, 1) |         1024 | (1, 1024)       |         1024 |                0 |       0 |\n",
      "| 218 | classifier.linear                 | Linear                 |                                                   | (1, 1024)       |         1024 | (1, 10)         |           10 |            10240 |   10240 |\n",
      "| 219 | classifier                        | DefaultClassifierHead  |                                                   | (1, 1024, 2, 2) |         4096 | (1, 10)         |           10 |                0 |       0 |\n",
      "+-----+-----------------------------------+------------------------+---------------------------------------------------+-----------------+--------------+-----------------+--------------+------------------+---------+\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:26:02,383\u001b[0m][\u001b[34mhannah.callbacks.summaries\u001b[0m][\u001b[32mINFO\u001b[0m] - Total MACs: 5,458,368\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:26:02,383\u001b[0m][\u001b[34mhannah.callbacks.summaries\u001b[0m][\u001b[32mINFO\u001b[0m] - Total Weights: 1,014,120\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:26:02,383\u001b[0m][\u001b[34mhannah.callbacks.summaries\u001b[0m][\u001b[32mINFO\u001b[0m] - Total Activations: 515,956\u001b[0m\n",
      "[\u001b[36m2024-02-29 15:26:02,383\u001b[0m][\u001b[34mhannah.callbacks.summaries\u001b[0m][\u001b[32mINFO\u001b[0m] - Estimated Activations: 36,864\u001b[0m\n",
      "Epoch 0: 100%|████| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=2.290]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 12.44it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  8.19it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=2.290, va\u001b[A[\u001b[36m2024-02-29 15:27:12,382\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 0, global step 21: 'val_error' reached 0.89526 (best 0.89526), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=0-step=21.ckpt' as top 1\u001b[0m\n",
      "Epoch 1: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=2.240, va\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 13.59it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  7.87it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=2.240, va\u001b[A[\u001b[36m2024-02-29 15:28:22,305\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 1, global step 42: 'val_error' reached 0.87842 (best 0.87842), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=1-step=42.ckpt' as top 1\u001b[0m\n",
      "Epoch 2: 100%|█| 21/21 [01:08<00:00,  0.30it/s, v_num=logs, train_loss=2.140, va\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 12.60it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  8.75it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=2.140, va\u001b[A[\u001b[36m2024-02-29 15:29:31,887\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 2, global step 63: 'val_error' reached 0.80078 (best 0.80078), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=2-step=63.ckpt' as top 1\u001b[0m\n",
      "Epoch 3: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=2.000, va\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 10.49it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  7.96it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=2.000, va\u001b[A[\u001b[36m2024-02-29 15:30:41,360\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 3, global step 84: 'val_error' reached 0.74756 (best 0.74756), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=3-step=84.ckpt' as top 1\u001b[0m\n",
      "Epoch 4: 100%|█| 21/21 [00:53<00:00,  0.39it/s, v_num=logs, train_loss=1.910, va\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 23.70it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00, 13.70it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 21/21 [00:53<00:00,  0.39it/s, v_num=logs, train_loss=1.910, va\u001b[A[\u001b[36m2024-02-29 15:31:35,393\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 4, global step 105: 'val_error' reached 0.70605 (best 0.70605), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=4-step=105.ckpt' as top 1\u001b[0m\n",
      "Epoch 5: 100%|█| 21/21 [01:06<00:00,  0.31it/s, v_num=logs, train_loss=1.830, va\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 21.62it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00, 11.60it/s]\u001b[A\n",
      "Epoch 5: 100%|█| 21/21 [01:07<00:00,  0.31it/s, v_num=logs, train_loss=1.830, va\u001b[A[\u001b[36m2024-02-29 15:32:42,693\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 5, global step 126: 'val_error' reached 0.67920 (best 0.67920), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=5-step=126.ckpt' as top 1\u001b[0m\n",
      "Epoch 6: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=1.710, va\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 12.59it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  9.08it/s]\u001b[A\n",
      "Epoch 6: 100%|█| 21/21 [01:08<00:00,  0.30it/s, v_num=logs, train_loss=1.710, va\u001b[A[\u001b[36m2024-02-29 15:33:51,984\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 6, global step 147: 'val_error' reached 0.62476 (best 0.62476), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=6-step=147.ckpt' as top 1\u001b[0m\n",
      "Epoch 7: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=1.650, va\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00,  8.90it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  8.39it/s]\u001b[A\n",
      "Epoch 7: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=1.650, va\u001b[A[\u001b[36m2024-02-29 15:35:01,377\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 7, global step 168: 'val_error' reached 0.58936 (best 0.58936), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=7-step=168.ckpt' as top 1\u001b[0m\n",
      "Epoch 8: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=1.570, va\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00,  9.67it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  7.85it/s]\u001b[A\n",
      "Epoch 8: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=1.570, va\u001b[A[\u001b[36m2024-02-29 15:36:10,726\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 8, global step 189: 'val_error' reached 0.54810 (best 0.54810), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=8-step=189.ckpt' as top 1\u001b[0m\n",
      "Epoch 9: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=1.530, va\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 12.54it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00, 10.51it/s]\u001b[A\n",
      "Epoch 9: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=1.530, va\u001b[A[\u001b[36m2024-02-29 15:37:20,122\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 9, global step 210: 'val_error' reached 0.53467 (best 0.53467), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=9-step=210.ckpt' as top 1\u001b[0m\n",
      "Epoch 10: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=1.490, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 12.72it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00, 10.04it/s]\u001b[A\n",
      "Epoch 10: 100%|█| 21/21 [01:08<00:00,  0.30it/s, v_num=logs, train_loss=1.490, v\u001b[A[\u001b[36m2024-02-29 15:38:29,386\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 10, global step 231: 'val_error' reached 0.50781 (best 0.50781), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=10-step=231.ckpt' as top 1\u001b[0m\n",
      "Epoch 11: 100%|█| 21/21 [01:07<00:00,  0.31it/s, v_num=logs, train_loss=1.460, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 23.82it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00, 12.13it/s]\u001b[A\n",
      "Epoch 11: 100%|█| 21/21 [01:07<00:00,  0.31it/s, v_num=logs, train_loss=1.460, v\u001b[A[\u001b[36m2024-02-29 15:39:37,449\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 11, global step 252: 'val_error' reached 0.49951 (best 0.49951), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=11-step=252.ckpt' as top 1\u001b[0m\n",
      "Epoch 12: 100%|█| 21/21 [01:06<00:00,  0.31it/s, v_num=logs, train_loss=1.440, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 11.14it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  8.33it/s]\u001b[A\n",
      "Epoch 12: 100%|█| 21/21 [01:07<00:00,  0.31it/s, v_num=logs, train_loss=1.440, v\u001b[A[\u001b[36m2024-02-29 15:40:45,076\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 12, global step 273: 'val_error' reached 0.48853 (best 0.48853), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=12-step=273.ckpt' as top 1\u001b[0m\n",
      "Epoch 13: 100%|█| 21/21 [00:31<00:00,  0.68it/s, v_num=logs, train_loss=1.390, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 56.62it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00, 18.39it/s]\u001b[A\n",
      "Epoch 13: 100%|█| 21/21 [00:31<00:00,  0.67it/s, v_num=logs, train_loss=1.390, v\u001b[A[\u001b[36m2024-02-29 15:41:16,641\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 13, global step 294: 'val_error' was not in top 1\u001b[0m\n",
      "Epoch 14: 100%|█| 21/21 [00:49<00:00,  0.42it/s, v_num=logs, train_loss=1.310, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 12.67it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  9.39it/s]\u001b[A\n",
      "Epoch 14: 100%|█| 21/21 [00:49<00:00,  0.42it/s, v_num=logs, train_loss=1.310, v\u001b[A[\u001b[36m2024-02-29 15:42:06,786\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 14, global step 315: 'val_error' reached 0.45801 (best 0.45801), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=14-step=315.ckpt' as top 1\u001b[0m\n",
      "Epoch 15: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=1.300, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 12.74it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  8.71it/s]\u001b[A\n",
      "Epoch 15: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=1.300, v\u001b[A[\u001b[36m2024-02-29 15:43:16,147\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 15, global step 336: 'val_error' reached 0.45679 (best 0.45679), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=15-step=336.ckpt' as top 1\u001b[0m\n",
      "Epoch 16: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=1.290, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 12.83it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  8.74it/s]\u001b[A\n",
      "Epoch 16: 100%|█| 21/21 [01:08<00:00,  0.30it/s, v_num=logs, train_loss=1.290, v\u001b[A[\u001b[36m2024-02-29 15:44:25,474\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 16, global step 357: 'val_error' reached 0.43066 (best 0.43066), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=16-step=357.ckpt' as top 1\u001b[0m\n",
      "Epoch 17: 100%|█| 21/21 [01:08<00:00,  0.30it/s, v_num=logs, train_loss=1.260, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 12.47it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  9.48it/s]\u001b[A\n",
      "Epoch 17: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=1.260, v\u001b[A[\u001b[36m2024-02-29 15:45:34,998\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 17, global step 378: 'val_error' reached 0.41968 (best 0.41968), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=17-step=378.ckpt' as top 1\u001b[0m\n",
      "Epoch 18: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=1.220, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 10.04it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  4.76it/s]\u001b[A\n",
      "Epoch 18: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=1.220, v\u001b[A[\u001b[36m2024-02-29 15:46:44,026\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 18, global step 399: 'val_error' reached 0.41089 (best 0.41089), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=18-step=399.ckpt' as top 1\u001b[0m\n",
      "Epoch 19: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=1.230, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 11.38it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  8.79it/s]\u001b[A\n",
      "Epoch 19: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=1.230, v\u001b[A[\u001b[36m2024-02-29 15:47:53,870\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 19, global step 420: 'val_error' reached 0.39624 (best 0.39624), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=19-step=420.ckpt' as top 1\u001b[0m\n",
      "Epoch 20: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=1.130, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 10.02it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  8.74it/s]\u001b[A\n",
      "Epoch 20: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=1.130, v\u001b[A[\u001b[36m2024-02-29 15:49:03,275\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 20, global step 441: 'val_error' was not in top 1\u001b[0m\n",
      "Epoch 21: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=1.140, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 10.05it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  7.30it/s]\u001b[A\n",
      "Epoch 21: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=1.140, v\u001b[A[\u001b[36m2024-02-29 15:50:12,816\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 21, global step 462: 'val_error' reached 0.37354 (best 0.37354), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=21-step=462.ckpt' as top 1\u001b[0m\n",
      "Epoch 22: 100%|█| 21/21 [00:58<00:00,  0.36it/s, v_num=logs, train_loss=1.110, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 33.49it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00, 14.90it/s]\u001b[A\n",
      "Epoch 22: 100%|█| 21/21 [00:59<00:00,  0.35it/s, v_num=logs, train_loss=1.110, v\u001b[A[\u001b[36m2024-02-29 15:51:12,284\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 22, global step 483: 'val_error' reached 0.35522 (best 0.35522), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=22-step=483.ckpt' as top 1\u001b[0m\n",
      "Epoch 23: 100%|█| 21/21 [01:01<00:00,  0.34it/s, v_num=logs, train_loss=1.140, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 12.41it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00, 10.89it/s]\u001b[A\n",
      "Epoch 23: 100%|█| 21/21 [01:01<00:00,  0.34it/s, v_num=logs, train_loss=1.140, v\u001b[A[\u001b[36m2024-02-29 15:52:14,093\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 23, global step 504: 'val_error' was not in top 1\u001b[0m\n",
      "Epoch 24: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=1.070, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 12.56it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  8.11it/s]\u001b[A\n",
      "Epoch 24: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=1.070, v\u001b[A[\u001b[36m2024-02-29 15:53:23,981\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 24, global step 525: 'val_error' reached 0.34888 (best 0.34888), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=24-step=525.ckpt' as top 1\u001b[0m\n",
      "Epoch 25: 100%|█| 21/21 [01:08<00:00,  0.30it/s, v_num=logs, train_loss=1.040, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 12.69it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00, 10.87it/s]\u001b[A\n",
      "Epoch 25: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=1.040, v\u001b[A[\u001b[36m2024-02-29 15:54:33,480\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 25, global step 546: 'val_error' reached 0.34717 (best 0.34717), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=25-step=546.ckpt' as top 1\u001b[0m\n",
      "Epoch 26: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=1.040, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 13.82it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00, 10.47it/s]\u001b[A\n",
      "Epoch 26: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=1.040, v\u001b[A[\u001b[36m2024-02-29 15:55:42,940\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 26, global step 567: 'val_error' reached 0.34155 (best 0.34155), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=26-step=567.ckpt' as top 1\u001b[0m\n",
      "Epoch 27: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=1.030, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 12.64it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  8.43it/s]\u001b[A\n",
      "Epoch 27: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=1.030, v\u001b[A[\u001b[36m2024-02-29 15:56:52,262\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 27, global step 588: 'val_error' was not in top 1\u001b[0m\n",
      "Epoch 28: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=1.030, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 12.53it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  9.98it/s]\u001b[A\n",
      "Epoch 28: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=1.030, v\u001b[A[\u001b[36m2024-02-29 15:58:01,597\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 28, global step 609: 'val_error' reached 0.30029 (best 0.30029), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=28-step=609.ckpt' as top 1\u001b[0m\n",
      "Epoch 29: 100%|█| 21/21 [01:07<00:00,  0.31it/s, v_num=logs, train_loss=0.981, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 29.57it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00, 13.66it/s]\u001b[A\n",
      "Epoch 29: 100%|█| 21/21 [01:07<00:00,  0.31it/s, v_num=logs, train_loss=0.981, v\u001b[A[\u001b[36m2024-02-29 15:59:09,242\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 29, global step 630: 'val_error' was not in top 1\u001b[0m\n",
      "Epoch 30: 100%|█| 21/21 [01:07<00:00,  0.31it/s, v_num=logs, train_loss=0.978, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 32.65it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00, 11.84it/s]\u001b[A\n",
      "Epoch 30: 100%|█| 21/21 [01:07<00:00,  0.31it/s, v_num=logs, train_loss=0.978, v\u001b[A[\u001b[36m2024-02-29 16:00:17,445\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 30, global step 651: 'val_error' reached 0.29688 (best 0.29688), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=30-step=651.ckpt' as top 1\u001b[0m\n",
      "Epoch 31: 100%|█| 21/21 [00:38<00:00,  0.54it/s, v_num=logs, train_loss=0.935, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 56.56it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00, 18.42it/s]\u001b[A\n",
      "Epoch 31: 100%|█| 21/21 [00:38<00:00,  0.54it/s, v_num=logs, train_loss=0.935, v\u001b[A[\u001b[36m2024-02-29 16:00:56,612\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 31, global step 672: 'val_error' reached 0.28882 (best 0.28882), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=31-step=672.ckpt' as top 1\u001b[0m\n",
      "Epoch 32: 100%|█| 21/21 [00:42<00:00,  0.50it/s, v_num=logs, train_loss=0.926, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 15.73it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00, 11.98it/s]\u001b[A\n",
      "Epoch 32: 100%|█| 21/21 [00:42<00:00,  0.49it/s, v_num=logs, train_loss=0.926, v\u001b[A[\u001b[36m2024-02-29 16:01:39,474\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 32, global step 693: 'val_error' was not in top 1\u001b[0m\n",
      "Epoch 33: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=0.931, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 12.48it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  9.22it/s]\u001b[A\n",
      "Epoch 33: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=0.931, v\u001b[A[\u001b[36m2024-02-29 16:02:48,210\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 33, global step 714: 'val_error' was not in top 1\u001b[0m\n",
      "Epoch 34: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=0.864, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 10.33it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  7.51it/s]\u001b[A\n",
      "Epoch 34: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=0.864, v\u001b[A[\u001b[36m2024-02-29 16:03:57,656\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 34, global step 735: 'val_error' reached 0.28516 (best 0.28516), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=34-step=735.ckpt' as top 1\u001b[0m\n",
      "Epoch 35: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=0.910, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 10.46it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  8.29it/s]\u001b[A\n",
      "Epoch 35: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=0.910, v\u001b[A[\u001b[36m2024-02-29 16:05:06,975\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 35, global step 756: 'val_error' reached 0.27100 (best 0.27100), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=35-step=756.ckpt' as top 1\u001b[0m\n",
      "Epoch 36: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=0.903, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 12.42it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  8.63it/s]\u001b[A\n",
      "Epoch 36: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=0.903, v\u001b[A[\u001b[36m2024-02-29 16:06:16,544\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 36, global step 777: 'val_error' reached 0.26733 (best 0.26733), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=36-step=777.ckpt' as top 1\u001b[0m\n",
      "Epoch 37: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=0.895, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 12.57it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  8.91it/s]\u001b[A\n",
      "Epoch 37: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=0.895, v\u001b[A[\u001b[36m2024-02-29 16:07:25,402\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 37, global step 798: 'val_error' was not in top 1\u001b[0m\n",
      "Epoch 38: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=0.816, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 12.65it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  8.53it/s]\u001b[A\n",
      "Epoch 38: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=0.816, v\u001b[A[\u001b[36m2024-02-29 16:08:35,095\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 38, global step 819: 'val_error' reached 0.26172 (best 0.26172), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=38-step=819.ckpt' as top 1\u001b[0m\n",
      "Epoch 39: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=0.854, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 12.66it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  9.57it/s]\u001b[A\n",
      "Epoch 39: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=0.854, v\u001b[A[\u001b[36m2024-02-29 16:09:44,439\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 39, global step 840: 'val_error' reached 0.24829 (best 0.24829), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=39-step=840.ckpt' as top 1\u001b[0m\n",
      "Epoch 40: 100%|█| 21/21 [01:04<00:00,  0.33it/s, v_num=logs, train_loss=0.805, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 28.24it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00, 14.45it/s]\u001b[A\n",
      "Epoch 40: 100%|█| 21/21 [01:04<00:00,  0.32it/s, v_num=logs, train_loss=0.805, v\u001b[A[\u001b[36m2024-02-29 16:10:49,454\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 40, global step 861: 'val_error' was not in top 1\u001b[0m\n",
      "Epoch 41: 100%|█| 21/21 [00:53<00:00,  0.39it/s, v_num=logs, train_loss=0.798, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 15.00it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00, 11.88it/s]\u001b[A\n",
      "Epoch 41: 100%|█| 21/21 [00:54<00:00,  0.39it/s, v_num=logs, train_loss=0.798, v\u001b[A[\u001b[36m2024-02-29 16:11:43,801\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 41, global step 882: 'val_error' reached 0.24512 (best 0.24512), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=41-step=882.ckpt' as top 1\u001b[0m\n",
      "Epoch 42: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=0.848, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 12.52it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  9.76it/s]\u001b[A\n",
      "Epoch 42: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=0.848, v\u001b[A[\u001b[36m2024-02-29 16:12:53,285\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 42, global step 903: 'val_error' reached 0.23584 (best 0.23584), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=42-step=903.ckpt' as top 1\u001b[0m\n",
      "Epoch 43: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=0.789, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 26.99it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00, 12.12it/s]\u001b[A\n",
      "Epoch 43: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=0.789, v\u001b[A[\u001b[36m2024-02-29 16:14:02,982\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 43, global step 924: 'val_error' was not in top 1\u001b[0m\n",
      "Epoch 44: 100%|█| 21/21 [01:08<00:00,  0.30it/s, v_num=logs, train_loss=0.768, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 10.22it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  7.52it/s]\u001b[A\n",
      "Epoch 44: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=0.768, v\u001b[A[\u001b[36m2024-02-29 16:15:12,653\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 44, global step 945: 'val_error' reached 0.23413 (best 0.23413), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=44-step=945.ckpt' as top 1\u001b[0m\n",
      "Epoch 45: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=0.768, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00,  9.99it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  8.67it/s]\u001b[A\n",
      "Epoch 45: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=0.768, v\u001b[A[\u001b[36m2024-02-29 16:16:22,042\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 45, global step 966: 'val_error' reached 0.22974 (best 0.22974), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=45-step=966.ckpt' as top 1\u001b[0m\n",
      "Epoch 46: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=0.751, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 10.03it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  7.97it/s]\u001b[A\n",
      "Epoch 46: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=0.751, v\u001b[A[\u001b[36m2024-02-29 16:17:31,454\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 46, global step 987: 'val_error' was not in top 1\u001b[0m\n",
      "Epoch 47: 100%|█| 21/21 [01:07<00:00,  0.31it/s, v_num=logs, train_loss=0.776, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 16.70it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  9.61it/s]\u001b[A\n",
      "Epoch 47: 100%|█| 21/21 [01:07<00:00,  0.31it/s, v_num=logs, train_loss=0.776, v\u001b[A[\u001b[36m2024-02-29 16:18:39,520\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 47, global step 1008: 'val_error' reached 0.22827 (best 0.22827), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=47-step=1008.ckpt' as top 1\u001b[0m\n",
      "Epoch 48: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=0.739, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 13.55it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00, 11.72it/s]\u001b[A\n",
      "Epoch 48: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=0.739, v\u001b[A[\u001b[36m2024-02-29 16:19:48,424\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 48, global step 1029: 'val_error' reached 0.22803 (best 0.22803), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=48-step=1029.ckpt' as top 1\u001b[0m\n",
      "Epoch 49: 100%|█| 21/21 [00:48<00:00,  0.44it/s, v_num=logs, train_loss=0.739, v\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 52.55it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00, 17.77it/s]\u001b[A\n",
      "Epoch 49: 100%|█| 21/21 [00:48<00:00,  0.43it/s, v_num=logs, train_loss=0.739, v\u001b[A[\u001b[36m2024-02-29 16:20:37,057\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 49, global step 1050: 'val_error' reached 0.22583 (best 0.22583), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=49-step=1050.ckpt' as top 1\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:37,091\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - `Trainer.fit` stopped: `max_epochs=50` reached.\u001b[0m\n",
      "Epoch 49: 100%|█| 21/21 [00:48<00:00,  0.43it/s, v_num=logs, train_loss=0.739, v\n",
      "INFO: Seed set to 1234\n",
      "[\u001b[36m2024-02-29 16:20:37,123\u001b[0m][\u001b[34mlightning.fabric.utilities.seed\u001b[0m][\u001b[32mINFO\u001b[0m] - Seed set to 1234\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:37,124\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:37,126\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=49-step=1050.ckpt\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:37,159\u001b[0m][\u001b[34mpytorch_lightning.accelerators.cuda\u001b[0m][\u001b[32mINFO\u001b[0m] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:37,928\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=49-step=1050.ckpt\u001b[0m\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00, 11.97it/s]\n",
      "INFO: Seed set to 1234\n",
      "[\u001b[36m2024-02-29 16:20:38,343\u001b[0m][\u001b[34mlightning.fabric.utilities.seed\u001b[0m][\u001b[32mINFO\u001b[0m] - Seed set to 1234\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:38,343\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:38,345\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=49-step=1050.ckpt\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:38,372\u001b[0m][\u001b[34mpytorch_lightning.accelerators.cuda\u001b[0m][\u001b[32mINFO\u001b[0m] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:39,100\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_075/checkpoints/epoch=49-step=1050.ckpt\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:39,102\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=191` in the `DataLoader` to improve performance.\n",
      "\u001b[0m\n",
      "Testing DataLoader 0: 100%|███████████████████████| 4/4 [00:00<00:00, 12.28it/s][\u001b[36m2024-02-29 16:20:39,549\u001b[0m][\u001b[34mhannah.callbacks.summaries\u001b[0m][\u001b[32mINFO\u001b[0m] - \n",
      "+-----+-----------------------------------+------------------------+---------------------------------------------------+-----------------+--------------+-----------------+--------------+------------------+---------+\n",
      "|     | Name                              | Type                   | Attrs                                             | IFM             |   IFM volume | OFM             |   OFM volume |   Weights volume |    MACs |\n",
      "|-----+-----------------------------------+------------------------+---------------------------------------------------+-----------------+--------------+-----------------+--------------+------------------+---------|\n",
      "|   0 | encoder.conv_stem                 | Conv2d                 | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 3, 32, 32)  |         3072 | (1, 16, 32, 32) |        16384 |              432 |  442368 |\n",
      "|   1 | encoder.bn1.drop                  | Identity               |                                                   | (1, 16, 32, 32) |        16384 | (1, 16, 32, 32) |        16384 |                0 |       0 |\n",
      "|   2 | encoder.bn1.act                   | Hardswish              |                                                   | (1, 16, 32, 32) |        16384 | (1, 16, 32, 32) |        16384 |                0 |       0 |\n",
      "|   3 | encoder.bn1                       | BatchNormAct2d         |                                                   | (1, 16, 32, 32) |        16384 | (1, 16, 32, 32) |        16384 |                0 |       0 |\n",
      "|   4 | encoder.blocks.0.0.conv_dw        | Conv2d                 | k=(3, 3), s=(2, 2), g=(16), dsc=(True), d=(1, 1)  | (1, 16, 32, 32) |        16384 | (1, 16, 16, 16) |         4096 |              144 |   36864 |\n",
      "|   5 | encoder.blocks.0.0.bn1.drop       | Identity               |                                                   | (1, 16, 16, 16) |         4096 | (1, 16, 16, 16) |         4096 |                0 |       0 |\n",
      "|   6 | encoder.blocks.0.0.bn1.act        | ReLU                   |                                                   | (1, 16, 16, 16) |         4096 | (1, 16, 16, 16) |         4096 |                0 |       0 |\n",
      "|   7 | encoder.blocks.0.0.bn1            | BatchNormAct2d         |                                                   | (1, 16, 16, 16) |         4096 | (1, 16, 16, 16) |         4096 |                0 |       0 |\n",
      "|   8 | encoder.blocks.0.0.se.conv_reduce | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 16, 1, 1)   |           16 | (1, 8, 1, 1)    |            8 |              128 |     128 |\n",
      "|   9 | encoder.blocks.0.0.se.act1        | ReLU                   |                                                   | (1, 8, 1, 1)    |            8 | (1, 8, 1, 1)    |            8 |                0 |       0 |\n",
      "|  10 | encoder.blocks.0.0.se.conv_expand | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 8, 1, 1)    |            8 | (1, 16, 1, 1)   |           16 |              128 |     128 |\n",
      "|  11 | encoder.blocks.0.0.se.gate        | Hardsigmoid            |                                                   | (1, 16, 1, 1)   |           16 | (1, 16, 1, 1)   |           16 |                0 |       0 |\n",
      "|  12 | encoder.blocks.0.0.se             | SqueezeExcite          |                                                   | (1, 16, 16, 16) |         4096 | (1, 16, 16, 16) |         4096 |                0 |       0 |\n",
      "|  13 | encoder.blocks.0.0.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 16, 16, 16) |         4096 | (1, 16, 16, 16) |         4096 |              256 |   65536 |\n",
      "|  14 | encoder.blocks.0.0.bn2.drop       | Identity               |                                                   | (1, 16, 16, 16) |         4096 | (1, 16, 16, 16) |         4096 |                0 |       0 |\n",
      "|  15 | encoder.blocks.0.0.bn2.act        | Identity               |                                                   | (1, 16, 16, 16) |         4096 | (1, 16, 16, 16) |         4096 |                0 |       0 |\n",
      "|  16 | encoder.blocks.0.0.bn2            | BatchNormAct2d         |                                                   | (1, 16, 16, 16) |         4096 | (1, 16, 16, 16) |         4096 |                0 |       0 |\n",
      "|  17 | encoder.blocks.0.0                | DepthwiseSeparableConv |                                                   | (1, 16, 32, 32) |        16384 | (1, 16, 16, 16) |         4096 |                0 |       0 |\n",
      "|  18 | encoder.blocks.0                  | Sequential             |                                                   | (1, 16, 32, 32) |        16384 | (1, 16, 16, 16) |         4096 |                0 |       0 |\n",
      "|  19 | encoder.blocks.1.0.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 16, 16, 16) |         4096 | (1, 72, 16, 16) |        18432 |             1152 |  294912 |\n",
      "|  20 | encoder.blocks.1.0.bn1.drop       | Identity               |                                                   | (1, 72, 16, 16) |        18432 | (1, 72, 16, 16) |        18432 |                0 |       0 |\n",
      "|  21 | encoder.blocks.1.0.bn1.act        | ReLU                   |                                                   | (1, 72, 16, 16) |        18432 | (1, 72, 16, 16) |        18432 |                0 |       0 |\n",
      "|  22 | encoder.blocks.1.0.bn1            | BatchNormAct2d         |                                                   | (1, 72, 16, 16) |        18432 | (1, 72, 16, 16) |        18432 |                0 |       0 |\n",
      "|  23 | encoder.blocks.1.0.conv_dw        | Conv2d                 | k=(3, 3), s=(2, 2), g=(72), dsc=(True), d=(1, 1)  | (1, 72, 16, 16) |        18432 | (1, 72, 8, 8)   |         4608 |              648 |   41472 |\n",
      "|  24 | encoder.blocks.1.0.bn2.drop       | Identity               |                                                   | (1, 72, 8, 8)   |         4608 | (1, 72, 8, 8)   |         4608 |                0 |       0 |\n",
      "|  25 | encoder.blocks.1.0.bn2.act        | ReLU                   |                                                   | (1, 72, 8, 8)   |         4608 | (1, 72, 8, 8)   |         4608 |                0 |       0 |\n",
      "|  26 | encoder.blocks.1.0.bn2            | BatchNormAct2d         |                                                   | (1, 72, 8, 8)   |         4608 | (1, 72, 8, 8)   |         4608 |                0 |       0 |\n",
      "|  27 | encoder.blocks.1.0.se             | Identity               |                                                   | (1, 72, 8, 8)   |         4608 | (1, 72, 8, 8)   |         4608 |                0 |       0 |\n",
      "|  28 | encoder.blocks.1.0.conv_pwl       | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 72, 8, 8)   |         4608 | (1, 24, 8, 8)   |         1536 |             1728 |  110592 |\n",
      "|  29 | encoder.blocks.1.0.bn3.drop       | Identity               |                                                   | (1, 24, 8, 8)   |         1536 | (1, 24, 8, 8)   |         1536 |                0 |       0 |\n",
      "|  30 | encoder.blocks.1.0.bn3.act        | Identity               |                                                   | (1, 24, 8, 8)   |         1536 | (1, 24, 8, 8)   |         1536 |                0 |       0 |\n",
      "|  31 | encoder.blocks.1.0.bn3            | BatchNormAct2d         |                                                   | (1, 24, 8, 8)   |         1536 | (1, 24, 8, 8)   |         1536 |                0 |       0 |\n",
      "|  32 | encoder.blocks.1.0                | InvertedResidual       |                                                   | (1, 16, 16, 16) |         4096 | (1, 24, 8, 8)   |         1536 |                0 |       0 |\n",
      "|  33 | encoder.blocks.1.1.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 24, 8, 8)   |         1536 | (1, 88, 8, 8)   |         5632 |             2112 |  135168 |\n",
      "|  34 | encoder.blocks.1.1.bn1.drop       | Identity               |                                                   | (1, 88, 8, 8)   |         5632 | (1, 88, 8, 8)   |         5632 |                0 |       0 |\n",
      "|  35 | encoder.blocks.1.1.bn1.act        | ReLU                   |                                                   | (1, 88, 8, 8)   |         5632 | (1, 88, 8, 8)   |         5632 |                0 |       0 |\n",
      "|  36 | encoder.blocks.1.1.bn1            | BatchNormAct2d         |                                                   | (1, 88, 8, 8)   |         5632 | (1, 88, 8, 8)   |         5632 |                0 |       0 |\n",
      "|  37 | encoder.blocks.1.1.conv_dw        | Conv2d                 | k=(3, 3), s=(1, 1), g=(88), dsc=(True), d=(1, 1)  | (1, 88, 8, 8)   |         5632 | (1, 88, 8, 8)   |         5632 |              792 |   50688 |\n",
      "|  38 | encoder.blocks.1.1.bn2.drop       | Identity               |                                                   | (1, 88, 8, 8)   |         5632 | (1, 88, 8, 8)   |         5632 |                0 |       0 |\n",
      "|  39 | encoder.blocks.1.1.bn2.act        | ReLU                   |                                                   | (1, 88, 8, 8)   |         5632 | (1, 88, 8, 8)   |         5632 |                0 |       0 |\n",
      "|  40 | encoder.blocks.1.1.bn2            | BatchNormAct2d         |                                                   | (1, 88, 8, 8)   |         5632 | (1, 88, 8, 8)   |         5632 |                0 |       0 |\n",
      "|  41 | encoder.blocks.1.1.se             | Identity               |                                                   | (1, 88, 8, 8)   |         5632 | (1, 88, 8, 8)   |         5632 |                0 |       0 |\n",
      "|  42 | encoder.blocks.1.1.conv_pwl       | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 88, 8, 8)   |         5632 | (1, 24, 8, 8)   |         1536 |             2112 |  135168 |\n",
      "|  43 | encoder.blocks.1.1.bn3.drop       | Identity               |                                                   | (1, 24, 8, 8)   |         1536 | (1, 24, 8, 8)   |         1536 |                0 |       0 |\n",
      "|  44 | encoder.blocks.1.1.bn3.act        | Identity               |                                                   | (1, 24, 8, 8)   |         1536 | (1, 24, 8, 8)   |         1536 |                0 |       0 |\n",
      "|  45 | encoder.blocks.1.1.bn3            | BatchNormAct2d         |                                                   | (1, 24, 8, 8)   |         1536 | (1, 24, 8, 8)   |         1536 |                0 |       0 |\n",
      "|  46 | encoder.blocks.1.1.drop_path      | DropPath               |                                                   | (1, 24, 8, 8)   |         1536 | (1, 24, 8, 8)   |         1536 |                0 |       0 |\n",
      "|  47 | encoder.blocks.1.1                | InvertedResidual       |                                                   | (1, 24, 8, 8)   |         1536 | (1, 24, 8, 8)   |         1536 |                0 |       0 |\n",
      "|  48 | encoder.blocks.1                  | Sequential             |                                                   | (1, 16, 16, 16) |         4096 | (1, 24, 8, 8)   |         1536 |                0 |       0 |\n",
      "|  49 | encoder.blocks.2.0.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 24, 8, 8)   |         1536 | (1, 96, 8, 8)   |         6144 |             2304 |  147456 |\n",
      "|  50 | encoder.blocks.2.0.bn1.drop       | Identity               |                                                   | (1, 96, 8, 8)   |         6144 | (1, 96, 8, 8)   |         6144 |                0 |       0 |\n",
      "|  51 | encoder.blocks.2.0.bn1.act        | Hardswish              |                                                   | (1, 96, 8, 8)   |         6144 | (1, 96, 8, 8)   |         6144 |                0 |       0 |\n",
      "|  52 | encoder.blocks.2.0.bn1            | BatchNormAct2d         |                                                   | (1, 96, 8, 8)   |         6144 | (1, 96, 8, 8)   |         6144 |                0 |       0 |\n",
      "|  53 | encoder.blocks.2.0.conv_dw        | Conv2d                 | k=(5, 5), s=(2, 2), g=(96), dsc=(True), d=(1, 1)  | (1, 96, 8, 8)   |         6144 | (1, 96, 4, 4)   |         1536 |             2400 |   38400 |\n",
      "|  54 | encoder.blocks.2.0.bn2.drop       | Identity               |                                                   | (1, 96, 4, 4)   |         1536 | (1, 96, 4, 4)   |         1536 |                0 |       0 |\n",
      "|  55 | encoder.blocks.2.0.bn2.act        | Hardswish              |                                                   | (1, 96, 4, 4)   |         1536 | (1, 96, 4, 4)   |         1536 |                0 |       0 |\n",
      "|  56 | encoder.blocks.2.0.bn2            | BatchNormAct2d         |                                                   | (1, 96, 4, 4)   |         1536 | (1, 96, 4, 4)   |         1536 |                0 |       0 |\n",
      "|  57 | encoder.blocks.2.0.se.conv_reduce | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 96, 1, 1)   |           96 | (1, 24, 1, 1)   |           24 |             2304 |    2304 |\n",
      "|  58 | encoder.blocks.2.0.se.act1        | ReLU                   |                                                   | (1, 24, 1, 1)   |           24 | (1, 24, 1, 1)   |           24 |                0 |       0 |\n",
      "|  59 | encoder.blocks.2.0.se.conv_expand | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 24, 1, 1)   |           24 | (1, 96, 1, 1)   |           96 |             2304 |    2304 |\n",
      "|  60 | encoder.blocks.2.0.se.gate        | Hardsigmoid            |                                                   | (1, 96, 1, 1)   |           96 | (1, 96, 1, 1)   |           96 |                0 |       0 |\n",
      "|  61 | encoder.blocks.2.0.se             | SqueezeExcite          |                                                   | (1, 96, 4, 4)   |         1536 | (1, 96, 4, 4)   |         1536 |                0 |       0 |\n",
      "|  62 | encoder.blocks.2.0.conv_pwl       | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 96, 4, 4)   |         1536 | (1, 32, 4, 4)   |          512 |             3072 |   49152 |\n",
      "|  63 | encoder.blocks.2.0.bn3.drop       | Identity               |                                                   | (1, 32, 4, 4)   |          512 | (1, 32, 4, 4)   |          512 |                0 |       0 |\n",
      "|  64 | encoder.blocks.2.0.bn3.act        | Identity               |                                                   | (1, 32, 4, 4)   |          512 | (1, 32, 4, 4)   |          512 |                0 |       0 |\n",
      "|  65 | encoder.blocks.2.0.bn3            | BatchNormAct2d         |                                                   | (1, 32, 4, 4)   |          512 | (1, 32, 4, 4)   |          512 |                0 |       0 |\n",
      "|  66 | encoder.blocks.2.0                | InvertedResidual       |                                                   | (1, 24, 8, 8)   |         1536 | (1, 32, 4, 4)   |          512 |                0 |       0 |\n",
      "|  67 | encoder.blocks.2.1.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 32, 4, 4)   |          512 | (1, 192, 4, 4)  |         3072 |             6144 |   98304 |\n",
      "|  68 | encoder.blocks.2.1.bn1.drop       | Identity               |                                                   | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |                0 |       0 |\n",
      "|  69 | encoder.blocks.2.1.bn1.act        | Hardswish              |                                                   | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |                0 |       0 |\n",
      "|  70 | encoder.blocks.2.1.bn1            | BatchNormAct2d         |                                                   | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |                0 |       0 |\n",
      "|  71 | encoder.blocks.2.1.conv_dw        | Conv2d                 | k=(5, 5), s=(1, 1), g=(192), dsc=(True), d=(1, 1) | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |             4800 |   76800 |\n",
      "|  72 | encoder.blocks.2.1.bn2.drop       | Identity               |                                                   | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |                0 |       0 |\n",
      "|  73 | encoder.blocks.2.1.bn2.act        | Hardswish              |                                                   | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |                0 |       0 |\n",
      "|  74 | encoder.blocks.2.1.bn2            | BatchNormAct2d         |                                                   | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |                0 |       0 |\n",
      "|  75 | encoder.blocks.2.1.se.conv_reduce | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 192, 1, 1)  |          192 | (1, 48, 1, 1)   |           48 |             9216 |    9216 |\n",
      "|  76 | encoder.blocks.2.1.se.act1        | ReLU                   |                                                   | (1, 48, 1, 1)   |           48 | (1, 48, 1, 1)   |           48 |                0 |       0 |\n",
      "|  77 | encoder.blocks.2.1.se.conv_expand | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 48, 1, 1)   |           48 | (1, 192, 1, 1)  |          192 |             9216 |    9216 |\n",
      "|  78 | encoder.blocks.2.1.se.gate        | Hardsigmoid            |                                                   | (1, 192, 1, 1)  |          192 | (1, 192, 1, 1)  |          192 |                0 |       0 |\n",
      "|  79 | encoder.blocks.2.1.se             | SqueezeExcite          |                                                   | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |                0 |       0 |\n",
      "|  80 | encoder.blocks.2.1.conv_pwl       | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 192, 4, 4)  |         3072 | (1, 32, 4, 4)   |          512 |             6144 |   98304 |\n",
      "|  81 | encoder.blocks.2.1.bn3.drop       | Identity               |                                                   | (1, 32, 4, 4)   |          512 | (1, 32, 4, 4)   |          512 |                0 |       0 |\n",
      "|  82 | encoder.blocks.2.1.bn3.act        | Identity               |                                                   | (1, 32, 4, 4)   |          512 | (1, 32, 4, 4)   |          512 |                0 |       0 |\n",
      "|  83 | encoder.blocks.2.1.bn3            | BatchNormAct2d         |                                                   | (1, 32, 4, 4)   |          512 | (1, 32, 4, 4)   |          512 |                0 |       0 |\n",
      "|  84 | encoder.blocks.2.1.drop_path      | DropPath               |                                                   | (1, 32, 4, 4)   |          512 | (1, 32, 4, 4)   |          512 |                0 |       0 |\n",
      "|  85 | encoder.blocks.2.1                | InvertedResidual       |                                                   | (1, 32, 4, 4)   |          512 | (1, 32, 4, 4)   |          512 |                0 |       0 |\n",
      "|  86 | encoder.blocks.2.2.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 32, 4, 4)   |          512 | (1, 192, 4, 4)  |         3072 |             6144 |   98304 |\n",
      "|  87 | encoder.blocks.2.2.bn1.drop       | Identity               |                                                   | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |                0 |       0 |\n",
      "|  88 | encoder.blocks.2.2.bn1.act        | Hardswish              |                                                   | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |                0 |       0 |\n",
      "|  89 | encoder.blocks.2.2.bn1            | BatchNormAct2d         |                                                   | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |                0 |       0 |\n",
      "|  90 | encoder.blocks.2.2.conv_dw        | Conv2d                 | k=(5, 5), s=(1, 1), g=(192), dsc=(True), d=(1, 1) | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |             4800 |   76800 |\n",
      "|  91 | encoder.blocks.2.2.bn2.drop       | Identity               |                                                   | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |                0 |       0 |\n",
      "|  92 | encoder.blocks.2.2.bn2.act        | Hardswish              |                                                   | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |                0 |       0 |\n",
      "|  93 | encoder.blocks.2.2.bn2            | BatchNormAct2d         |                                                   | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |                0 |       0 |\n",
      "|  94 | encoder.blocks.2.2.se.conv_reduce | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 192, 1, 1)  |          192 | (1, 48, 1, 1)   |           48 |             9216 |    9216 |\n",
      "|  95 | encoder.blocks.2.2.se.act1        | ReLU                   |                                                   | (1, 48, 1, 1)   |           48 | (1, 48, 1, 1)   |           48 |                0 |       0 |\n",
      "|  96 | encoder.blocks.2.2.se.conv_expand | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 48, 1, 1)   |           48 | (1, 192, 1, 1)  |          192 |             9216 |    9216 |\n",
      "|  97 | encoder.blocks.2.2.se.gate        | Hardsigmoid            |                                                   | (1, 192, 1, 1)  |          192 | (1, 192, 1, 1)  |          192 |                0 |       0 |\n",
      "|  98 | encoder.blocks.2.2.se             | SqueezeExcite          |                                                   | (1, 192, 4, 4)  |         3072 | (1, 192, 4, 4)  |         3072 |                0 |       0 |\n",
      "|  99 | encoder.blocks.2.2.conv_pwl       | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 192, 4, 4)  |         3072 | (1, 32, 4, 4)   |          512 |             6144 |   98304 |\n",
      "| 100 | encoder.blocks.2.2.bn3.drop       | Identity               |                                                   | (1, 32, 4, 4)   |          512 | (1, 32, 4, 4)   |          512 |                0 |       0 |\n",
      "| 101 | encoder.blocks.2.2.bn3.act        | Identity               |                                                   | (1, 32, 4, 4)   |          512 | (1, 32, 4, 4)   |          512 |                0 |       0 |\n",
      "| 102 | encoder.blocks.2.2.bn3            | BatchNormAct2d         |                                                   | (1, 32, 4, 4)   |          512 | (1, 32, 4, 4)   |          512 |                0 |       0 |\n",
      "| 103 | encoder.blocks.2.2.drop_path      | DropPath               |                                                   | (1, 32, 4, 4)   |          512 | (1, 32, 4, 4)   |          512 |                0 |       0 |\n",
      "| 104 | encoder.blocks.2.2                | InvertedResidual       |                                                   | (1, 32, 4, 4)   |          512 | (1, 32, 4, 4)   |          512 |                0 |       0 |\n",
      "| 105 | encoder.blocks.2                  | Sequential             |                                                   | (1, 24, 8, 8)   |         1536 | (1, 32, 4, 4)   |          512 |                0 |       0 |\n",
      "| 106 | encoder.blocks.3.0.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 32, 4, 4)   |          512 | (1, 96, 4, 4)   |         1536 |             3072 |   49152 |\n",
      "| 107 | encoder.blocks.3.0.bn1.drop       | Identity               |                                                   | (1, 96, 4, 4)   |         1536 | (1, 96, 4, 4)   |         1536 |                0 |       0 |\n",
      "| 108 | encoder.blocks.3.0.bn1.act        | Hardswish              |                                                   | (1, 96, 4, 4)   |         1536 | (1, 96, 4, 4)   |         1536 |                0 |       0 |\n",
      "| 109 | encoder.blocks.3.0.bn1            | BatchNormAct2d         |                                                   | (1, 96, 4, 4)   |         1536 | (1, 96, 4, 4)   |         1536 |                0 |       0 |\n",
      "| 110 | encoder.blocks.3.0.conv_dw        | Conv2d                 | k=(5, 5), s=(1, 1), g=(96), dsc=(True), d=(1, 1)  | (1, 96, 4, 4)   |         1536 | (1, 96, 4, 4)   |         1536 |             2400 |   38400 |\n",
      "| 111 | encoder.blocks.3.0.bn2.drop       | Identity               |                                                   | (1, 96, 4, 4)   |         1536 | (1, 96, 4, 4)   |         1536 |                0 |       0 |\n",
      "| 112 | encoder.blocks.3.0.bn2.act        | Hardswish              |                                                   | (1, 96, 4, 4)   |         1536 | (1, 96, 4, 4)   |         1536 |                0 |       0 |\n",
      "| 113 | encoder.blocks.3.0.bn2            | BatchNormAct2d         |                                                   | (1, 96, 4, 4)   |         1536 | (1, 96, 4, 4)   |         1536 |                0 |       0 |\n",
      "| 114 | encoder.blocks.3.0.se.conv_reduce | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 96, 1, 1)   |           96 | (1, 24, 1, 1)   |           24 |             2304 |    2304 |\n",
      "| 115 | encoder.blocks.3.0.se.act1        | ReLU                   |                                                   | (1, 24, 1, 1)   |           24 | (1, 24, 1, 1)   |           24 |                0 |       0 |\n",
      "| 116 | encoder.blocks.3.0.se.conv_expand | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 24, 1, 1)   |           24 | (1, 96, 1, 1)   |           96 |             2304 |    2304 |\n",
      "| 117 | encoder.blocks.3.0.se.gate        | Hardsigmoid            |                                                   | (1, 96, 1, 1)   |           96 | (1, 96, 1, 1)   |           96 |                0 |       0 |\n",
      "| 118 | encoder.blocks.3.0.se             | SqueezeExcite          |                                                   | (1, 96, 4, 4)   |         1536 | (1, 96, 4, 4)   |         1536 |                0 |       0 |\n",
      "| 119 | encoder.blocks.3.0.conv_pwl       | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 96, 4, 4)   |         1536 | (1, 40, 4, 4)   |          640 |             3840 |   61440 |\n",
      "| 120 | encoder.blocks.3.0.bn3.drop       | Identity               |                                                   | (1, 40, 4, 4)   |          640 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "| 121 | encoder.blocks.3.0.bn3.act        | Identity               |                                                   | (1, 40, 4, 4)   |          640 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "| 122 | encoder.blocks.3.0.bn3            | BatchNormAct2d         |                                                   | (1, 40, 4, 4)   |          640 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "| 123 | encoder.blocks.3.0                | InvertedResidual       |                                                   | (1, 32, 4, 4)   |          512 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "| 124 | encoder.blocks.3.1.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 40, 4, 4)   |          640 | (1, 120, 4, 4)  |         1920 |             4800 |   76800 |\n",
      "| 125 | encoder.blocks.3.1.bn1.drop       | Identity               |                                                   | (1, 120, 4, 4)  |         1920 | (1, 120, 4, 4)  |         1920 |                0 |       0 |\n",
      "| 126 | encoder.blocks.3.1.bn1.act        | Hardswish              |                                                   | (1, 120, 4, 4)  |         1920 | (1, 120, 4, 4)  |         1920 |                0 |       0 |\n",
      "| 127 | encoder.blocks.3.1.bn1            | BatchNormAct2d         |                                                   | (1, 120, 4, 4)  |         1920 | (1, 120, 4, 4)  |         1920 |                0 |       0 |\n",
      "| 128 | encoder.blocks.3.1.conv_dw        | Conv2d                 | k=(5, 5), s=(1, 1), g=(120), dsc=(True), d=(1, 1) | (1, 120, 4, 4)  |         1920 | (1, 120, 4, 4)  |         1920 |             3000 |   48000 |\n",
      "| 129 | encoder.blocks.3.1.bn2.drop       | Identity               |                                                   | (1, 120, 4, 4)  |         1920 | (1, 120, 4, 4)  |         1920 |                0 |       0 |\n",
      "| 130 | encoder.blocks.3.1.bn2.act        | Hardswish              |                                                   | (1, 120, 4, 4)  |         1920 | (1, 120, 4, 4)  |         1920 |                0 |       0 |\n",
      "| 131 | encoder.blocks.3.1.bn2            | BatchNormAct2d         |                                                   | (1, 120, 4, 4)  |         1920 | (1, 120, 4, 4)  |         1920 |                0 |       0 |\n",
      "| 132 | encoder.blocks.3.1.se.conv_reduce | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 120, 1, 1)  |          120 | (1, 32, 1, 1)   |           32 |             3840 |    3840 |\n",
      "| 133 | encoder.blocks.3.1.se.act1        | ReLU                   |                                                   | (1, 32, 1, 1)   |           32 | (1, 32, 1, 1)   |           32 |                0 |       0 |\n",
      "| 134 | encoder.blocks.3.1.se.conv_expand | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 32, 1, 1)   |           32 | (1, 120, 1, 1)  |          120 |             3840 |    3840 |\n",
      "| 135 | encoder.blocks.3.1.se.gate        | Hardsigmoid            |                                                   | (1, 120, 1, 1)  |          120 | (1, 120, 1, 1)  |          120 |                0 |       0 |\n",
      "| 136 | encoder.blocks.3.1.se             | SqueezeExcite          |                                                   | (1, 120, 4, 4)  |         1920 | (1, 120, 4, 4)  |         1920 |                0 |       0 |\n",
      "| 137 | encoder.blocks.3.1.conv_pwl       | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 120, 4, 4)  |         1920 | (1, 40, 4, 4)   |          640 |             4800 |   76800 |\n",
      "| 138 | encoder.blocks.3.1.bn3.drop       | Identity               |                                                   | (1, 40, 4, 4)   |          640 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "| 139 | encoder.blocks.3.1.bn3.act        | Identity               |                                                   | (1, 40, 4, 4)   |          640 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "| 140 | encoder.blocks.3.1.bn3            | BatchNormAct2d         |                                                   | (1, 40, 4, 4)   |          640 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "| 141 | encoder.blocks.3.1.drop_path      | DropPath               |                                                   | (1, 40, 4, 4)   |          640 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "| 142 | encoder.blocks.3.1                | InvertedResidual       |                                                   | (1, 40, 4, 4)   |          640 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "| 143 | encoder.blocks.3                  | Sequential             |                                                   | (1, 32, 4, 4)   |          512 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "| 144 | encoder.blocks.4.0.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 40, 4, 4)   |          640 | (1, 240, 4, 4)  |         3840 |             9600 |  153600 |\n",
      "| 145 | encoder.blocks.4.0.bn1.drop       | Identity               |                                                   | (1, 240, 4, 4)  |         3840 | (1, 240, 4, 4)  |         3840 |                0 |       0 |\n",
      "| 146 | encoder.blocks.4.0.bn1.act        | Hardswish              |                                                   | (1, 240, 4, 4)  |         3840 | (1, 240, 4, 4)  |         3840 |                0 |       0 |\n",
      "| 147 | encoder.blocks.4.0.bn1            | BatchNormAct2d         |                                                   | (1, 240, 4, 4)  |         3840 | (1, 240, 4, 4)  |         3840 |                0 |       0 |\n",
      "| 148 | encoder.blocks.4.0.conv_dw        | Conv2d                 | k=(5, 5), s=(2, 2), g=(240), dsc=(True), d=(1, 1) | (1, 240, 4, 4)  |         3840 | (1, 240, 2, 2)  |          960 |             6000 |   24000 |\n",
      "| 149 | encoder.blocks.4.0.bn2.drop       | Identity               |                                                   | (1, 240, 2, 2)  |          960 | (1, 240, 2, 2)  |          960 |                0 |       0 |\n",
      "| 150 | encoder.blocks.4.0.bn2.act        | Hardswish              |                                                   | (1, 240, 2, 2)  |          960 | (1, 240, 2, 2)  |          960 |                0 |       0 |\n",
      "| 151 | encoder.blocks.4.0.bn2            | BatchNormAct2d         |                                                   | (1, 240, 2, 2)  |          960 | (1, 240, 2, 2)  |          960 |                0 |       0 |\n",
      "| 152 | encoder.blocks.4.0.se.conv_reduce | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 240, 1, 1)  |          240 | (1, 64, 1, 1)   |           64 |            15360 |   15360 |\n",
      "| 153 | encoder.blocks.4.0.se.act1        | ReLU                   |                                                   | (1, 64, 1, 1)   |           64 | (1, 64, 1, 1)   |           64 |                0 |       0 |\n",
      "| 154 | encoder.blocks.4.0.se.conv_expand | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 64, 1, 1)   |           64 | (1, 240, 1, 1)  |          240 |            15360 |   15360 |\n",
      "| 155 | encoder.blocks.4.0.se.gate        | Hardsigmoid            |                                                   | (1, 240, 1, 1)  |          240 | (1, 240, 1, 1)  |          240 |                0 |       0 |\n",
      "| 156 | encoder.blocks.4.0.se             | SqueezeExcite          |                                                   | (1, 240, 2, 2)  |          960 | (1, 240, 2, 2)  |          960 |                0 |       0 |\n",
      "| 157 | encoder.blocks.4.0.conv_pwl       | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 240, 2, 2)  |          960 | (1, 72, 2, 2)   |          288 |            17280 |   69120 |\n",
      "| 158 | encoder.blocks.4.0.bn3.drop       | Identity               |                                                   | (1, 72, 2, 2)   |          288 | (1, 72, 2, 2)   |          288 |                0 |       0 |\n",
      "| 159 | encoder.blocks.4.0.bn3.act        | Identity               |                                                   | (1, 72, 2, 2)   |          288 | (1, 72, 2, 2)   |          288 |                0 |       0 |\n",
      "| 160 | encoder.blocks.4.0.bn3            | BatchNormAct2d         |                                                   | (1, 72, 2, 2)   |          288 | (1, 72, 2, 2)   |          288 |                0 |       0 |\n",
      "| 161 | encoder.blocks.4.0                | InvertedResidual       |                                                   | (1, 40, 4, 4)   |          640 | (1, 72, 2, 2)   |          288 |                0 |       0 |\n",
      "| 162 | encoder.blocks.4.1.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 72, 2, 2)   |          288 | (1, 432, 2, 2)  |         1728 |            31104 |  124416 |\n",
      "| 163 | encoder.blocks.4.1.bn1.drop       | Identity               |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 164 | encoder.blocks.4.1.bn1.act        | Hardswish              |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 165 | encoder.blocks.4.1.bn1            | BatchNormAct2d         |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 166 | encoder.blocks.4.1.conv_dw        | Conv2d                 | k=(5, 5), s=(1, 1), g=(432), dsc=(True), d=(1, 1) | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |            10800 |   43200 |\n",
      "| 167 | encoder.blocks.4.1.bn2.drop       | Identity               |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 168 | encoder.blocks.4.1.bn2.act        | Hardswish              |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 169 | encoder.blocks.4.1.bn2            | BatchNormAct2d         |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 170 | encoder.blocks.4.1.se.conv_reduce | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 432, 1, 1)  |          432 | (1, 112, 1, 1)  |          112 |            48384 |   48384 |\n",
      "| 171 | encoder.blocks.4.1.se.act1        | ReLU                   |                                                   | (1, 112, 1, 1)  |          112 | (1, 112, 1, 1)  |          112 |                0 |       0 |\n",
      "| 172 | encoder.blocks.4.1.se.conv_expand | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 112, 1, 1)  |          112 | (1, 432, 1, 1)  |          432 |            48384 |   48384 |\n",
      "| 173 | encoder.blocks.4.1.se.gate        | Hardsigmoid            |                                                   | (1, 432, 1, 1)  |          432 | (1, 432, 1, 1)  |          432 |                0 |       0 |\n",
      "| 174 | encoder.blocks.4.1.se             | SqueezeExcite          |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 175 | encoder.blocks.4.1.conv_pwl       | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 432, 2, 2)  |         1728 | (1, 72, 2, 2)   |          288 |            31104 |  124416 |\n",
      "| 176 | encoder.blocks.4.1.bn3.drop       | Identity               |                                                   | (1, 72, 2, 2)   |          288 | (1, 72, 2, 2)   |          288 |                0 |       0 |\n",
      "| 177 | encoder.blocks.4.1.bn3.act        | Identity               |                                                   | (1, 72, 2, 2)   |          288 | (1, 72, 2, 2)   |          288 |                0 |       0 |\n",
      "| 178 | encoder.blocks.4.1.bn3            | BatchNormAct2d         |                                                   | (1, 72, 2, 2)   |          288 | (1, 72, 2, 2)   |          288 |                0 |       0 |\n",
      "| 179 | encoder.blocks.4.1.drop_path      | DropPath               |                                                   | (1, 72, 2, 2)   |          288 | (1, 72, 2, 2)   |          288 |                0 |       0 |\n",
      "| 180 | encoder.blocks.4.1                | InvertedResidual       |                                                   | (1, 72, 2, 2)   |          288 | (1, 72, 2, 2)   |          288 |                0 |       0 |\n",
      "| 181 | encoder.blocks.4.2.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 72, 2, 2)   |          288 | (1, 432, 2, 2)  |         1728 |            31104 |  124416 |\n",
      "| 182 | encoder.blocks.4.2.bn1.drop       | Identity               |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 183 | encoder.blocks.4.2.bn1.act        | Hardswish              |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 184 | encoder.blocks.4.2.bn1            | BatchNormAct2d         |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 185 | encoder.blocks.4.2.conv_dw        | Conv2d                 | k=(5, 5), s=(1, 1), g=(432), dsc=(True), d=(1, 1) | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |            10800 |   43200 |\n",
      "| 186 | encoder.blocks.4.2.bn2.drop       | Identity               |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 187 | encoder.blocks.4.2.bn2.act        | Hardswish              |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 188 | encoder.blocks.4.2.bn2            | BatchNormAct2d         |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 189 | encoder.blocks.4.2.se.conv_reduce | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 432, 1, 1)  |          432 | (1, 112, 1, 1)  |          112 |            48384 |   48384 |\n",
      "| 190 | encoder.blocks.4.2.se.act1        | ReLU                   |                                                   | (1, 112, 1, 1)  |          112 | (1, 112, 1, 1)  |          112 |                0 |       0 |\n",
      "| 191 | encoder.blocks.4.2.se.conv_expand | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 112, 1, 1)  |          112 | (1, 432, 1, 1)  |          432 |            48384 |   48384 |\n",
      "| 192 | encoder.blocks.4.2.se.gate        | Hardsigmoid            |                                                   | (1, 432, 1, 1)  |          432 | (1, 432, 1, 1)  |          432 |                0 |       0 |\n",
      "| 193 | encoder.blocks.4.2.se             | SqueezeExcite          |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 194 | encoder.blocks.4.2.conv_pwl       | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 432, 2, 2)  |         1728 | (1, 72, 2, 2)   |          288 |            31104 |  124416 |\n",
      "| 195 | encoder.blocks.4.2.bn3.drop       | Identity               |                                                   | (1, 72, 2, 2)   |          288 | (1, 72, 2, 2)   |          288 |                0 |       0 |\n",
      "| 196 | encoder.blocks.4.2.bn3.act        | Identity               |                                                   | (1, 72, 2, 2)   |          288 | (1, 72, 2, 2)   |          288 |                0 |       0 |\n",
      "| 197 | encoder.blocks.4.2.bn3            | BatchNormAct2d         |                                                   | (1, 72, 2, 2)   |          288 | (1, 72, 2, 2)   |          288 |                0 |       0 |\n",
      "| 198 | encoder.blocks.4.2.drop_path      | DropPath               |                                                   | (1, 72, 2, 2)   |          288 | (1, 72, 2, 2)   |          288 |                0 |       0 |\n",
      "| 199 | encoder.blocks.4.2                | InvertedResidual       |                                                   | (1, 72, 2, 2)   |          288 | (1, 72, 2, 2)   |          288 |                0 |       0 |\n",
      "| 200 | encoder.blocks.4                  | Sequential             |                                                   | (1, 40, 4, 4)   |          640 | (1, 72, 2, 2)   |          288 |                0 |       0 |\n",
      "| 201 | encoder.blocks.5.0.conv           | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 72, 2, 2)   |          288 | (1, 432, 2, 2)  |         1728 |            31104 |  124416 |\n",
      "| 202 | encoder.blocks.5.0.bn1.drop       | Identity               |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 203 | encoder.blocks.5.0.bn1.act        | Hardswish              |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 204 | encoder.blocks.5.0.bn1            | BatchNormAct2d         |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 205 | encoder.blocks.5.0                | ConvBnAct              |                                                   | (1, 72, 2, 2)   |          288 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 206 | encoder.blocks.5                  | Sequential             |                                                   | (1, 72, 2, 2)   |          288 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 207 | encoder.blocks                    | Sequential             |                                                   | (1, 16, 32, 32) |        16384 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 208 | encoder.global_pool.pool          | Identity               |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 209 | encoder.global_pool.flatten       | Identity               |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 210 | encoder.global_pool               | SelectAdaptivePool2d   |                                                   | (1, 432, 2, 2)  |         1728 | (1, 432, 2, 2)  |         1728 |                0 |       0 |\n",
      "| 211 | encoder.conv_head                 | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 432, 2, 2)  |         1728 | (1, 1024, 2, 2) |         4096 |           442368 | 1769472 |\n",
      "| 212 | encoder.act2                      | Hardswish              |                                                   | (1, 1024, 2, 2) |         4096 | (1, 1024, 2, 2) |         4096 |                0 |       0 |\n",
      "| 213 | encoder.flatten                   | Identity               |                                                   | (1, 1024, 2, 2) |         4096 | (1, 1024, 2, 2) |         4096 |                0 |       0 |\n",
      "| 214 | encoder.classifier                | Identity               |                                                   | (1, 1024, 2, 2) |         4096 | (1, 1024, 2, 2) |         4096 |                0 |       0 |\n",
      "| 215 | encoder                           | MobileNetV3            |                                                   | (1, 3, 32, 32)  |         3072 | (1, 1024, 2, 2) |         4096 |                0 |       0 |\n",
      "| 216 | classifier.pooling                | AdaptiveAvgPool2d      |                                                   | (1, 1024, 2, 2) |         4096 | (1, 1024, 1, 1) |         1024 |                0 |       0 |\n",
      "| 217 | classifier.flatten                | Flatten                |                                                   | (1, 1024, 1, 1) |         1024 | (1, 1024)       |         1024 |                0 |       0 |\n",
      "| 218 | classifier.linear                 | Linear                 |                                                   | (1, 1024)       |         1024 | (1, 10)         |           10 |            10240 |   10240 |\n",
      "| 219 | classifier                        | DefaultClassifierHead  |                                                   | (1, 1024, 2, 2) |         4096 | (1, 10)         |           10 |                0 |       0 |\n",
      "+-----+-----------------------------------+------------------------+---------------------------------------------------+-----------------+--------------+-----------------+--------------+------------------+---------+\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:39,553\u001b[0m][\u001b[34mhannah.callbacks.summaries\u001b[0m][\u001b[32mINFO\u001b[0m] - Total MACs: 5,458,368\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:39,553\u001b[0m][\u001b[34mhannah.callbacks.summaries\u001b[0m][\u001b[32mINFO\u001b[0m] - Total Weights: 1,014,120\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:39,553\u001b[0m][\u001b[34mhannah.callbacks.summaries\u001b[0m][\u001b[32mINFO\u001b[0m] - Total Activations: 515,956\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:39,553\u001b[0m][\u001b[34mhannah.callbacks.summaries\u001b[0m][\u001b[32mINFO\u001b[0m] - Estimated Activations: 36,864\u001b[0m\n",
      "Testing DataLoader 0: 100%|███████████████████████| 4/4 [00:00<00:00, 10.57it/s]\n",
      "[\u001b[36m2024-02-29 16:20:39,554\u001b[0m][\u001b[34mhannah.datasets.base\u001b[0m][\u001b[33mWARNING\u001b[0m] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:39,554\u001b[0m][\u001b[34mhannah.datasets.base\u001b[0m][\u001b[33mWARNING\u001b[0m] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:39,791\u001b[0m][\u001b[34mhannah.datasets.base\u001b[0m][\u001b[33mWARNING\u001b[0m] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:39,893\u001b[0m][\u001b[34mhannah.datasets.base\u001b[0m][\u001b[33mWARNING\u001b[0m] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:40,037\u001b[0m][\u001b[34mhannah.train\u001b[0m][\u001b[32mINFO\u001b[0m] - Averaged Result Metrics:\n",
      "| Metric               |     Mean |   Std |   Count |\n",
      "|----------------------|----------|-------|---------|\n",
      "| test_classifier_loss | 0.632001 |     0 |       1 |\n",
      "| test_accuracy        | 0.782471 |     0 |       1 |\n",
      "| test_error           | 0.217529 |     0 |       1 |\n",
      "| test_f1              | 0.782036 |     0 |       1 |\n",
      "| test_precision       | 0.781485 |     0 |       1 |\n",
      "| test_recall          | 0.783115 |     0 |       1 |\n",
      "| test_loss            | 0.632001 |     0 |       1 |\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:40,048\u001b[0m][\u001b[34mhannah.train\u001b[0m][\u001b[32mINFO\u001b[0m] - Averaged Result Metrics:\n",
      "| Metric              |     Mean |   Std |   Count |\n",
      "|---------------------|----------|-------|---------|\n",
      "| val_classifier_loss | 0.643386 |     0 |       1 |\n",
      "| val_accuracy        | 0.77417  |     0 |       1 |\n",
      "| val_error           | 0.22583  |     0 |       1 |\n",
      "| val_f1              | 0.772275 |     0 |       1 |\n",
      "| val_precision       | 0.772212 |     0 |       1 |\n",
      "| val_recall          | 0.772874 |     0 |       1 |\n",
      "| val_loss            | 0.643386 |     0 |       1 |\u001b[0m\n",
      "[2024-02-29 16:20:40,052][HYDRA] \t#2 : model=timm_mobilenetv3_small_100 +experiment=sweep_models\n",
      "\n",
      " **                                            **\n",
      "/**                                           /**\n",
      "/**       ******   *******  *******   ******  /**\n",
      "/******  //////** //**///**//**///** //////** /******\n",
      "/**///**  *******  /**  /** /**  /**  ******* /**///**\n",
      "/**  /** **////**  /**  /** /**  /** **////** /**  /**\n",
      "/**  /**//******** ***  /** ***  /**//********/**  /**\n",
      "//   //  //////// ///   // ///   //  //////// //   //\n",
      "\n",
      "[\u001b[36m2024-02-29 16:20:40,379\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] - Environment info:\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:40,379\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   Number of GPUs: 2\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:40,379\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   CUDA version: 12.1\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:40,379\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   CUDNN version: 8907\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:40,379\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   Kernel: 4.18.0-513.11.1.el8_9.x86_64\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:40,379\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:40,379\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   PyTorch: 2.1.2+cu121\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:40,379\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   Pytorch Lightning: 2.1.3\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:40,379\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   Numpy: 1.23.5\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:40,379\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   Hannah version info:\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:40,379\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -     Cannot find a Git repository.  You probably downloaded an archive\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:40,380\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train +experiment=sweep_models\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:40,380\u001b[0m][\u001b[34mhannah.utils.utils\u001b[0m][\u001b[32mINFO\u001b[0m] -   \u001b[0m\n",
      "INFO: Seed set to 1234\n",
      "[\u001b[36m2024-02-29 16:20:40,380\u001b[0m][\u001b[34mlightning.fabric.utilities.seed\u001b[0m][\u001b[32mINFO\u001b[0m] - Seed set to 1234\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:40,380\u001b[0m][\u001b[34mroot\u001b[0m][\u001b[32mINFO\u001b[0m] - Configuration: \u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:40,383\u001b[0m][\u001b[34mroot\u001b[0m][\u001b[32mINFO\u001b[0m] - dataset:\n",
      "  data_folder: ${hydra:runtime.cwd}/datasets/\n",
      "  cls: hannah.datasets.vision.Cifar10Dataset\n",
      "  dataset: cifar10\n",
      "  val_percent: 0.1\n",
      "features:\n",
      "  _target_: torch.nn.Identity\n",
      "model:\n",
      "  _target_: hannah.models.timm.TimmModel\n",
      "  name: mobilenetv3_small_100\n",
      "  drop_rate: 0.3\n",
      "  drop_path_rate: 0.2\n",
      "scheduler:\n",
      "  _target_: torch.optim.lr_scheduler.OneCycleLR\n",
      "  max_lr: ${optimizer.lr}\n",
      "  pct_start: 0.3\n",
      "  anneal_strategy: cos\n",
      "  cycle_momentum: true\n",
      "  base_momentum: 0.85\n",
      "  max_momentum: 0.95\n",
      "  div_factor: 25.0\n",
      "  final_div_factor: 10000.0\n",
      "  last_epoch: -1\n",
      "optimizer:\n",
      "  _target_: torch.optim.sgd.SGD\n",
      "  lr: 0.3\n",
      "  momentum: 0.9\n",
      "  dampening: 0\n",
      "  weight_decay: 0.0005\n",
      "  nesterov: false\n",
      "module:\n",
      "  _target_: hannah.modules.vision.ImageClassifierModule\n",
      "  num_workers: 0\n",
      "  batch_size: 2048\n",
      "  shuffle_all_dataloaders: false\n",
      "trainer:\n",
      "  _target_: pytorch_lightning.trainer.Trainer\n",
      "  accelerator: auto\n",
      "  devices: 1\n",
      "  limit_train_batches: 1.0\n",
      "  limit_val_batches: 1.0\n",
      "  limit_test_batches: 1.0\n",
      "  max_epochs: 50\n",
      "  default_root_dir: .\n",
      "  fast_dev_run: false\n",
      "  overfit_batches: 0.0\n",
      "  benchmark: false\n",
      "  deterministic: warn\n",
      "  gradient_clip_val: 0\n",
      "  accumulate_grad_batches: 1\n",
      "  plugins: null\n",
      "  strategy: auto\n",
      "  reload_dataloaders_every_n_epochs: 0\n",
      "  precision: 16\n",
      "  enable_model_summary: false\n",
      "checkpoint:\n",
      "  _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
      "  dirpath: checkpoints\n",
      "  save_top_k: 1\n",
      "  verbose: true\n",
      "  monitor: val_error\n",
      "  mode: min\n",
      "  save_last: true\n",
      "augmentation:\n",
      "  batch_augment:\n",
      "    pipeline: null\n",
      "    transforms:\n",
      "      RandomHorizontalFlip:\n",
      "        p: 0.5\n",
      "      RandomAffine:\n",
      "        degrees:\n",
      "        - -15\n",
      "        - 15\n",
      "        translate:\n",
      "        - 0.1\n",
      "        - 0.1\n",
      "        scale:\n",
      "        - 0.9\n",
      "        - 1.1\n",
      "        shear:\n",
      "        - -5\n",
      "        - 5\n",
      "        p: 0.5\n",
      "      RandomCrop:\n",
      "        size:\n",
      "        - 32\n",
      "        - 32\n",
      "        padding: 4\n",
      "      RandomErasing:\n",
      "        p: 0.5\n",
      "experiment_id: sweep_models\n",
      "output_dir: trained_models\n",
      "auto_lr: false\n",
      "resume: false\n",
      "fx_mac_summary: false\n",
      "skip_test: false\n",
      "skip_val: false\n",
      "seed:\n",
      "- 1234\n",
      "validate_output: false\n",
      "monitor:\n",
      "  metric: val_accuracy\n",
      "  direction: maximize\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:40,383\u001b[0m][\u001b[34mroot\u001b[0m][\u001b[32mINFO\u001b[0m] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_100\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:40,389\u001b[0m][\u001b[34mhannah.callbacks.optimization\u001b[0m][\u001b[32mINFO\u001b[0m] - Monitoring the following values for optimization\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:40,389\u001b[0m][\u001b[34mhannah.callbacks.optimization\u001b[0m][\u001b[32mINFO\u001b[0m] -   - val_accuracy direction: maximize(-1)\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:40,393\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:558: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:40,393\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Using 16bit Automatic Mixed Precision (AMP)\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:40,402\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - GPU available: True (cuda), used: True\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:40,403\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - TPU available: False, using: 0 TPU cores\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:40,403\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - IPU available: False, using: 0 IPUs\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:40,403\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - HPU available: False, using: 0 HPUs\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:40,403\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:40,403\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:40,403\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:40,403\u001b[0m][\u001b[34mroot\u001b[0m][\u001b[32mINFO\u001b[0m] - Starting training\u001b[0m\n",
      "Files already downloaded and verified\n",
      "[\u001b[36m2024-02-29 16:20:41,596\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/hannah/hannah/modules/vision/base.py:66: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None\n",
      "  warnings.warn(\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:41,596\u001b[0m][\u001b[34mhannah.modules.vision.base\u001b[0m][\u001b[32mINFO\u001b[0m] - Dataset lengths:\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:41,596\u001b[0m][\u001b[34mhannah.modules.vision.base\u001b[0m][\u001b[32mINFO\u001b[0m] -   Train Set (Labeled): 45000\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:41,597\u001b[0m][\u001b[34mhannah.modules.vision.base\u001b[0m][\u001b[32mINFO\u001b[0m] -   Train Set (Unlabled): 0\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:41,597\u001b[0m][\u001b[34mhannah.modules.vision.base\u001b[0m][\u001b[32mINFO\u001b[0m] -   Dev Set: 5000\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:41,597\u001b[0m][\u001b[34mhannah.modules.vision.base\u001b[0m][\u001b[32mINFO\u001b[0m] -   Test Set: 10000\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:41,597\u001b[0m][\u001b[34mhannah.modules.vision.base\u001b[0m][\u001b[32mINFO\u001b[0m] - Setting up model mobilenetv3_small_100\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:41,622\u001b[0m][\u001b[34mhannah.models.timm\u001b[0m][\u001b[32mINFO\u001b[0m] - Using default logger for automatic stem creation\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:41,622\u001b[0m][\u001b[34mhannah.models.timm\u001b[0m][\u001b[32mINFO\u001b[0m] - Small input size detected trying to adopt small input size\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:41,632\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:41,632\u001b[0m][\u001b[34mhannah.modules.vision.base\u001b[0m][\u001b[32mINFO\u001b[0m] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:41,638\u001b[0m][\u001b[34mhannah.modules.vision.base\u001b[0m][\u001b[32mINFO\u001b[0m] - Running dummy forward to initialize lazy modules\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:41,655\u001b[0m][\u001b[34mpytorch_lightning.accelerators.cuda\u001b[0m][\u001b[32mINFO\u001b[0m] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:41,657\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading `train_dataloader` to estimate number of stepping batches.\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:41,658\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=191` in the `DataLoader` to improve performance.\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:41,658\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:41,911\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/hannah/hannah/models/timm.py:313: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  decoded = torch.tensor([])\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:41,911\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/hannah/hannah/models/timm.py:317: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  logits = torch.tensor([])\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:41,998\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/hannah/hannah/models/timm.py:321: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  projection = torch.tensor([])\n",
      "\u001b[0m\n",
      "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s][\u001b[36m2024-02-29 16:20:42,491\u001b[0m][\u001b[34mpy.warnings\u001b[0m][\u001b[33mWARNING\u001b[0m] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=191` in the `DataLoader` to improve performance.\n",
      "\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:42,825\u001b[0m][\u001b[34mhannah.callbacks.summaries\u001b[0m][\u001b[32mINFO\u001b[0m] - \n",
      "+-----+-----------------------------------+------------------------+---------------------------------------------------+-----------------+--------------+-----------------+--------------+------------------+---------+\n",
      "|     | Name                              | Type                   | Attrs                                             | IFM             |   IFM volume | OFM             |   OFM volume |   Weights volume |    MACs |\n",
      "|-----+-----------------------------------+------------------------+---------------------------------------------------+-----------------+--------------+-----------------+--------------+------------------+---------|\n",
      "|   0 | encoder.conv_stem                 | Conv2d                 | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 3, 32, 32)  |         3072 | (1, 16, 32, 32) |        16384 |              432 |  442368 |\n",
      "|   1 | encoder.bn1.drop                  | Identity               |                                                   | (1, 16, 32, 32) |        16384 | (1, 16, 32, 32) |        16384 |                0 |       0 |\n",
      "|   2 | encoder.bn1.act                   | Hardswish              |                                                   | (1, 16, 32, 32) |        16384 | (1, 16, 32, 32) |        16384 |                0 |       0 |\n",
      "|   3 | encoder.bn1                       | BatchNormAct2d         |                                                   | (1, 16, 32, 32) |        16384 | (1, 16, 32, 32) |        16384 |                0 |       0 |\n",
      "|   4 | encoder.blocks.0.0.conv_dw        | Conv2d                 | k=(3, 3), s=(2, 2), g=(16), dsc=(True), d=(1, 1)  | (1, 16, 32, 32) |        16384 | (1, 16, 16, 16) |         4096 |              144 |   36864 |\n",
      "|   5 | encoder.blocks.0.0.bn1.drop       | Identity               |                                                   | (1, 16, 16, 16) |         4096 | (1, 16, 16, 16) |         4096 |                0 |       0 |\n",
      "|   6 | encoder.blocks.0.0.bn1.act        | ReLU                   |                                                   | (1, 16, 16, 16) |         4096 | (1, 16, 16, 16) |         4096 |                0 |       0 |\n",
      "|   7 | encoder.blocks.0.0.bn1            | BatchNormAct2d         |                                                   | (1, 16, 16, 16) |         4096 | (1, 16, 16, 16) |         4096 |                0 |       0 |\n",
      "|   8 | encoder.blocks.0.0.se.conv_reduce | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 16, 1, 1)   |           16 | (1, 8, 1, 1)    |            8 |              128 |     128 |\n",
      "|   9 | encoder.blocks.0.0.se.act1        | ReLU                   |                                                   | (1, 8, 1, 1)    |            8 | (1, 8, 1, 1)    |            8 |                0 |       0 |\n",
      "|  10 | encoder.blocks.0.0.se.conv_expand | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 8, 1, 1)    |            8 | (1, 16, 1, 1)   |           16 |              128 |     128 |\n",
      "|  11 | encoder.blocks.0.0.se.gate        | Hardsigmoid            |                                                   | (1, 16, 1, 1)   |           16 | (1, 16, 1, 1)   |           16 |                0 |       0 |\n",
      "|  12 | encoder.blocks.0.0.se             | SqueezeExcite          |                                                   | (1, 16, 16, 16) |         4096 | (1, 16, 16, 16) |         4096 |                0 |       0 |\n",
      "|  13 | encoder.blocks.0.0.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 16, 16, 16) |         4096 | (1, 16, 16, 16) |         4096 |              256 |   65536 |\n",
      "|  14 | encoder.blocks.0.0.bn2.drop       | Identity               |                                                   | (1, 16, 16, 16) |         4096 | (1, 16, 16, 16) |         4096 |                0 |       0 |\n",
      "|  15 | encoder.blocks.0.0.bn2.act        | Identity               |                                                   | (1, 16, 16, 16) |         4096 | (1, 16, 16, 16) |         4096 |                0 |       0 |\n",
      "|  16 | encoder.blocks.0.0.bn2            | BatchNormAct2d         |                                                   | (1, 16, 16, 16) |         4096 | (1, 16, 16, 16) |         4096 |                0 |       0 |\n",
      "|  17 | encoder.blocks.0.0                | DepthwiseSeparableConv |                                                   | (1, 16, 32, 32) |        16384 | (1, 16, 16, 16) |         4096 |                0 |       0 |\n",
      "|  18 | encoder.blocks.0                  | Sequential             |                                                   | (1, 16, 32, 32) |        16384 | (1, 16, 16, 16) |         4096 |                0 |       0 |\n",
      "|  19 | encoder.blocks.1.0.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 16, 16, 16) |         4096 | (1, 72, 16, 16) |        18432 |             1152 |  294912 |\n",
      "|  20 | encoder.blocks.1.0.bn1.drop       | Identity               |                                                   | (1, 72, 16, 16) |        18432 | (1, 72, 16, 16) |        18432 |                0 |       0 |\n",
      "|  21 | encoder.blocks.1.0.bn1.act        | ReLU                   |                                                   | (1, 72, 16, 16) |        18432 | (1, 72, 16, 16) |        18432 |                0 |       0 |\n",
      "|  22 | encoder.blocks.1.0.bn1            | BatchNormAct2d         |                                                   | (1, 72, 16, 16) |        18432 | (1, 72, 16, 16) |        18432 |                0 |       0 |\n",
      "|  23 | encoder.blocks.1.0.conv_dw        | Conv2d                 | k=(3, 3), s=(2, 2), g=(72), dsc=(True), d=(1, 1)  | (1, 72, 16, 16) |        18432 | (1, 72, 8, 8)   |         4608 |              648 |   41472 |\n",
      "|  24 | encoder.blocks.1.0.bn2.drop       | Identity               |                                                   | (1, 72, 8, 8)   |         4608 | (1, 72, 8, 8)   |         4608 |                0 |       0 |\n",
      "|  25 | encoder.blocks.1.0.bn2.act        | ReLU                   |                                                   | (1, 72, 8, 8)   |         4608 | (1, 72, 8, 8)   |         4608 |                0 |       0 |\n",
      "|  26 | encoder.blocks.1.0.bn2            | BatchNormAct2d         |                                                   | (1, 72, 8, 8)   |         4608 | (1, 72, 8, 8)   |         4608 |                0 |       0 |\n",
      "|  27 | encoder.blocks.1.0.se             | Identity               |                                                   | (1, 72, 8, 8)   |         4608 | (1, 72, 8, 8)   |         4608 |                0 |       0 |\n",
      "|  28 | encoder.blocks.1.0.conv_pwl       | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 72, 8, 8)   |         4608 | (1, 24, 8, 8)   |         1536 |             1728 |  110592 |\n",
      "|  29 | encoder.blocks.1.0.bn3.drop       | Identity               |                                                   | (1, 24, 8, 8)   |         1536 | (1, 24, 8, 8)   |         1536 |                0 |       0 |\n",
      "|  30 | encoder.blocks.1.0.bn3.act        | Identity               |                                                   | (1, 24, 8, 8)   |         1536 | (1, 24, 8, 8)   |         1536 |                0 |       0 |\n",
      "|  31 | encoder.blocks.1.0.bn3            | BatchNormAct2d         |                                                   | (1, 24, 8, 8)   |         1536 | (1, 24, 8, 8)   |         1536 |                0 |       0 |\n",
      "|  32 | encoder.blocks.1.0                | InvertedResidual       |                                                   | (1, 16, 16, 16) |         4096 | (1, 24, 8, 8)   |         1536 |                0 |       0 |\n",
      "|  33 | encoder.blocks.1.1.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 24, 8, 8)   |         1536 | (1, 88, 8, 8)   |         5632 |             2112 |  135168 |\n",
      "|  34 | encoder.blocks.1.1.bn1.drop       | Identity               |                                                   | (1, 88, 8, 8)   |         5632 | (1, 88, 8, 8)   |         5632 |                0 |       0 |\n",
      "|  35 | encoder.blocks.1.1.bn1.act        | ReLU                   |                                                   | (1, 88, 8, 8)   |         5632 | (1, 88, 8, 8)   |         5632 |                0 |       0 |\n",
      "|  36 | encoder.blocks.1.1.bn1            | BatchNormAct2d         |                                                   | (1, 88, 8, 8)   |         5632 | (1, 88, 8, 8)   |         5632 |                0 |       0 |\n",
      "|  37 | encoder.blocks.1.1.conv_dw        | Conv2d                 | k=(3, 3), s=(1, 1), g=(88), dsc=(True), d=(1, 1)  | (1, 88, 8, 8)   |         5632 | (1, 88, 8, 8)   |         5632 |              792 |   50688 |\n",
      "|  38 | encoder.blocks.1.1.bn2.drop       | Identity               |                                                   | (1, 88, 8, 8)   |         5632 | (1, 88, 8, 8)   |         5632 |                0 |       0 |\n",
      "|  39 | encoder.blocks.1.1.bn2.act        | ReLU                   |                                                   | (1, 88, 8, 8)   |         5632 | (1, 88, 8, 8)   |         5632 |                0 |       0 |\n",
      "|  40 | encoder.blocks.1.1.bn2            | BatchNormAct2d         |                                                   | (1, 88, 8, 8)   |         5632 | (1, 88, 8, 8)   |         5632 |                0 |       0 |\n",
      "|  41 | encoder.blocks.1.1.se             | Identity               |                                                   | (1, 88, 8, 8)   |         5632 | (1, 88, 8, 8)   |         5632 |                0 |       0 |\n",
      "|  42 | encoder.blocks.1.1.conv_pwl       | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 88, 8, 8)   |         5632 | (1, 24, 8, 8)   |         1536 |             2112 |  135168 |\n",
      "|  43 | encoder.blocks.1.1.bn3.drop       | Identity               |                                                   | (1, 24, 8, 8)   |         1536 | (1, 24, 8, 8)   |         1536 |                0 |       0 |\n",
      "|  44 | encoder.blocks.1.1.bn3.act        | Identity               |                                                   | (1, 24, 8, 8)   |         1536 | (1, 24, 8, 8)   |         1536 |                0 |       0 |\n",
      "|  45 | encoder.blocks.1.1.bn3            | BatchNormAct2d         |                                                   | (1, 24, 8, 8)   |         1536 | (1, 24, 8, 8)   |         1536 |                0 |       0 |\n",
      "|  46 | encoder.blocks.1.1.drop_path      | DropPath               |                                                   | (1, 24, 8, 8)   |         1536 | (1, 24, 8, 8)   |         1536 |                0 |       0 |\n",
      "|  47 | encoder.blocks.1.1                | InvertedResidual       |                                                   | (1, 24, 8, 8)   |         1536 | (1, 24, 8, 8)   |         1536 |                0 |       0 |\n",
      "|  48 | encoder.blocks.1                  | Sequential             |                                                   | (1, 16, 16, 16) |         4096 | (1, 24, 8, 8)   |         1536 |                0 |       0 |\n",
      "|  49 | encoder.blocks.2.0.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 24, 8, 8)   |         1536 | (1, 96, 8, 8)   |         6144 |             2304 |  147456 |\n",
      "|  50 | encoder.blocks.2.0.bn1.drop       | Identity               |                                                   | (1, 96, 8, 8)   |         6144 | (1, 96, 8, 8)   |         6144 |                0 |       0 |\n",
      "|  51 | encoder.blocks.2.0.bn1.act        | Hardswish              |                                                   | (1, 96, 8, 8)   |         6144 | (1, 96, 8, 8)   |         6144 |                0 |       0 |\n",
      "|  52 | encoder.blocks.2.0.bn1            | BatchNormAct2d         |                                                   | (1, 96, 8, 8)   |         6144 | (1, 96, 8, 8)   |         6144 |                0 |       0 |\n",
      "|  53 | encoder.blocks.2.0.conv_dw        | Conv2d                 | k=(5, 5), s=(2, 2), g=(96), dsc=(True), d=(1, 1)  | (1, 96, 8, 8)   |         6144 | (1, 96, 4, 4)   |         1536 |             2400 |   38400 |\n",
      "|  54 | encoder.blocks.2.0.bn2.drop       | Identity               |                                                   | (1, 96, 4, 4)   |         1536 | (1, 96, 4, 4)   |         1536 |                0 |       0 |\n",
      "|  55 | encoder.blocks.2.0.bn2.act        | Hardswish              |                                                   | (1, 96, 4, 4)   |         1536 | (1, 96, 4, 4)   |         1536 |                0 |       0 |\n",
      "|  56 | encoder.blocks.2.0.bn2            | BatchNormAct2d         |                                                   | (1, 96, 4, 4)   |         1536 | (1, 96, 4, 4)   |         1536 |                0 |       0 |\n",
      "|  57 | encoder.blocks.2.0.se.conv_reduce | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 96, 1, 1)   |           96 | (1, 24, 1, 1)   |           24 |             2304 |    2304 |\n",
      "|  58 | encoder.blocks.2.0.se.act1        | ReLU                   |                                                   | (1, 24, 1, 1)   |           24 | (1, 24, 1, 1)   |           24 |                0 |       0 |\n",
      "|  59 | encoder.blocks.2.0.se.conv_expand | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 24, 1, 1)   |           24 | (1, 96, 1, 1)   |           96 |             2304 |    2304 |\n",
      "|  60 | encoder.blocks.2.0.se.gate        | Hardsigmoid            |                                                   | (1, 96, 1, 1)   |           96 | (1, 96, 1, 1)   |           96 |                0 |       0 |\n",
      "|  61 | encoder.blocks.2.0.se             | SqueezeExcite          |                                                   | (1, 96, 4, 4)   |         1536 | (1, 96, 4, 4)   |         1536 |                0 |       0 |\n",
      "|  62 | encoder.blocks.2.0.conv_pwl       | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 96, 4, 4)   |         1536 | (1, 40, 4, 4)   |          640 |             3840 |   61440 |\n",
      "|  63 | encoder.blocks.2.0.bn3.drop       | Identity               |                                                   | (1, 40, 4, 4)   |          640 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "|  64 | encoder.blocks.2.0.bn3.act        | Identity               |                                                   | (1, 40, 4, 4)   |          640 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "|  65 | encoder.blocks.2.0.bn3            | BatchNormAct2d         |                                                   | (1, 40, 4, 4)   |          640 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "|  66 | encoder.blocks.2.0                | InvertedResidual       |                                                   | (1, 24, 8, 8)   |         1536 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "|  67 | encoder.blocks.2.1.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 40, 4, 4)   |          640 | (1, 240, 4, 4)  |         3840 |             9600 |  153600 |\n",
      "|  68 | encoder.blocks.2.1.bn1.drop       | Identity               |                                                   | (1, 240, 4, 4)  |         3840 | (1, 240, 4, 4)  |         3840 |                0 |       0 |\n",
      "|  69 | encoder.blocks.2.1.bn1.act        | Hardswish              |                                                   | (1, 240, 4, 4)  |         3840 | (1, 240, 4, 4)  |         3840 |                0 |       0 |\n",
      "|  70 | encoder.blocks.2.1.bn1            | BatchNormAct2d         |                                                   | (1, 240, 4, 4)  |         3840 | (1, 240, 4, 4)  |         3840 |                0 |       0 |\n",
      "|  71 | encoder.blocks.2.1.conv_dw        | Conv2d                 | k=(5, 5), s=(1, 1), g=(240), dsc=(True), d=(1, 1) | (1, 240, 4, 4)  |         3840 | (1, 240, 4, 4)  |         3840 |             6000 |   96000 |\n",
      "|  72 | encoder.blocks.2.1.bn2.drop       | Identity               |                                                   | (1, 240, 4, 4)  |         3840 | (1, 240, 4, 4)  |         3840 |                0 |       0 |\n",
      "|  73 | encoder.blocks.2.1.bn2.act        | Hardswish              |                                                   | (1, 240, 4, 4)  |         3840 | (1, 240, 4, 4)  |         3840 |                0 |       0 |\n",
      "|  74 | encoder.blocks.2.1.bn2            | BatchNormAct2d         |                                                   | (1, 240, 4, 4)  |         3840 | (1, 240, 4, 4)  |         3840 |                0 |       0 |\n",
      "|  75 | encoder.blocks.2.1.se.conv_reduce | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 240, 1, 1)  |          240 | (1, 64, 1, 1)   |           64 |            15360 |   15360 |\n",
      "|  76 | encoder.blocks.2.1.se.act1        | ReLU                   |                                                   | (1, 64, 1, 1)   |           64 | (1, 64, 1, 1)   |           64 |                0 |       0 |\n",
      "|  77 | encoder.blocks.2.1.se.conv_expand | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 64, 1, 1)   |           64 | (1, 240, 1, 1)  |          240 |            15360 |   15360 |\n",
      "|  78 | encoder.blocks.2.1.se.gate        | Hardsigmoid            |                                                   | (1, 240, 1, 1)  |          240 | (1, 240, 1, 1)  |          240 |                0 |       0 |\n",
      "|  79 | encoder.blocks.2.1.se             | SqueezeExcite          |                                                   | (1, 240, 4, 4)  |         3840 | (1, 240, 4, 4)  |         3840 |                0 |       0 |\n",
      "|  80 | encoder.blocks.2.1.conv_pwl       | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 240, 4, 4)  |         3840 | (1, 40, 4, 4)   |          640 |             9600 |  153600 |\n",
      "|  81 | encoder.blocks.2.1.bn3.drop       | Identity               |                                                   | (1, 40, 4, 4)   |          640 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "|  82 | encoder.blocks.2.1.bn3.act        | Identity               |                                                   | (1, 40, 4, 4)   |          640 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "|  83 | encoder.blocks.2.1.bn3            | BatchNormAct2d         |                                                   | (1, 40, 4, 4)   |          640 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "|  84 | encoder.blocks.2.1.drop_path      | DropPath               |                                                   | (1, 40, 4, 4)   |          640 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "|  85 | encoder.blocks.2.1                | InvertedResidual       |                                                   | (1, 40, 4, 4)   |          640 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "|  86 | encoder.blocks.2.2.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 40, 4, 4)   |          640 | (1, 240, 4, 4)  |         3840 |             9600 |  153600 |\n",
      "|  87 | encoder.blocks.2.2.bn1.drop       | Identity               |                                                   | (1, 240, 4, 4)  |         3840 | (1, 240, 4, 4)  |         3840 |                0 |       0 |\n",
      "|  88 | encoder.blocks.2.2.bn1.act        | Hardswish              |                                                   | (1, 240, 4, 4)  |         3840 | (1, 240, 4, 4)  |         3840 |                0 |       0 |\n",
      "|  89 | encoder.blocks.2.2.bn1            | BatchNormAct2d         |                                                   | (1, 240, 4, 4)  |         3840 | (1, 240, 4, 4)  |         3840 |                0 |       0 |\n",
      "|  90 | encoder.blocks.2.2.conv_dw        | Conv2d                 | k=(5, 5), s=(1, 1), g=(240), dsc=(True), d=(1, 1) | (1, 240, 4, 4)  |         3840 | (1, 240, 4, 4)  |         3840 |             6000 |   96000 |\n",
      "|  91 | encoder.blocks.2.2.bn2.drop       | Identity               |                                                   | (1, 240, 4, 4)  |         3840 | (1, 240, 4, 4)  |         3840 |                0 |       0 |\n",
      "|  92 | encoder.blocks.2.2.bn2.act        | Hardswish              |                                                   | (1, 240, 4, 4)  |         3840 | (1, 240, 4, 4)  |         3840 |                0 |       0 |\n",
      "|  93 | encoder.blocks.2.2.bn2            | BatchNormAct2d         |                                                   | (1, 240, 4, 4)  |         3840 | (1, 240, 4, 4)  |         3840 |                0 |       0 |\n",
      "|  94 | encoder.blocks.2.2.se.conv_reduce | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 240, 1, 1)  |          240 | (1, 64, 1, 1)   |           64 |            15360 |   15360 |\n",
      "|  95 | encoder.blocks.2.2.se.act1        | ReLU                   |                                                   | (1, 64, 1, 1)   |           64 | (1, 64, 1, 1)   |           64 |                0 |       0 |\n",
      "|  96 | encoder.blocks.2.2.se.conv_expand | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 64, 1, 1)   |           64 | (1, 240, 1, 1)  |          240 |            15360 |   15360 |\n",
      "|  97 | encoder.blocks.2.2.se.gate        | Hardsigmoid            |                                                   | (1, 240, 1, 1)  |          240 | (1, 240, 1, 1)  |          240 |                0 |       0 |\n",
      "|  98 | encoder.blocks.2.2.se             | SqueezeExcite          |                                                   | (1, 240, 4, 4)  |         3840 | (1, 240, 4, 4)  |         3840 |                0 |       0 |\n",
      "|  99 | encoder.blocks.2.2.conv_pwl       | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 240, 4, 4)  |         3840 | (1, 40, 4, 4)   |          640 |             9600 |  153600 |\n",
      "| 100 | encoder.blocks.2.2.bn3.drop       | Identity               |                                                   | (1, 40, 4, 4)   |          640 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "| 101 | encoder.blocks.2.2.bn3.act        | Identity               |                                                   | (1, 40, 4, 4)   |          640 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "| 102 | encoder.blocks.2.2.bn3            | BatchNormAct2d         |                                                   | (1, 40, 4, 4)   |          640 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "| 103 | encoder.blocks.2.2.drop_path      | DropPath               |                                                   | (1, 40, 4, 4)   |          640 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "| 104 | encoder.blocks.2.2                | InvertedResidual       |                                                   | (1, 40, 4, 4)   |          640 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "| 105 | encoder.blocks.2                  | Sequential             |                                                   | (1, 24, 8, 8)   |         1536 | (1, 40, 4, 4)   |          640 |                0 |       0 |\n",
      "| 106 | encoder.blocks.3.0.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 40, 4, 4)   |          640 | (1, 120, 4, 4)  |         1920 |             4800 |   76800 |\n",
      "| 107 | encoder.blocks.3.0.bn1.drop       | Identity               |                                                   | (1, 120, 4, 4)  |         1920 | (1, 120, 4, 4)  |         1920 |                0 |       0 |\n",
      "| 108 | encoder.blocks.3.0.bn1.act        | Hardswish              |                                                   | (1, 120, 4, 4)  |         1920 | (1, 120, 4, 4)  |         1920 |                0 |       0 |\n",
      "| 109 | encoder.blocks.3.0.bn1            | BatchNormAct2d         |                                                   | (1, 120, 4, 4)  |         1920 | (1, 120, 4, 4)  |         1920 |                0 |       0 |\n",
      "| 110 | encoder.blocks.3.0.conv_dw        | Conv2d                 | k=(5, 5), s=(1, 1), g=(120), dsc=(True), d=(1, 1) | (1, 120, 4, 4)  |         1920 | (1, 120, 4, 4)  |         1920 |             3000 |   48000 |\n",
      "| 111 | encoder.blocks.3.0.bn2.drop       | Identity               |                                                   | (1, 120, 4, 4)  |         1920 | (1, 120, 4, 4)  |         1920 |                0 |       0 |\n",
      "| 112 | encoder.blocks.3.0.bn2.act        | Hardswish              |                                                   | (1, 120, 4, 4)  |         1920 | (1, 120, 4, 4)  |         1920 |                0 |       0 |\n",
      "| 113 | encoder.blocks.3.0.bn2            | BatchNormAct2d         |                                                   | (1, 120, 4, 4)  |         1920 | (1, 120, 4, 4)  |         1920 |                0 |       0 |\n",
      "| 114 | encoder.blocks.3.0.se.conv_reduce | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 120, 1, 1)  |          120 | (1, 32, 1, 1)   |           32 |             3840 |    3840 |\n",
      "| 115 | encoder.blocks.3.0.se.act1        | ReLU                   |                                                   | (1, 32, 1, 1)   |           32 | (1, 32, 1, 1)   |           32 |                0 |       0 |\n",
      "| 116 | encoder.blocks.3.0.se.conv_expand | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 32, 1, 1)   |           32 | (1, 120, 1, 1)  |          120 |             3840 |    3840 |\n",
      "| 117 | encoder.blocks.3.0.se.gate        | Hardsigmoid            |                                                   | (1, 120, 1, 1)  |          120 | (1, 120, 1, 1)  |          120 |                0 |       0 |\n",
      "| 118 | encoder.blocks.3.0.se             | SqueezeExcite          |                                                   | (1, 120, 4, 4)  |         1920 | (1, 120, 4, 4)  |         1920 |                0 |       0 |\n",
      "| 119 | encoder.blocks.3.0.conv_pwl       | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 120, 4, 4)  |         1920 | (1, 48, 4, 4)   |          768 |             5760 |   92160 |\n",
      "| 120 | encoder.blocks.3.0.bn3.drop       | Identity               |                                                   | (1, 48, 4, 4)   |          768 | (1, 48, 4, 4)   |          768 |                0 |       0 |\n",
      "| 121 | encoder.blocks.3.0.bn3.act        | Identity               |                                                   | (1, 48, 4, 4)   |          768 | (1, 48, 4, 4)   |          768 |                0 |       0 |\n",
      "| 122 | encoder.blocks.3.0.bn3            | BatchNormAct2d         |                                                   | (1, 48, 4, 4)   |          768 | (1, 48, 4, 4)   |          768 |                0 |       0 |\n",
      "| 123 | encoder.blocks.3.0                | InvertedResidual       |                                                   | (1, 40, 4, 4)   |          640 | (1, 48, 4, 4)   |          768 |                0 |       0 |\n",
      "| 124 | encoder.blocks.3.1.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 48, 4, 4)   |          768 | (1, 144, 4, 4)  |         2304 |             6912 |  110592 |\n",
      "| 125 | encoder.blocks.3.1.bn1.drop       | Identity               |                                                   | (1, 144, 4, 4)  |         2304 | (1, 144, 4, 4)  |         2304 |                0 |       0 |\n",
      "| 126 | encoder.blocks.3.1.bn1.act        | Hardswish              |                                                   | (1, 144, 4, 4)  |         2304 | (1, 144, 4, 4)  |         2304 |                0 |       0 |\n",
      "| 127 | encoder.blocks.3.1.bn1            | BatchNormAct2d         |                                                   | (1, 144, 4, 4)  |         2304 | (1, 144, 4, 4)  |         2304 |                0 |       0 |\n",
      "| 128 | encoder.blocks.3.1.conv_dw        | Conv2d                 | k=(5, 5), s=(1, 1), g=(144), dsc=(True), d=(1, 1) | (1, 144, 4, 4)  |         2304 | (1, 144, 4, 4)  |         2304 |             3600 |   57600 |\n",
      "| 129 | encoder.blocks.3.1.bn2.drop       | Identity               |                                                   | (1, 144, 4, 4)  |         2304 | (1, 144, 4, 4)  |         2304 |                0 |       0 |\n",
      "| 130 | encoder.blocks.3.1.bn2.act        | Hardswish              |                                                   | (1, 144, 4, 4)  |         2304 | (1, 144, 4, 4)  |         2304 |                0 |       0 |\n",
      "| 131 | encoder.blocks.3.1.bn2            | BatchNormAct2d         |                                                   | (1, 144, 4, 4)  |         2304 | (1, 144, 4, 4)  |         2304 |                0 |       0 |\n",
      "| 132 | encoder.blocks.3.1.se.conv_reduce | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 144, 1, 1)  |          144 | (1, 40, 1, 1)   |           40 |             5760 |    5760 |\n",
      "| 133 | encoder.blocks.3.1.se.act1        | ReLU                   |                                                   | (1, 40, 1, 1)   |           40 | (1, 40, 1, 1)   |           40 |                0 |       0 |\n",
      "| 134 | encoder.blocks.3.1.se.conv_expand | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 40, 1, 1)   |           40 | (1, 144, 1, 1)  |          144 |             5760 |    5760 |\n",
      "| 135 | encoder.blocks.3.1.se.gate        | Hardsigmoid            |                                                   | (1, 144, 1, 1)  |          144 | (1, 144, 1, 1)  |          144 |                0 |       0 |\n",
      "| 136 | encoder.blocks.3.1.se             | SqueezeExcite          |                                                   | (1, 144, 4, 4)  |         2304 | (1, 144, 4, 4)  |         2304 |                0 |       0 |\n",
      "| 137 | encoder.blocks.3.1.conv_pwl       | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 144, 4, 4)  |         2304 | (1, 48, 4, 4)   |          768 |             6912 |  110592 |\n",
      "| 138 | encoder.blocks.3.1.bn3.drop       | Identity               |                                                   | (1, 48, 4, 4)   |          768 | (1, 48, 4, 4)   |          768 |                0 |       0 |\n",
      "| 139 | encoder.blocks.3.1.bn3.act        | Identity               |                                                   | (1, 48, 4, 4)   |          768 | (1, 48, 4, 4)   |          768 |                0 |       0 |\n",
      "| 140 | encoder.blocks.3.1.bn3            | BatchNormAct2d         |                                                   | (1, 48, 4, 4)   |          768 | (1, 48, 4, 4)   |          768 |                0 |       0 |\n",
      "| 141 | encoder.blocks.3.1.drop_path      | DropPath               |                                                   | (1, 48, 4, 4)   |          768 | (1, 48, 4, 4)   |          768 |                0 |       0 |\n",
      "| 142 | encoder.blocks.3.1                | InvertedResidual       |                                                   | (1, 48, 4, 4)   |          768 | (1, 48, 4, 4)   |          768 |                0 |       0 |\n",
      "| 143 | encoder.blocks.3                  | Sequential             |                                                   | (1, 40, 4, 4)   |          640 | (1, 48, 4, 4)   |          768 |                0 |       0 |\n",
      "| 144 | encoder.blocks.4.0.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 48, 4, 4)   |          768 | (1, 288, 4, 4)  |         4608 |            13824 |  221184 |\n",
      "| 145 | encoder.blocks.4.0.bn1.drop       | Identity               |                                                   | (1, 288, 4, 4)  |         4608 | (1, 288, 4, 4)  |         4608 |                0 |       0 |\n",
      "| 146 | encoder.blocks.4.0.bn1.act        | Hardswish              |                                                   | (1, 288, 4, 4)  |         4608 | (1, 288, 4, 4)  |         4608 |                0 |       0 |\n",
      "| 147 | encoder.blocks.4.0.bn1            | BatchNormAct2d         |                                                   | (1, 288, 4, 4)  |         4608 | (1, 288, 4, 4)  |         4608 |                0 |       0 |\n",
      "| 148 | encoder.blocks.4.0.conv_dw        | Conv2d                 | k=(5, 5), s=(2, 2), g=(288), dsc=(True), d=(1, 1) | (1, 288, 4, 4)  |         4608 | (1, 288, 2, 2)  |         1152 |             7200 |   28800 |\n",
      "| 149 | encoder.blocks.4.0.bn2.drop       | Identity               |                                                   | (1, 288, 2, 2)  |         1152 | (1, 288, 2, 2)  |         1152 |                0 |       0 |\n",
      "| 150 | encoder.blocks.4.0.bn2.act        | Hardswish              |                                                   | (1, 288, 2, 2)  |         1152 | (1, 288, 2, 2)  |         1152 |                0 |       0 |\n",
      "| 151 | encoder.blocks.4.0.bn2            | BatchNormAct2d         |                                                   | (1, 288, 2, 2)  |         1152 | (1, 288, 2, 2)  |         1152 |                0 |       0 |\n",
      "| 152 | encoder.blocks.4.0.se.conv_reduce | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 288, 1, 1)  |          288 | (1, 72, 1, 1)   |           72 |            20736 |   20736 |\n",
      "| 153 | encoder.blocks.4.0.se.act1        | ReLU                   |                                                   | (1, 72, 1, 1)   |           72 | (1, 72, 1, 1)   |           72 |                0 |       0 |\n",
      "| 154 | encoder.blocks.4.0.se.conv_expand | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 72, 1, 1)   |           72 | (1, 288, 1, 1)  |          288 |            20736 |   20736 |\n",
      "| 155 | encoder.blocks.4.0.se.gate        | Hardsigmoid            |                                                   | (1, 288, 1, 1)  |          288 | (1, 288, 1, 1)  |          288 |                0 |       0 |\n",
      "| 156 | encoder.blocks.4.0.se             | SqueezeExcite          |                                                   | (1, 288, 2, 2)  |         1152 | (1, 288, 2, 2)  |         1152 |                0 |       0 |\n",
      "| 157 | encoder.blocks.4.0.conv_pwl       | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 288, 2, 2)  |         1152 | (1, 96, 2, 2)   |          384 |            27648 |  110592 |\n",
      "| 158 | encoder.blocks.4.0.bn3.drop       | Identity               |                                                   | (1, 96, 2, 2)   |          384 | (1, 96, 2, 2)   |          384 |                0 |       0 |\n",
      "| 159 | encoder.blocks.4.0.bn3.act        | Identity               |                                                   | (1, 96, 2, 2)   |          384 | (1, 96, 2, 2)   |          384 |                0 |       0 |\n",
      "| 160 | encoder.blocks.4.0.bn3            | BatchNormAct2d         |                                                   | (1, 96, 2, 2)   |          384 | (1, 96, 2, 2)   |          384 |                0 |       0 |\n",
      "| 161 | encoder.blocks.4.0                | InvertedResidual       |                                                   | (1, 48, 4, 4)   |          768 | (1, 96, 2, 2)   |          384 |                0 |       0 |\n",
      "| 162 | encoder.blocks.4.1.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 96, 2, 2)   |          384 | (1, 576, 2, 2)  |         2304 |            55296 |  221184 |\n",
      "| 163 | encoder.blocks.4.1.bn1.drop       | Identity               |                                                   | (1, 576, 2, 2)  |         2304 | (1, 576, 2, 2)  |         2304 |                0 |       0 |\n",
      "| 164 | encoder.blocks.4.1.bn1.act        | Hardswish              |                                                   | (1, 576, 2, 2)  |         2304 | (1, 576, 2, 2)  |         2304 |                0 |       0 |\n",
      "| 165 | encoder.blocks.4.1.bn1            | BatchNormAct2d         |                                                   | (1, 576, 2, 2)  |         2304 | (1, 576, 2, 2)  |         2304 |                0 |       0 |\n",
      "| 166 | encoder.blocks.4.1.conv_dw        | Conv2d                 | k=(5, 5), s=(1, 1), g=(576), dsc=(True), d=(1, 1) | (1, 576, 2, 2)  |         2304 | (1, 576, 2, 2)  |         2304 |            14400 |   57600 |\n",
      "| 167 | encoder.blocks.4.1.bn2.drop       | Identity               |                                                   | (1, 576, 2, 2)  |         2304 | (1, 576, 2, 2)  |         2304 |                0 |       0 |\n",
      "| 168 | encoder.blocks.4.1.bn2.act        | Hardswish              |                                                   | (1, 576, 2, 2)  |         2304 | (1, 576, 2, 2)  |         2304 |                0 |       0 |\n",
      "| 169 | encoder.blocks.4.1.bn2            | BatchNormAct2d         |                                                   | (1, 576, 2, 2)  |         2304 | (1, 576, 2, 2)  |         2304 |                0 |       0 |\n",
      "| 170 | encoder.blocks.4.1.se.conv_reduce | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 576, 1, 1)  |          576 | (1, 144, 1, 1)  |          144 |            82944 |   82944 |\n",
      "| 171 | encoder.blocks.4.1.se.act1        | ReLU                   |                                                   | (1, 144, 1, 1)  |          144 | (1, 144, 1, 1)  |          144 |                0 |       0 |\n",
      "| 172 | encoder.blocks.4.1.se.conv_expand | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 144, 1, 1)  |          144 | (1, 576, 1, 1)  |          576 |            82944 |   82944 |\n",
      "| 173 | encoder.blocks.4.1.se.gate        | Hardsigmoid            |                                                   | (1, 576, 1, 1)  |          576 | (1, 576, 1, 1)  |          576 |                0 |       0 |\n",
      "| 174 | encoder.blocks.4.1.se             | SqueezeExcite          |                                                   | (1, 576, 2, 2)  |         2304 | (1, 576, 2, 2)  |         2304 |                0 |       0 |\n",
      "| 175 | encoder.blocks.4.1.conv_pwl       | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 576, 2, 2)  |         2304 | (1, 96, 2, 2)   |          384 |            55296 |  221184 |\n",
      "| 176 | encoder.blocks.4.1.bn3.drop       | Identity               |                                                   | (1, 96, 2, 2)   |          384 | (1, 96, 2, 2)   |          384 |                0 |       0 |\n",
      "| 177 | encoder.blocks.4.1.bn3.act        | Identity               |                                                   | (1, 96, 2, 2)   |          384 | (1, 96, 2, 2)   |          384 |                0 |       0 |\n",
      "| 178 | encoder.blocks.4.1.bn3            | BatchNormAct2d         |                                                   | (1, 96, 2, 2)   |          384 | (1, 96, 2, 2)   |          384 |                0 |       0 |\n",
      "| 179 | encoder.blocks.4.1.drop_path      | DropPath               |                                                   | (1, 96, 2, 2)   |          384 | (1, 96, 2, 2)   |          384 |                0 |       0 |\n",
      "| 180 | encoder.blocks.4.1                | InvertedResidual       |                                                   | (1, 96, 2, 2)   |          384 | (1, 96, 2, 2)   |          384 |                0 |       0 |\n",
      "| 181 | encoder.blocks.4.2.conv_pw        | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 96, 2, 2)   |          384 | (1, 576, 2, 2)  |         2304 |            55296 |  221184 |\n",
      "| 182 | encoder.blocks.4.2.bn1.drop       | Identity               |                                                   | (1, 576, 2, 2)  |         2304 | (1, 576, 2, 2)  |         2304 |                0 |       0 |\n",
      "| 183 | encoder.blocks.4.2.bn1.act        | Hardswish              |                                                   | (1, 576, 2, 2)  |         2304 | (1, 576, 2, 2)  |         2304 |                0 |       0 |\n",
      "| 184 | encoder.blocks.4.2.bn1            | BatchNormAct2d         |                                                   | (1, 576, 2, 2)  |         2304 | (1, 576, 2, 2)  |         2304 |                0 |       0 |\n",
      "| 185 | encoder.blocks.4.2.conv_dw        | Conv2d                 | k=(5, 5), s=(1, 1), g=(576), dsc=(True), d=(1, 1) | (1, 576, 2, 2)  |         2304 | (1, 576, 2, 2)  |         2304 |            14400 |   57600 |\n",
      "| 186 | encoder.blocks.4.2.bn2.drop       | Identity               |                                                   | (1, 576, 2, 2)  |         2304 | (1, 576, 2, 2)  |         2304 |                0 |       0 |\n",
      "| 187 | encoder.blocks.4.2.bn2.act        | Hardswish              |                                                   | (1, 576, 2, 2)  |         2304 | (1, 576, 2, 2)  |         2304 |                0 |       0 |\n",
      "| 188 | encoder.blocks.4.2.bn2            | BatchNormAct2d         |                                                   | (1, 576, 2, 2)  |         2304 | (1, 576, 2, 2)  |         2304 |                0 |       0 |\n",
      "| 189 | encoder.blocks.4.2.se.conv_reduce | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 576, 1, 1)  |          576 | (1, 144, 1, 1)  |          144 |            82944 |   82944 |\n",
      "| 190 | encoder.blocks.4.2.se.act1        | ReLU                   |                                                   | (1, 144, 1, 1)  |          144 | (1, 144, 1, 1)  |          144 |                0 |       0 |\n",
      "| 191 | encoder.blocks.4.2.se.conv_expand | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 144, 1, 1)  |          144 | (1, 576, 1, 1)  |          576 |            82944 |   82944 |\n",
      "| 192 | encoder.blocks.4.2.se.gate        | Hardsigmoid            |                                                   | (1, 576, 1, 1)  |          576 | (1, 576, 1, 1)  |          576 |                0 |       0 |\n",
      "| 193 | encoder.blocks.4.2.se             | SqueezeExcite          |                                                   | (1, 576, 2, 2)  |         2304 | (1, 576, 2, 2)  |         2304 |                0 |       0 |\n",
      "| 194 | encoder.blocks.4.2.conv_pwl       | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 576, 2, 2)  |         2304 | (1, 96, 2, 2)   |          384 |            55296 |  221184 |\n",
      "| 195 | encoder.blocks.4.2.bn3.drop       | Identity               |                                                   | (1, 96, 2, 2)   |          384 | (1, 96, 2, 2)   |          384 |                0 |       0 |\n",
      "| 196 | encoder.blocks.4.2.bn3.act        | Identity               |                                                   | (1, 96, 2, 2)   |          384 | (1, 96, 2, 2)   |          384 |                0 |       0 |\n",
      "| 197 | encoder.blocks.4.2.bn3            | BatchNormAct2d         |                                                   | (1, 96, 2, 2)   |          384 | (1, 96, 2, 2)   |          384 |                0 |       0 |\n",
      "| 198 | encoder.blocks.4.2.drop_path      | DropPath               |                                                   | (1, 96, 2, 2)   |          384 | (1, 96, 2, 2)   |          384 |                0 |       0 |\n",
      "| 199 | encoder.blocks.4.2                | InvertedResidual       |                                                   | (1, 96, 2, 2)   |          384 | (1, 96, 2, 2)   |          384 |                0 |       0 |\n",
      "| 200 | encoder.blocks.4                  | Sequential             |                                                   | (1, 48, 4, 4)   |          768 | (1, 96, 2, 2)   |          384 |                0 |       0 |\n",
      "| 201 | encoder.blocks.5.0.conv           | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 96, 2, 2)   |          384 | (1, 576, 2, 2)  |         2304 |            55296 |  221184 |\n",
      "| 202 | encoder.blocks.5.0.bn1.drop       | Identity               |                                                   | (1, 576, 2, 2)  |         2304 | (1, 576, 2, 2)  |         2304 |                0 |       0 |\n",
      "| 203 | encoder.blocks.5.0.bn1.act        | Hardswish              |                                                   | (1, 576, 2, 2)  |         2304 | (1, 576, 2, 2)  |         2304 |                0 |       0 |\n",
      "| 204 | encoder.blocks.5.0.bn1            | BatchNormAct2d         |                                                   | (1, 576, 2, 2)  |         2304 | (1, 576, 2, 2)  |         2304 |                0 |       0 |\n",
      "| 205 | encoder.blocks.5.0                | ConvBnAct              |                                                   | (1, 96, 2, 2)   |          384 | (1, 576, 2, 2)  |         2304 |                0 |       0 |\n",
      "| 206 | encoder.blocks.5                  | Sequential             |                                                   | (1, 96, 2, 2)   |          384 | (1, 576, 2, 2)  |         2304 |                0 |       0 |\n",
      "| 207 | encoder.blocks                    | Sequential             |                                                   | (1, 16, 32, 32) |        16384 | (1, 576, 2, 2)  |         2304 |                0 |       0 |\n",
      "| 208 | encoder.global_pool.pool          | Identity               |                                                   | (1, 576, 2, 2)  |         2304 | (1, 576, 2, 2)  |         2304 |                0 |       0 |\n",
      "| 209 | encoder.global_pool.flatten       | Identity               |                                                   | (1, 576, 2, 2)  |         2304 | (1, 576, 2, 2)  |         2304 |                0 |       0 |\n",
      "| 210 | encoder.global_pool               | SelectAdaptivePool2d   |                                                   | (1, 576, 2, 2)  |         2304 | (1, 576, 2, 2)  |         2304 |                0 |       0 |\n",
      "| 211 | encoder.conv_head                 | Conv2d                 | k=(1, 1), s=(1, 1), g=(1), dsc=(False), d=(1, 1)  | (1, 576, 2, 2)  |         2304 | (1, 1024, 2, 2) |         4096 |           589824 | 2359296 |\n",
      "| 212 | encoder.act2                      | Hardswish              |                                                   | (1, 1024, 2, 2) |         4096 | (1, 1024, 2, 2) |         4096 |                0 |       0 |\n",
      "| 213 | encoder.flatten                   | Identity               |                                                   | (1, 1024, 2, 2) |         4096 | (1, 1024, 2, 2) |         4096 |                0 |       0 |\n",
      "| 214 | encoder.classifier                | Identity               |                                                   | (1, 1024, 2, 2) |         4096 | (1, 1024, 2, 2) |         4096 |                0 |       0 |\n",
      "| 215 | encoder                           | MobileNetV3            |                                                   | (1, 3, 32, 32)  |         3072 | (1, 1024, 2, 2) |         4096 |                0 |       0 |\n",
      "| 216 | classifier.pooling                | AdaptiveAvgPool2d      |                                                   | (1, 1024, 2, 2) |         4096 | (1, 1024, 1, 1) |         1024 |                0 |       0 |\n",
      "| 217 | classifier.flatten                | Flatten                |                                                   | (1, 1024, 1, 1) |         1024 | (1, 1024)       |         1024 |                0 |       0 |\n",
      "| 218 | classifier.linear                 | Linear                 |                                                   | (1, 1024)       |         1024 | (1, 10)         |           10 |            10240 |   10240 |\n",
      "| 219 | classifier                        | DefaultClassifierHead  |                                                   | (1, 1024, 2, 2) |         4096 | (1, 10)         |           10 |                0 |       0 |\n",
      "+-----+-----------------------------------+------------------------+---------------------------------------------------+-----------------+--------------+-----------------+--------------+------------------+---------+\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:42,829\u001b[0m][\u001b[34mhannah.callbacks.summaries\u001b[0m][\u001b[32mINFO\u001b[0m] - Total MACs: 7,272,192\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:42,829\u001b[0m][\u001b[34mhannah.callbacks.summaries\u001b[0m][\u001b[32mINFO\u001b[0m] - Total Weights: 1,512,072\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:42,829\u001b[0m][\u001b[34mhannah.callbacks.summaries\u001b[0m][\u001b[32mINFO\u001b[0m] - Total Activations: 563,620\u001b[0m\n",
      "[\u001b[36m2024-02-29 16:20:42,829\u001b[0m][\u001b[34mhannah.callbacks.summaries\u001b[0m][\u001b[32mINFO\u001b[0m] - Estimated Activations: 36,864\u001b[0m\n",
      "Epoch 0: 100%|████| 21/21 [00:55<00:00,  0.38it/s, v_num=logs, train_loss=2.300]\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00,  8.41it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  8.37it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 21/21 [00:56<00:00,  0.37it/s, v_num=logs, train_loss=2.300, va\u001b[A[\u001b[36m2024-02-29 16:21:39,402\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 0, global step 21: 'val_error' reached 0.89429 (best 0.89429), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_100/checkpoints/epoch=0-step=21.ckpt' as top 1\u001b[0m\n",
      "Epoch 1: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=2.270, va\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 19.01it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00, 11.30it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=2.270, va\u001b[A[\u001b[36m2024-02-29 16:22:49,226\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 1, global step 42: 'val_error' reached 0.86719 (best 0.86719), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_100/checkpoints/epoch=1-step=42.ckpt' as top 1\u001b[0m\n",
      "Epoch 2: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=2.170, va\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00,  9.52it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  8.35it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=2.170, va\u001b[A[\u001b[36m2024-02-29 16:23:59,210\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 2, global step 63: 'val_error' reached 0.78809 (best 0.78809), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_100/checkpoints/epoch=2-step=63.ckpt' as top 1\u001b[0m\n",
      "Epoch 3: 100%|█| 21/21 [01:08<00:00,  0.30it/s, v_num=logs, train_loss=2.010, va\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 11.67it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00, 10.44it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=2.010, va\u001b[A[\u001b[36m2024-02-29 16:25:08,835\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 3, global step 84: 'val_error' reached 0.76489 (best 0.76489), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_100/checkpoints/epoch=3-step=84.ckpt' as top 1\u001b[0m\n",
      "Epoch 4: 100%|█| 21/21 [01:08<00:00,  0.31it/s, v_num=logs, train_loss=1.960, va\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████████          | 1/2 [00:00<00:00, 11.81it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████████████| 2/2 [00:00<00:00,  9.00it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 21/21 [01:09<00:00,  0.30it/s, v_num=logs, train_loss=1.960, va\u001b[A[\u001b[36m2024-02-29 16:26:18,389\u001b[0m][\u001b[34mpytorch_lightning.utilities.rank_zero\u001b[0m][\u001b[32mINFO\u001b[0m] - Epoch 4, global step 105: 'val_error' reached 0.71021 (best 0.71021), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/mobilenetv3_small_100/checkpoints/epoch=4-step=105.ckpt' as top 1\u001b[0m\n",
      "Epoch 5:  76%|▊| 16/21 [00:52<00:16,  0.30it/s, v_num=logs, train_loss=1.870, va"
     ]
    }
   ],
   "source": [
    "!hannah-train +experiment=sweep_models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hannah-8Yp6PnCx-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
