[2024-05-16 17:57:03,668][hannah.utils.utils][INFO] - Environment info:
[2024-05-16 17:57:03,763][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-16 17:57:03,764][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-16 17:57:03,768][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-16 17:57:03,768][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-16 17:57:03,769][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-16 17:57:03,769][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-16 17:57:03,769][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.2
[2024-05-16 17:57:03,769][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-16 17:57:03,769][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-16 17:57:03,770][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-16 17:57:03,770][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train dataset=cifar10_ffcv
[2024-05-16 17:57:03,770][hannah.utils.utils][INFO] -   
[2024-05-16 17:57:03,771][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-16 17:57:03,773][root][INFO] - Configuration: 
[2024-05-16 17:57:03,776][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10FFCVDataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-16 17:57:03,776][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-16 17:57:05,104][root][ERROR] - Exception Message: Error locating target 'hannah.modules.vision.ImageClassifierModule', set env var HYDRA_FULL_ERROR=1 to see chained exception.
full_key: module
Traceback (most recent call last):
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 644, in _locate
    obj = getattr(obj, part)
          ^^^^^^^^^^^^^^^^^^
AttributeError: module 'hannah.modules' has no attribute 'vision'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 650, in _locate
    obj = import_module(mod)
          ^^^^^^^^^^^^^^^^^^
  File "/usr/lib64/python3.11/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1147, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/local/gerum/hannah/hannah/modules/vision/__init__.py", line 19, in <module>
    from .anomaly_detection import AnomalyDetectionModule
  File "/local/gerum/hannah/hannah/modules/vision/anomaly_detection.py", line 33, in <module>
    from ..augmentation.batch_augmentation import BatchAugmentationPipeline
  File "/local/gerum/hannah/hannah/modules/augmentation/batch_augmentation.py", line 25, in <module>
    from .transforms.registry import registry
  File "/local/gerum/hannah/hannah/modules/augmentation/transforms/__init__.py", line 19, in <module>
    from . import kornia_transforms
  File "/local/gerum/hannah/hannah/modules/augmentation/transforms/kornia_transforms.py", line 25, in <module>
    import kornia.augmentation as K
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/__init__.py", line 8, in <module>
    from . import augmentation, color, contrib, core, enhance, feature, io, losses, metrics, morphology, tracking, utils, x
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/__init__.py", line 2, in <module>
    from kornia.augmentation import auto, container
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/auto/__init__.py", line 1, in <module>
    from .autoaugment import AutoAugment
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/auto/autoaugment/__init__.py", line 1, in <module>
    from .autoaugment import AutoAugment
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/auto/autoaugment/autoaugment.py", line 5, in <module>
    from kornia.augmentation.auto.base import SUBPOLICY_CONFIG, PolicyAugmentBase
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/auto/base.py", line 5, in <module>
    from kornia.augmentation.auto.operations.base import OperationBase
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/auto/operations/__init__.py", line 3, in <module>
    from .policy import PolicySequential
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/auto/operations/policy.py", line 7, in <module>
    from kornia.augmentation.container.base import ImageSequentialBase, TransformMatrixMinIn
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/container/__init__.py", line 1, in <module>
    from kornia.augmentation.container.augment import AugmentationSequential
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/container/augment.py", line 4, in <module>
    from kornia.augmentation._2d.base import RigidAffineAugmentationBase2D
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/_2d/__init__.py", line 2, in <module>
    from kornia.augmentation._2d.intensity import *
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/_2d/intensity/__init__.py", line 28, in <module>
    from kornia.augmentation._2d.intensity.plasma import RandomPlasmaBrightness, RandomPlasmaContrast, RandomPlasmaShadow
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/_2d/intensity/plasma.py", line 5, in <module>
    from kornia.contrib import diamond_square
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/contrib/__init__.py", line 15, in <module>
    from .image_stitching import ImageStitcher
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/contrib/image_stitching.py", line 7, in <module>
    from kornia.feature import LocalFeatureMatcher, LoFTR
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/feature/__init__.py", line 7, in <module>
    from .integrated import (
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/feature/integrated.py", line 17, in <module>
    from .lightglue import LightGlue
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/feature/lightglue.py", line 30, in <module>
    from flash_attn.modules.mha import FlashCrossAttention
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/flash_attn/__init__.py", line 3, in <module>
    from flash_attn.flash_attn_interface import (
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/flash_attn/flash_attn_interface.py", line 8, in <module>
    import flash_attn_2_cuda as flash_attn_cuda
ImportError: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/flash_attn_2_cuda.cpython-311-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops9_pad_enum4callERKNS_6TensorEN3c108ArrayRefINS5_6SymIntEEElNS5_8optionalIdEE

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 134, in _resolve_target
    target = _locate(target)
             ^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 658, in _locate
    raise ImportError(
ImportError: Error loading 'hannah.modules.vision.ImageClassifierModule':
ImportError('/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/flash_attn_2_cuda.cpython-311-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops9_pad_enum4callERKNS_6TensorEN3c108ArrayRefINS5_6SymIntEEElNS5_8optionalIdEE')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 93, in train
    lit_module = instantiate(
                 ^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 226, in instantiate
    return instantiate_node(
           ^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 333, in instantiate_node
    _target_ = _resolve_target(node.get(_Keys.TARGET), full_key)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 139, in _resolve_target
    raise InstantiationException(msg) from e
hydra.errors.InstantiationException: Error locating target 'hannah.modules.vision.ImageClassifierModule', set env var HYDRA_FULL_ERROR=1 to see chained exception.
full_key: module
[2024-05-16 17:59:49,548][matplotlib.font_manager][INFO] - Failed to extract font properties from /usr/share/fonts/google-noto-emoji/NotoColorEmoji.ttf: In FT2Font: Can not load face (unknown file format; error code 0x2)
[2024-05-16 17:59:49,562][matplotlib.font_manager][INFO] - generated new fontManager
[2024-05-16 17:59:52,004][hannah.utils.utils][INFO] - Environment info:
[2024-05-16 17:59:52,097][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-16 17:59:52,098][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-16 17:59:52,100][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-16 17:59:52,101][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-16 17:59:52,101][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-16 17:59:52,101][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-16 17:59:52,101][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-16 17:59:52,101][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-16 17:59:52,101][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-16 17:59:52,102][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-16 17:59:52,103][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train dataset=cifar10_ffcv
[2024-05-16 17:59:52,103][hannah.utils.utils][INFO] -   
[2024-05-16 17:59:52,104][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-16 17:59:52,105][root][INFO] - Configuration: 
[2024-05-16 17:59:52,108][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10FFCVDataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-16 17:59:52,108][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-16 17:59:52,610][root][ERROR] - Exception Message: Error locating target 'hannah.modules.vision.ImageClassifierModule', set env var HYDRA_FULL_ERROR=1 to see chained exception.
full_key: module
Traceback (most recent call last):
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 644, in _locate
    obj = getattr(obj, part)
          ^^^^^^^^^^^^^^^^^^
AttributeError: module 'hannah.modules' has no attribute 'vision'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 650, in _locate
    obj = import_module(mod)
          ^^^^^^^^^^^^^^^^^^
  File "/usr/lib64/python3.11/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1147, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/local/gerum/hannah/hannah/modules/vision/__init__.py", line 19, in <module>
    from .anomaly_detection import AnomalyDetectionModule
  File "/local/gerum/hannah/hannah/modules/vision/anomaly_detection.py", line 33, in <module>
    from ..augmentation.batch_augmentation import BatchAugmentationPipeline
  File "/local/gerum/hannah/hannah/modules/augmentation/batch_augmentation.py", line 25, in <module>
    from .transforms.registry import registry
  File "/local/gerum/hannah/hannah/modules/augmentation/transforms/__init__.py", line 19, in <module>
    from . import kornia_transforms
  File "/local/gerum/hannah/hannah/modules/augmentation/transforms/kornia_transforms.py", line 25, in <module>
    import kornia.augmentation as K
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/__init__.py", line 8, in <module>
    from . import augmentation, color, contrib, core, enhance, feature, io, losses, metrics, morphology, tracking, utils, x
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/__init__.py", line 2, in <module>
    from kornia.augmentation import auto, container
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/auto/__init__.py", line 1, in <module>
    from .autoaugment import AutoAugment
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/auto/autoaugment/__init__.py", line 1, in <module>
    from .autoaugment import AutoAugment
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/auto/autoaugment/autoaugment.py", line 5, in <module>
    from kornia.augmentation.auto.base import SUBPOLICY_CONFIG, PolicyAugmentBase
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/auto/base.py", line 5, in <module>
    from kornia.augmentation.auto.operations.base import OperationBase
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/auto/operations/__init__.py", line 3, in <module>
    from .policy import PolicySequential
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/auto/operations/policy.py", line 7, in <module>
    from kornia.augmentation.container.base import ImageSequentialBase, TransformMatrixMinIn
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/container/__init__.py", line 1, in <module>
    from kornia.augmentation.container.augment import AugmentationSequential
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/container/augment.py", line 4, in <module>
    from kornia.augmentation._2d.base import RigidAffineAugmentationBase2D
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/_2d/__init__.py", line 2, in <module>
    from kornia.augmentation._2d.intensity import *
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/_2d/intensity/__init__.py", line 28, in <module>
    from kornia.augmentation._2d.intensity.plasma import RandomPlasmaBrightness, RandomPlasmaContrast, RandomPlasmaShadow
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/_2d/intensity/plasma.py", line 5, in <module>
    from kornia.contrib import diamond_square
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/contrib/__init__.py", line 15, in <module>
    from .image_stitching import ImageStitcher
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/contrib/image_stitching.py", line 7, in <module>
    from kornia.feature import LocalFeatureMatcher, LoFTR
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/feature/__init__.py", line 7, in <module>
    from .integrated import (
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/feature/integrated.py", line 17, in <module>
    from .lightglue import LightGlue
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/feature/lightglue.py", line 30, in <module>
    from flash_attn.modules.mha import FlashCrossAttention
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/flash_attn/__init__.py", line 3, in <module>
    from flash_attn.flash_attn_interface import (
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/flash_attn/flash_attn_interface.py", line 8, in <module>
    import flash_attn_2_cuda as flash_attn_cuda
ImportError: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/flash_attn_2_cuda.cpython-311-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops9_pad_enum4callERKNS_6TensorEN3c108ArrayRefINS5_6SymIntEEElNS5_8optionalIdEE

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 134, in _resolve_target
    target = _locate(target)
             ^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 658, in _locate
    raise ImportError(
ImportError: Error loading 'hannah.modules.vision.ImageClassifierModule':
ImportError('/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/flash_attn_2_cuda.cpython-311-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops9_pad_enum4callERKNS_6TensorEN3c108ArrayRefINS5_6SymIntEEElNS5_8optionalIdEE')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 93, in train
    lit_module = instantiate(
                 ^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 226, in instantiate
    return instantiate_node(
           ^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 333, in instantiate_node
    _target_ = _resolve_target(node.get(_Keys.TARGET), full_key)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 139, in _resolve_target
    raise InstantiationException(msg) from e
hydra.errors.InstantiationException: Error locating target 'hannah.modules.vision.ImageClassifierModule', set env var HYDRA_FULL_ERROR=1 to see chained exception.
full_key: module
[2024-05-16 18:00:37,054][hannah.utils.utils][INFO] - Environment info:
[2024-05-16 18:00:37,146][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-16 18:00:37,147][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-16 18:00:37,150][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-16 18:00:37,150][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-16 18:00:37,150][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-16 18:00:37,150][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-16 18:00:37,150][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-16 18:00:37,150][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-16 18:00:37,150][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-16 18:00:37,152][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-16 18:00:37,152][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train dataset=cifar10_ffcv
[2024-05-16 18:00:37,152][hannah.utils.utils][INFO] -   
[2024-05-16 18:00:37,153][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-16 18:00:37,154][root][INFO] - Configuration: 
[2024-05-16 18:00:37,157][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10FFCVDataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-16 18:00:37,157][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-16 18:00:37,649][root][ERROR] - Exception Message: Error locating target 'hannah.modules.vision.ImageClassifierModule', set env var HYDRA_FULL_ERROR=1 to see chained exception.
full_key: module
Traceback (most recent call last):
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 644, in _locate
    obj = getattr(obj, part)
          ^^^^^^^^^^^^^^^^^^
AttributeError: module 'hannah.modules' has no attribute 'vision'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 650, in _locate
    obj = import_module(mod)
          ^^^^^^^^^^^^^^^^^^
  File "/usr/lib64/python3.11/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1147, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/local/gerum/hannah/hannah/modules/vision/__init__.py", line 19, in <module>
    from .anomaly_detection import AnomalyDetectionModule
  File "/local/gerum/hannah/hannah/modules/vision/anomaly_detection.py", line 33, in <module>
    from ..augmentation.batch_augmentation import BatchAugmentationPipeline
  File "/local/gerum/hannah/hannah/modules/augmentation/batch_augmentation.py", line 25, in <module>
    from .transforms.registry import registry
  File "/local/gerum/hannah/hannah/modules/augmentation/transforms/__init__.py", line 19, in <module>
    from . import kornia_transforms
  File "/local/gerum/hannah/hannah/modules/augmentation/transforms/kornia_transforms.py", line 25, in <module>
    import kornia.augmentation as K
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/__init__.py", line 8, in <module>
    from . import augmentation, color, contrib, core, enhance, feature, io, losses, metrics, morphology, tracking, utils, x
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/__init__.py", line 2, in <module>
    from kornia.augmentation import auto, container
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/auto/__init__.py", line 1, in <module>
    from .autoaugment import AutoAugment
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/auto/autoaugment/__init__.py", line 1, in <module>
    from .autoaugment import AutoAugment
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/auto/autoaugment/autoaugment.py", line 5, in <module>
    from kornia.augmentation.auto.base import SUBPOLICY_CONFIG, PolicyAugmentBase
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/auto/base.py", line 5, in <module>
    from kornia.augmentation.auto.operations.base import OperationBase
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/auto/operations/__init__.py", line 3, in <module>
    from .policy import PolicySequential
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/auto/operations/policy.py", line 7, in <module>
    from kornia.augmentation.container.base import ImageSequentialBase, TransformMatrixMinIn
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/container/__init__.py", line 1, in <module>
    from kornia.augmentation.container.augment import AugmentationSequential
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/container/augment.py", line 4, in <module>
    from kornia.augmentation._2d.base import RigidAffineAugmentationBase2D
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/_2d/__init__.py", line 2, in <module>
    from kornia.augmentation._2d.intensity import *
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/_2d/intensity/__init__.py", line 28, in <module>
    from kornia.augmentation._2d.intensity.plasma import RandomPlasmaBrightness, RandomPlasmaContrast, RandomPlasmaShadow
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/augmentation/_2d/intensity/plasma.py", line 5, in <module>
    from kornia.contrib import diamond_square
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/contrib/__init__.py", line 15, in <module>
    from .image_stitching import ImageStitcher
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/contrib/image_stitching.py", line 7, in <module>
    from kornia.feature import LocalFeatureMatcher, LoFTR
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/feature/__init__.py", line 7, in <module>
    from .integrated import (
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/feature/integrated.py", line 17, in <module>
    from .lightglue import LightGlue
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/kornia/feature/lightglue.py", line 30, in <module>
    from flash_attn.modules.mha import FlashCrossAttention
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/flash_attn/__init__.py", line 3, in <module>
    from flash_attn.flash_attn_interface import (
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/flash_attn/flash_attn_interface.py", line 8, in <module>
    import flash_attn_2_cuda as flash_attn_cuda
ImportError: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/flash_attn_2_cuda.cpython-311-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops9_pad_enum4callERKNS_6TensorEN3c108ArrayRefINS5_6SymIntEEElNS5_8optionalIdEE

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 134, in _resolve_target
    target = _locate(target)
             ^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 658, in _locate
    raise ImportError(
ImportError: Error loading 'hannah.modules.vision.ImageClassifierModule':
ImportError('/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/flash_attn_2_cuda.cpython-311-x86_64-linux-gnu.so: undefined symbol: _ZN2at4_ops9_pad_enum4callERKNS_6TensorEN3c108ArrayRefINS5_6SymIntEEElNS5_8optionalIdEE')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 93, in train
    lit_module = instantiate(
                 ^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 226, in instantiate
    return instantiate_node(
           ^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 333, in instantiate_node
    _target_ = _resolve_target(node.get(_Keys.TARGET), full_key)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 139, in _resolve_target
    raise InstantiationException(msg) from e
hydra.errors.InstantiationException: Error locating target 'hannah.modules.vision.ImageClassifierModule', set env var HYDRA_FULL_ERROR=1 to see chained exception.
full_key: module
[2024-05-16 18:01:21,863][hannah.utils.utils][INFO] - Environment info:
[2024-05-16 18:01:21,958][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-16 18:01:21,959][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-16 18:01:21,961][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-16 18:01:21,961][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-16 18:01:21,961][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-16 18:01:21,962][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-16 18:01:21,962][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-16 18:01:21,962][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-16 18:01:21,962][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-16 18:01:21,963][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-16 18:01:21,963][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train dataset=cifar10_ffcv
[2024-05-16 18:01:21,963][hannah.utils.utils][INFO] -   
[2024-05-16 18:01:21,965][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-16 18:01:21,966][root][INFO] - Configuration: 
[2024-05-16 18:01:21,969][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10FFCVDataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-16 18:01:21,969][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-16 18:01:22,561][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-16 18:01:22,562][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-16 18:01:22,629][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-16 18:01:22,653][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-16 18:01:22,660][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-16 18:01:22,660][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-16 18:01:22,660][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-16 18:01:22,660][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-16 18:01:22,660][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-16 18:01:22,660][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-16 18:01:22,660][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-16 18:01:22,661][root][INFO] - Starting training
[2024-05-16 18:01:26,978][root][ERROR] - Exception Message: FFCV is not available
Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 947, in _run
    self._data_connector.prepare_data()
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py", line 100, in prepare_data
    call._call_lightning_module_hook(trainer, "prepare_data")
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 216, in prepare_data
    get_class(self.hparams.dataset.cls).prepare(self.hparams.dataset)
  File "/local/gerum/hannah/hannah/datasets/vision/cifar10_ffcv.py", line 115, in prepare
    raise RuntimeError("FFCV is not available")
RuntimeError: FFCV is not available
[2024-05-16 18:01:57,054][hannah.utils.utils][INFO] - Environment info:
[2024-05-16 18:01:57,147][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-16 18:01:57,148][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-16 18:01:57,150][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-16 18:01:57,150][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-16 18:01:57,151][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-16 18:01:57,151][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-16 18:01:57,151][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-16 18:01:57,151][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-16 18:01:57,151][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-16 18:01:57,152][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-16 18:01:57,152][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train dataset=cifar10_ffcv
[2024-05-16 18:01:57,152][hannah.utils.utils][INFO] -   
[2024-05-16 18:01:57,153][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-16 18:01:57,155][root][INFO] - Configuration: 
[2024-05-16 18:01:57,158][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10FFCVDataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-16 18:01:57,158][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-16 18:01:57,676][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-16 18:01:57,676][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-16 18:01:57,731][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-16 18:01:57,755][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-16 18:01:57,762][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-16 18:01:57,762][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-16 18:01:57,762][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-16 18:01:57,762][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-16 18:01:57,762][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-16 18:01:57,762][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-16 18:01:57,762][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-16 18:01:57,762][root][INFO] - Starting training
[2024-05-16 18:02:01,800][root][ERROR] - Exception Message: FFCV is not available
Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 947, in _run
    self._data_connector.prepare_data()
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py", line 100, in prepare_data
    call._call_lightning_module_hook(trainer, "prepare_data")
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 216, in prepare_data
    get_class(self.hparams.dataset.cls).prepare(self.hparams.dataset)
  File "/local/gerum/hannah/hannah/datasets/vision/cifar10_ffcv.py", line 115, in prepare
    raise RuntimeError("FFCV is not available")
RuntimeError: FFCV is not available
[2024-05-16 18:03:31,857][hannah.utils.utils][INFO] - Environment info:
[2024-05-16 18:03:31,949][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-16 18:03:31,949][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-16 18:03:31,952][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-16 18:03:31,952][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-16 18:03:31,952][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-16 18:03:31,952][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-16 18:03:31,952][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-16 18:03:31,953][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-16 18:03:31,953][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-16 18:03:31,954][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-16 18:03:31,954][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train dataset=cifar10_ffcv
[2024-05-16 18:03:31,954][hannah.utils.utils][INFO] -   
[2024-05-16 18:03:31,955][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-16 18:03:31,956][root][INFO] - Configuration: 
[2024-05-16 18:03:31,960][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10FFCVDataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-16 18:03:31,960][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-16 18:03:32,478][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-16 18:03:32,478][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-16 18:03:32,535][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-16 18:03:32,559][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-16 18:03:32,566][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-16 18:03:32,566][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-16 18:03:32,566][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-16 18:03:32,566][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-16 18:03:32,566][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-16 18:03:32,567][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-16 18:03:32,567][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-16 18:03:32,567][root][INFO] - Starting training
[2024-05-16 18:03:42,654][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:66: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-16 18:03:42,654][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-16 18:03:43,158][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 50000
[2024-05-16 18:03:43,159][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-16 18:03:43,229][hannah.modules.vision.base][INFO] -   Dev Set: 10000
[2024-05-16 18:03:43,298][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-16 18:03:44,329][hannah.modules.vision.base][INFO] - Setting up model resnet18
[2024-05-16 18:03:44,737][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:803: UserWarning: Overwriting focalnet_tiny_srf in registry with hannah.models._vendor.focalnet.focalnet_tiny_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-16 18:03:44,737][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:824: UserWarning: Overwriting focalnet_small_srf in registry with hannah.models._vendor.focalnet.focalnet_small_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-16 18:03:44,737][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:843: UserWarning: Overwriting focalnet_base_srf in registry with hannah.models._vendor.focalnet.focalnet_base_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-16 18:03:44,737][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:862: UserWarning: Overwriting focalnet_tiny_lrf in registry with hannah.models._vendor.focalnet.focalnet_tiny_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-16 18:03:44,737][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:885: UserWarning: Overwriting focalnet_small_lrf in registry with hannah.models._vendor.focalnet.focalnet_small_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-16 18:03:44,737][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:906: UserWarning: Overwriting focalnet_base_lrf in registry with hannah.models._vendor.focalnet.focalnet_base_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-16 18:03:44,737][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1010: UserWarning: Overwriting focalnet_large_fl3 in registry with hannah.models._vendor.focalnet.focalnet_large_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-16 18:03:44,737][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1031: UserWarning: Overwriting focalnet_large_fl4 in registry with hannah.models._vendor.focalnet.focalnet_large_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-16 18:03:44,737][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1052: UserWarning: Overwriting focalnet_xlarge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-16 18:03:44,737][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1073: UserWarning: Overwriting focalnet_xlarge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-16 18:03:44,737][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1094: UserWarning: Overwriting focalnet_huge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-16 18:03:44,738][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1115: UserWarning: Overwriting focalnet_huge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-16 18:03:44,850][hannah.models.timm][INFO] - Using default logger for automatic stem creation
[2024-05-16 18:03:44,850][hannah.models.timm][INFO] - Small input size detected trying to adopt small input size
[2024-05-16 18:03:44,895][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '

[2024-05-16 18:03:44,896][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.4914, 0.4822, 0.4465), std: (0.2023, 0.1994, 0.201)
[2024-05-16 18:03:44,902][hannah.modules.vision.base][INFO] - Running dummy forward to initialize lazy modules
[2024-05-16 18:03:44,942][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-16 18:03:44,955][pytorch_lightning.utilities.rank_zero][INFO] - Loading `train_dataloader` to estimate number of stepping batches.
[2024-05-16 18:03:46,208][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

[2024-05-16 18:03:46,764][pytorch_lightning.callbacks.model_summary][INFO] - 
   | Name                 | Type                           | Params | In sizes       | Out sizes                          
--------------------------------------------------------------------------------------------------------------------------------
0  | val_metrics          | MetricCollection               | 0      | ?              | ?                                  
1  | test_metrics         | MetricCollection               | 0      | ?              | ?                                  
2  | train_metrics        | MetricCollection               | 0      | ?              | ?                                  
3  | model                | TimmModel                      | 11.2 M | [1, 3, 32, 32] | [[1, 512, 4, 4], [0], [0], [1, 10]]
4  | input_normalizer     | Normalize                      | 0      | ?              | ?                                  
5  | default_augmentation | Sequential                     | 0      | ?              | ?                                  
6  | augmentations        | ModuleDict                     | 0      | ?              | ?                                  
7  | test_confusion       | MulticlassConfusionMatrix      | 0      | ?              | ?                                  
8  | test_roc             | MulticlassROC                  | 0      | ?              | ?                                  
9  | test_pr_curve        | MulticlassPrecisionRecallCurve | 0      | ?              | ?                                  
10 | metrics              | ModuleDict                     | 0      | ?              | ?                                  
--------------------------------------------------------------------------------------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.696    Total estimated model params size (MB)
[2024-05-16 18:03:46,947][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-16 18:03:46,947][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-16 18:03:46,952][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-16 18:03:48,178][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-16 18:03:48,178][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-16 18:03:48,178][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-16 18:03:48,179][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-16 18:03:48,179][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-16 18:04:00,664][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 0, global step 24: 'val_error' reached 0.76050 (best 0.76050), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=24.ckpt' as top 1
[2024-05-16 18:04:13,448][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 1, global step 48: 'val_error' reached 0.72290 (best 0.72290), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=1-step=48.ckpt' as top 1
[2024-05-16 18:04:26,056][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 2, global step 72: 'val_error' reached 0.67651 (best 0.67651), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=2-step=72.ckpt' as top 1
[2024-05-16 18:04:36,167][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...

[2024-05-16 18:04:36,173][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-16 18:04:36,174][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-16 18:04:36,635][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=2-step=72.ckpt
[2024-05-16 18:04:36,646][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...

[2024-05-16 18:04:36,652][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-16 18:04:36,653][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-16 18:04:36,886][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=2-step=72.ckpt
[2024-05-16 18:04:36,924][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-16 18:04:37,042][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-16 18:04:37,042][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-16 18:04:37,044][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-16 18:04:37,148][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...

[2024-05-16 18:04:37,165][hannah.train][INFO] - Averaged Result Metrics:
| Metric              |     Mean |   Std |   Count |
|---------------------|----------|-------|---------|
| val_classifier_loss | 1.84448  |     0 |       1 |
| val_accuracy        | 0.323486 |     0 |       1 |
| val_error           | 0.676514 |     0 |       1 |
| val_f1              | 0.309794 |     0 |       1 |
| val_precision       | 0.338392 |     0 |       1 |
| val_recall          | 0.324106 |     0 |       1 |
| val_loss            | 1.84448  |     0 |       1 |
[2024-05-16 18:05:30,331][hannah.utils.utils][INFO] - Environment info:
[2024-05-16 18:05:30,425][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-16 18:05:30,426][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-16 18:05:30,429][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-16 18:05:30,429][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-16 18:05:30,429][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-16 18:05:30,429][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-16 18:05:30,429][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-16 18:05:30,429][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-16 18:05:30,430][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-16 18:05:30,431][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-16 18:05:30,431][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train dataset=cifar10_ffcv
[2024-05-16 18:05:30,431][hannah.utils.utils][INFO] -   
[2024-05-16 18:05:30,432][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-16 18:05:30,460][root][INFO] - Configuration: 
[2024-05-16 18:05:30,463][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10FFCVDataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-16 18:05:30,463][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-16 18:05:30,984][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-16 18:05:30,984][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-16 18:05:31,040][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-16 18:05:31,064][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-16 18:05:31,071][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-16 18:05:31,071][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-16 18:05:31,071][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-16 18:05:31,071][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-16 18:05:31,071][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-16 18:05:31,071][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-16 18:05:31,071][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-16 18:05:31,071][root][INFO] - Starting training
[2024-05-16 18:05:36,335][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:66: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-16 18:05:36,335][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-16 18:05:36,817][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 50000
[2024-05-16 18:05:36,817][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-16 18:05:36,887][hannah.modules.vision.base][INFO] -   Dev Set: 10000
[2024-05-16 18:05:36,956][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-16 18:05:37,941][hannah.modules.vision.base][INFO] - Setting up model resnet18
[2024-05-16 18:05:38,051][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:803: UserWarning: Overwriting focalnet_tiny_srf in registry with hannah.models._vendor.focalnet.focalnet_tiny_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-16 18:05:38,051][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:824: UserWarning: Overwriting focalnet_small_srf in registry with hannah.models._vendor.focalnet.focalnet_small_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-16 18:05:38,051][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:843: UserWarning: Overwriting focalnet_base_srf in registry with hannah.models._vendor.focalnet.focalnet_base_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-16 18:05:38,051][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:862: UserWarning: Overwriting focalnet_tiny_lrf in registry with hannah.models._vendor.focalnet.focalnet_tiny_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-16 18:05:38,051][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:885: UserWarning: Overwriting focalnet_small_lrf in registry with hannah.models._vendor.focalnet.focalnet_small_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-16 18:05:38,051][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:906: UserWarning: Overwriting focalnet_base_lrf in registry with hannah.models._vendor.focalnet.focalnet_base_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-16 18:05:38,052][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1010: UserWarning: Overwriting focalnet_large_fl3 in registry with hannah.models._vendor.focalnet.focalnet_large_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-16 18:05:38,052][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1031: UserWarning: Overwriting focalnet_large_fl4 in registry with hannah.models._vendor.focalnet.focalnet_large_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-16 18:05:38,052][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1052: UserWarning: Overwriting focalnet_xlarge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-16 18:05:38,052][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1073: UserWarning: Overwriting focalnet_xlarge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-16 18:05:38,052][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1094: UserWarning: Overwriting focalnet_huge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-16 18:05:38,052][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1115: UserWarning: Overwriting focalnet_huge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-16 18:05:38,149][hannah.models.timm][INFO] - Using default logger for automatic stem creation
[2024-05-16 18:05:38,149][hannah.models.timm][INFO] - Small input size detected trying to adopt small input size
[2024-05-16 18:05:38,161][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '

[2024-05-16 18:05:38,162][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.4914, 0.4822, 0.4465), std: (0.2023, 0.1994, 0.201)
[2024-05-16 18:05:38,168][hannah.modules.vision.base][INFO] - Running dummy forward to initialize lazy modules
[2024-05-16 18:05:38,177][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-16 18:05:38,191][pytorch_lightning.utilities.rank_zero][INFO] - Loading `train_dataloader` to estimate number of stepping batches.
[2024-05-16 18:05:39,436][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

[2024-05-16 18:05:39,595][pytorch_lightning.callbacks.model_summary][INFO] - 
   | Name                 | Type                           | Params | In sizes       | Out sizes                          
--------------------------------------------------------------------------------------------------------------------------------
0  | val_metrics          | MetricCollection               | 0      | ?              | ?                                  
1  | test_metrics         | MetricCollection               | 0      | ?              | ?                                  
2  | train_metrics        | MetricCollection               | 0      | ?              | ?                                  
3  | model                | TimmModel                      | 11.2 M | [1, 3, 32, 32] | [[1, 512, 4, 4], [0], [0], [1, 10]]
4  | input_normalizer     | Normalize                      | 0      | ?              | ?                                  
5  | default_augmentation | Sequential                     | 0      | ?              | ?                                  
6  | augmentations        | ModuleDict                     | 0      | ?              | ?                                  
7  | test_confusion       | MulticlassConfusionMatrix      | 0      | ?              | ?                                  
8  | test_roc             | MulticlassROC                  | 0      | ?              | ?                                  
9  | test_pr_curve        | MulticlassPrecisionRecallCurve | 0      | ?              | ?                                  
10 | metrics              | ModuleDict                     | 0      | ?              | ?                                  
--------------------------------------------------------------------------------------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.696    Total estimated model params size (MB)
[2024-05-16 18:05:39,752][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-16 18:05:39,752][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-16 18:05:39,758][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-16 18:05:41,214][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-16 18:05:41,214][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-16 18:05:41,215][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-16 18:05:41,215][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-16 18:05:41,215][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-16 18:05:53,677][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 0, global step 24: 'val_error' reached 0.76050 (best 0.76050), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=24.ckpt' as top 1
[2024-05-16 18:06:06,396][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 1, global step 48: 'val_error' reached 0.72290 (best 0.72290), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=1-step=48.ckpt' as top 1
[2024-05-16 18:06:13,830][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...

[2024-05-16 18:06:13,836][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-16 18:06:13,836][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-16 18:06:14,071][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=1-step=48.ckpt
[2024-05-16 18:06:14,107][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-16 18:06:14,224][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-16 18:06:14,224][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-16 18:06:14,226][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-16 18:06:14,326][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...

[2024-05-16 18:06:14,333][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-16 18:06:14,334][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-16 18:06:14,371][hannah.train][INFO] - Averaged Result Metrics:
| Metric              |     Mean |   Std |   Count |
|---------------------|----------|-------|---------|
| val_classifier_loss | 1.93342  |     0 |       1 |
| val_accuracy        | 0.2771   |     0 |       1 |
| val_error           | 0.7229   |     0 |       1 |
| val_f1              | 0.267421 |     0 |       1 |
| val_precision       | 0.287816 |     0 |       1 |
| val_recall          | 0.277468 |     0 |       1 |
| val_loss            | 1.93342  |     0 |       1 |
[2024-05-22 12:07:32,875][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 12:07:32,997][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 12:07:32,999][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 12:07:33,002][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 12:07:33,002][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 12:07:33,002][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 12:07:33,002][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 12:07:33,002][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 12:07:33,002][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 12:07:33,002][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 12:07:33,004][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 12:07:33,004][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train
[2024-05-22 12:07:33,004][hannah.utils.utils][INFO] -   
[2024-05-22 12:07:33,005][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 12:07:33,034][root][INFO] - Configuration: 
[2024-05-22 12:07:33,037][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 12:07:33,037][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 12:07:33,824][root][WARNING] - Could not import kornia augmentations if needed install with -E vision
[2024-05-22 12:07:33,824][root][ERROR] - Exception Message: Error locating target 'hannah.modules.vision.ImageClassifierModule', set env var HYDRA_FULL_ERROR=1 to see chained exception.
full_key: module
Traceback (most recent call last):
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 644, in _locate
    obj = getattr(obj, part)
          ^^^^^^^^^^^^^^^^^^
AttributeError: module 'hannah.modules' has no attribute 'vision'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 650, in _locate
    obj = import_module(mod)
          ^^^^^^^^^^^^^^^^^^
  File "/usr/lib64/python3.11/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1147, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/local/gerum/hannah/hannah/modules/vision/__init__.py", line 19, in <module>
    from .anomaly_detection import AnomalyDetectionModule
  File "/local/gerum/hannah/hannah/modules/vision/anomaly_detection.py", line 34, in <module>
    from .base import VisionBaseModule
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 24, in <module>
    import kornia
ModuleNotFoundError: No module named 'kornia'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 134, in _resolve_target
    target = _locate(target)
             ^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 653, in _locate
    raise ImportError(
ImportError: Error loading 'hannah.modules.vision.ImageClassifierModule':
ModuleNotFoundError("No module named 'kornia'")
Are you sure that 'vision' is importable from module 'hannah.modules'?

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 93, in train
    lit_module = instantiate(
                 ^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 226, in instantiate
    return instantiate_node(
           ^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 333, in instantiate_node
    _target_ = _resolve_target(node.get(_Keys.TARGET), full_key)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 139, in _resolve_target
    raise InstantiationException(msg) from e
hydra.errors.InstantiationException: Error locating target 'hannah.modules.vision.ImageClassifierModule', set env var HYDRA_FULL_ERROR=1 to see chained exception.
full_key: module
[2024-05-22 12:09:00,305][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 12:09:00,398][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 12:09:00,399][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 12:09:00,402][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 12:09:00,402][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 12:09:00,403][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 12:09:00,403][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 12:09:00,403][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 12:09:00,403][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 12:09:00,403][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 12:09:00,404][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 12:09:00,404][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train
[2024-05-22 12:09:00,404][hannah.utils.utils][INFO] -   
[2024-05-22 12:09:00,405][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 12:09:00,407][root][INFO] - Configuration: 
[2024-05-22 12:09:00,410][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 12:09:00,410][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 12:09:01,137][root][WARNING] - Could not import kornia augmentations if needed install with -E vision
[2024-05-22 12:09:01,143][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 12:09:01,144][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 12:09:01,210][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 12:09:01,235][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 12:09:01,242][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 12:09:01,242][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 12:09:01,242][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 12:09:01,242][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 12:09:01,242][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 12:09:01,242][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 12:09:01,242][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 12:09:01,242][root][INFO] - Starting training
[2024-05-22 12:09:02,649][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:64: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 12:09:02,649][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 12:09:02,649][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 12:09:02,650][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 12:09:02,650][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 12:09:02,650][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 12:09:02,651][hannah.modules.vision.base][INFO] - Setting up model resnet18
[2024-05-22 12:09:02,884][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:803: UserWarning: Overwriting focalnet_tiny_srf in registry with hannah.models._vendor.focalnet.focalnet_tiny_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:09:02,884][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:824: UserWarning: Overwriting focalnet_small_srf in registry with hannah.models._vendor.focalnet.focalnet_small_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:09:02,884][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:843: UserWarning: Overwriting focalnet_base_srf in registry with hannah.models._vendor.focalnet.focalnet_base_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:09:02,884][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:862: UserWarning: Overwriting focalnet_tiny_lrf in registry with hannah.models._vendor.focalnet.focalnet_tiny_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:09:02,884][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:885: UserWarning: Overwriting focalnet_small_lrf in registry with hannah.models._vendor.focalnet.focalnet_small_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:09:02,885][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:906: UserWarning: Overwriting focalnet_base_lrf in registry with hannah.models._vendor.focalnet.focalnet_base_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:09:02,885][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1010: UserWarning: Overwriting focalnet_large_fl3 in registry with hannah.models._vendor.focalnet.focalnet_large_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:09:02,885][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1031: UserWarning: Overwriting focalnet_large_fl4 in registry with hannah.models._vendor.focalnet.focalnet_large_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:09:02,885][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1052: UserWarning: Overwriting focalnet_xlarge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:09:02,885][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1073: UserWarning: Overwriting focalnet_xlarge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:09:02,885][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1094: UserWarning: Overwriting focalnet_huge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:09:02,885][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1115: UserWarning: Overwriting focalnet_huge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:09:03,013][hannah.models.timm][INFO] - Using default logger for automatic stem creation
[2024-05-22 12:09:03,014][hannah.models.timm][INFO] - Small input size detected trying to adopt small input size
[2024-05-22 12:09:03,030][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '

[2024-05-22 12:09:03,226][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)
[2024-05-22 12:09:03,233][root][ERROR] - Exception Message: 'ImageClassifierModule' object has no attribute 'setup_augmentations'
Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 949, in _run
    call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 94, in _call_setup_hook
    _call_lightning_module_hook(trainer, "setup", stage=fn)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 137, in setup
    self.setup_augmentations(self.hparams.augmentation)
    ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/module.py", line 1688, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'ImageClassifierModule' object has no attribute 'setup_augmentations'
[2024-05-22 12:17:45,842][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 12:17:45,930][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 12:17:45,930][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 12:17:45,934][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 12:17:45,934][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 12:17:45,934][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 12:17:45,934][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 12:17:45,934][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 12:17:45,934][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 12:17:45,934][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 12:17:45,936][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 12:17:45,936][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train
[2024-05-22 12:17:45,936][hannah.utils.utils][INFO] -   
[2024-05-22 12:17:45,937][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 12:17:45,938][root][INFO] - Configuration: 
[2024-05-22 12:17:45,941][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 12:17:45,941][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 12:17:46,718][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 12:17:46,718][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 12:17:46,774][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 12:17:46,798][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 12:17:46,805][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 12:17:46,805][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 12:17:46,805][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 12:17:46,805][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 12:17:46,805][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 12:17:46,805][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 12:17:46,805][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 12:17:46,806][root][INFO] - Starting training
[2024-05-22 12:17:48,310][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 12:17:48,310][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 12:17:48,310][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 12:17:48,311][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 12:17:48,311][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 12:17:48,311][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 12:17:48,312][hannah.modules.vision.base][INFO] - Setting up model resnet18
[2024-05-22 12:17:48,475][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:803: UserWarning: Overwriting focalnet_tiny_srf in registry with hannah.models._vendor.focalnet.focalnet_tiny_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:17:48,475][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:824: UserWarning: Overwriting focalnet_small_srf in registry with hannah.models._vendor.focalnet.focalnet_small_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:17:48,475][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:843: UserWarning: Overwriting focalnet_base_srf in registry with hannah.models._vendor.focalnet.focalnet_base_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:17:48,475][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:862: UserWarning: Overwriting focalnet_tiny_lrf in registry with hannah.models._vendor.focalnet.focalnet_tiny_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:17:48,475][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:885: UserWarning: Overwriting focalnet_small_lrf in registry with hannah.models._vendor.focalnet.focalnet_small_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:17:48,475][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:906: UserWarning: Overwriting focalnet_base_lrf in registry with hannah.models._vendor.focalnet.focalnet_base_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:17:48,475][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1010: UserWarning: Overwriting focalnet_large_fl3 in registry with hannah.models._vendor.focalnet.focalnet_large_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:17:48,475][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1031: UserWarning: Overwriting focalnet_large_fl4 in registry with hannah.models._vendor.focalnet.focalnet_large_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:17:48,475][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1052: UserWarning: Overwriting focalnet_xlarge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:17:48,476][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1073: UserWarning: Overwriting focalnet_xlarge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:17:48,476][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1094: UserWarning: Overwriting focalnet_huge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:17:48,476][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1115: UserWarning: Overwriting focalnet_huge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:17:48,604][hannah.models.timm][INFO] - Using default logger for automatic stem creation
[2024-05-22 12:17:48,604][hannah.models.timm][INFO] - Small input size detected trying to adopt small input size
[2024-05-22 12:17:48,676][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '

[2024-05-22 12:17:49,002][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)
[2024-05-22 12:17:49,007][hannah.modules.vision.base][INFO] - Running dummy forward to initialize lazy modules
[2024-05-22 12:17:49,022][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 12:17:49,136][pytorch_lightning.utilities.rank_zero][INFO] - Loading `train_dataloader` to estimate number of stepping batches.
[2024-05-22 12:17:49,137][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=191` in the `DataLoader` to improve performance.

[2024-05-22 12:17:49,158][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

[2024-05-22 12:17:49,401][pytorch_lightning.callbacks.model_summary][INFO] - 
  | Name           | Type                           | Params | In sizes       | Out sizes                          
-------------------------------------------------------------------------------------------------------------------------
0 | val_metrics    | MetricCollection               | 0      | ?              | ?                                  
1 | test_metrics   | MetricCollection               | 0      | ?              | ?                                  
2 | train_metrics  | MetricCollection               | 0      | ?              | ?                                  
3 | model          | TimmModel                      | 11.2 M | [1, 3, 32, 32] | [[1, 512, 4, 4], [0], [0], [1, 10]]
4 | test_confusion | MulticlassConfusionMatrix      | 0      | ?              | ?                                  
5 | test_roc       | MulticlassROC                  | 0      | ?              | ?                                  
6 | test_pr_curve  | MulticlassPrecisionRecallCurve | 0      | ?              | ?                                  
7 | metrics        | ModuleDict                     | 0      | ?              | ?                                  
-------------------------------------------------------------------------------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.696    Total estimated model params size (MB)
[2024-05-22 12:17:49,536][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 12:17:49,537][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 12:17:49,542][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 12:17:49,834][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=191` in the `DataLoader` to improve performance.

[2024-05-22 12:17:49,976][root][ERROR] - Exception Message: 'ImageClassifierModule' object has no attribute 'augment'
Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1031, in _run_stage
    self._run_sanity_check()
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1060, in _run_sanity_check
    val_loop.run()
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 309, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 412, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/image_classifier.py", line 133, in validation_step
    loss, prediction_result, batch, preds = self.common_step(
                                            ^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/image_classifier.py", line 59, in common_step
    augmented_data, x = self.augment(x, labels, boxes, batch_idx)
                        ^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/module.py", line 1688, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'ImageClassifierModule' object has no attribute 'augment'
[2024-05-22 12:18:34,540][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 12:18:34,631][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 12:18:34,632][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 12:18:34,635][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 12:18:34,635][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 12:18:34,635][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 12:18:34,635][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 12:18:34,636][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 12:18:34,636][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 12:18:34,636][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 12:18:34,637][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 12:18:34,637][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train
[2024-05-22 12:18:34,637][hannah.utils.utils][INFO] -   
[2024-05-22 12:18:34,638][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 12:18:34,639][root][INFO] - Configuration: 
[2024-05-22 12:18:34,642][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 12:18:34,643][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 12:18:35,395][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 12:18:35,396][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 12:18:35,466][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 12:18:35,490][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 12:18:35,497][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 12:18:35,497][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 12:18:35,497][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 12:18:35,497][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 12:18:35,497][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 12:18:35,497][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 12:18:35,498][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 12:18:35,498][root][INFO] - Starting training
[2024-05-22 12:18:36,922][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 12:18:36,922][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 12:18:36,922][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 12:18:36,923][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 12:18:36,923][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 12:18:36,923][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 12:18:36,923][hannah.modules.vision.base][INFO] - Setting up model resnet18
[2024-05-22 12:18:37,084][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:803: UserWarning: Overwriting focalnet_tiny_srf in registry with hannah.models._vendor.focalnet.focalnet_tiny_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:18:37,085][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:824: UserWarning: Overwriting focalnet_small_srf in registry with hannah.models._vendor.focalnet.focalnet_small_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:18:37,085][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:843: UserWarning: Overwriting focalnet_base_srf in registry with hannah.models._vendor.focalnet.focalnet_base_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:18:37,085][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:862: UserWarning: Overwriting focalnet_tiny_lrf in registry with hannah.models._vendor.focalnet.focalnet_tiny_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:18:37,085][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:885: UserWarning: Overwriting focalnet_small_lrf in registry with hannah.models._vendor.focalnet.focalnet_small_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:18:37,085][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:906: UserWarning: Overwriting focalnet_base_lrf in registry with hannah.models._vendor.focalnet.focalnet_base_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:18:37,085][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1010: UserWarning: Overwriting focalnet_large_fl3 in registry with hannah.models._vendor.focalnet.focalnet_large_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:18:37,085][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1031: UserWarning: Overwriting focalnet_large_fl4 in registry with hannah.models._vendor.focalnet.focalnet_large_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:18:37,085][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1052: UserWarning: Overwriting focalnet_xlarge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:18:37,085][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1073: UserWarning: Overwriting focalnet_xlarge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:18:37,085][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1094: UserWarning: Overwriting focalnet_huge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:18:37,085][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1115: UserWarning: Overwriting focalnet_huge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:18:37,212][hannah.models.timm][INFO] - Using default logger for automatic stem creation
[2024-05-22 12:18:37,212][hannah.models.timm][INFO] - Small input size detected trying to adopt small input size
[2024-05-22 12:18:37,229][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '

[2024-05-22 12:18:37,563][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)
[2024-05-22 12:18:37,568][hannah.modules.vision.base][INFO] - Running dummy forward to initialize lazy modules
[2024-05-22 12:18:37,583][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 12:18:37,647][pytorch_lightning.utilities.rank_zero][INFO] - Loading `train_dataloader` to estimate number of stepping batches.
[2024-05-22 12:18:37,648][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=191` in the `DataLoader` to improve performance.

[2024-05-22 12:18:37,655][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

[2024-05-22 12:18:37,873][pytorch_lightning.callbacks.model_summary][INFO] - 
  | Name           | Type                           | Params | In sizes       | Out sizes                          
-------------------------------------------------------------------------------------------------------------------------
0 | val_metrics    | MetricCollection               | 0      | ?              | ?                                  
1 | test_metrics   | MetricCollection               | 0      | ?              | ?                                  
2 | train_metrics  | MetricCollection               | 0      | ?              | ?                                  
3 | model          | TimmModel                      | 11.2 M | [1, 3, 32, 32] | [[1, 512, 4, 4], [0], [0], [1, 10]]
4 | test_confusion | MulticlassConfusionMatrix      | 0      | ?              | ?                                  
5 | test_roc       | MulticlassROC                  | 0      | ?              | ?                                  
6 | test_pr_curve  | MulticlassPrecisionRecallCurve | 0      | ?              | ?                                  
7 | metrics        | ModuleDict                     | 0      | ?              | ?                                  
-------------------------------------------------------------------------------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.696    Total estimated model params size (MB)
[2024-05-22 12:18:38,006][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 12:18:38,006][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 12:18:38,012][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 12:18:38,316][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=191` in the `DataLoader` to improve performance.

[2024-05-22 12:18:38,871][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 12:18:38,871][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 12:18:38,871][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 12:18:38,871][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 12:18:38,871][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 12:18:46,240][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 0, global step 21: 'val_error' reached 0.88940 (best 0.88940), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=21.ckpt' as top 1
[2024-05-22 12:18:53,576][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 1, global step 42: 'val_error' reached 0.75220 (best 0.75220), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=1-step=42.ckpt' as top 1
[2024-05-22 12:19:01,085][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 2, global step 63: 'val_error' reached 0.67798 (best 0.67798), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=2-step=63.ckpt' as top 1
[2024-05-22 12:19:07,635][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 3, global step 84: 'val_error' reached 0.64990 (best 0.64990), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=3-step=84.ckpt' as top 1
[2024-05-22 12:19:15,794][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 4, global step 105: 'val_error' was not in top 1
[2024-05-22 12:19:23,799][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 5, global step 126: 'val_error' reached 0.59644 (best 0.59644), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=5-step=126.ckpt' as top 1
[2024-05-22 12:19:32,148][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 6, global step 147: 'val_error' was not in top 1
[2024-05-22 12:19:40,123][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 7, global step 168: 'val_error' reached 0.58276 (best 0.58276), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=7-step=168.ckpt' as top 1
[2024-05-22 12:19:48,493][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 8, global step 189: 'val_error' was not in top 1
[2024-05-22 12:19:56,510][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 9, global step 210: 'val_error' was not in top 1
[2024-05-22 12:20:04,497][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 10, global step 231: 'val_error' was not in top 1
[2024-05-22 12:20:12,805][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 11, global step 252: 'val_error' was not in top 1
[2024-05-22 12:20:20,798][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 12, global step 273: 'val_error' reached 0.41846 (best 0.41846), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=12-step=273.ckpt' as top 1
[2024-05-22 12:20:29,003][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 13, global step 294: 'val_error' was not in top 1
[2024-05-22 12:20:37,181][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 14, global step 315: 'val_error' reached 0.34009 (best 0.34009), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=14-step=315.ckpt' as top 1
[2024-05-22 12:20:45,482][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 15, global step 336: 'val_error' was not in top 1
[2024-05-22 12:20:53,508][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 16, global step 357: 'val_error' was not in top 1
[2024-05-22 12:21:01,667][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 17, global step 378: 'val_error' reached 0.32080 (best 0.32080), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=17-step=378.ckpt' as top 1
[2024-05-22 12:21:09,845][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 18, global step 399: 'val_error' was not in top 1
[2024-05-22 12:21:17,985][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 19, global step 420: 'val_error' was not in top 1
[2024-05-22 12:21:26,245][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 20, global step 441: 'val_error' reached 0.30933 (best 0.30933), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=20-step=441.ckpt' as top 1
[2024-05-22 12:21:34,431][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 21, global step 462: 'val_error' was not in top 1
[2024-05-22 12:21:42,453][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 22, global step 483: 'val_error' was not in top 1
[2024-05-22 12:21:50,424][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 23, global step 504: 'val_error' reached 0.28833 (best 0.28833), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=23-step=504.ckpt' as top 1
[2024-05-22 12:21:58,881][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 24, global step 525: 'val_error' was not in top 1
[2024-05-22 12:22:06,932][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 25, global step 546: 'val_error' reached 0.25439 (best 0.25439), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=25-step=546.ckpt' as top 1
[2024-05-22 12:22:15,230][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 26, global step 567: 'val_error' was not in top 1
[2024-05-22 12:22:23,240][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 27, global step 588: 'val_error' reached 0.23926 (best 0.23926), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=27-step=588.ckpt' as top 1
[2024-05-22 12:22:31,432][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 28, global step 609: 'val_error' reached 0.23413 (best 0.23413), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=28-step=609.ckpt' as top 1
[2024-05-22 12:22:39,570][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 29, global step 630: 'val_error' reached 0.22974 (best 0.22974), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=29-step=630.ckpt' as top 1
[2024-05-22 12:22:47,852][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 30, global step 651: 'val_error' reached 0.22632 (best 0.22632), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=30-step=651.ckpt' as top 1
[2024-05-22 12:22:56,272][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 31, global step 672: 'val_error' was not in top 1
[2024-05-22 12:23:04,175][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 32, global step 693: 'val_error' reached 0.22607 (best 0.22607), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=32-step=693.ckpt' as top 1
[2024-05-22 12:23:12,612][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 33, global step 714: 'val_error' was not in top 1
[2024-05-22 12:23:20,601][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 34, global step 735: 'val_error' reached 0.22437 (best 0.22437), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=34-step=735.ckpt' as top 1
[2024-05-22 12:23:28,859][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 35, global step 756: 'val_error' was not in top 1
[2024-05-22 12:23:36,884][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 36, global step 777: 'val_error' was not in top 1
[2024-05-22 12:23:45,497][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 37, global step 798: 'val_error' was not in top 1
[2024-05-22 12:23:47,979][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...

[2024-05-22 12:23:47,985][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 12:23:47,985][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 12:23:47,987][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=34-step=735.ckpt
[2024-05-22 12:23:48,235][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 12:23:48,342][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 12:23:48,343][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 12:23:48,344][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 12:23:48,499][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 12:23:48,500][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 12:23:48,501][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=34-step=735.ckpt
[2024-05-22 12:23:48,523][hannah.train][INFO] - Averaged Result Metrics:
| Metric              |     Mean |   Std |   Count |
|---------------------|----------|-------|---------|
| val_classifier_loss | 0.872247 |     0 |       1 |
| val_accuracy        | 0.773926 |     0 |       1 |
| val_error           | 0.226074 |     0 |       1 |
| val_f1              | 0.772754 |     0 |       1 |
| val_precision       | 0.773625 |     0 |       1 |
| val_recall          | 0.773026 |     0 |       1 |
| val_loss            | 0.872247 |     0 |       1 |
[2024-05-22 12:24:00,104][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 12:24:00,215][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 12:24:00,216][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 12:24:00,220][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 12:24:00,220][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 12:24:00,220][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 12:24:00,220][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 12:24:00,220][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 12:24:00,220][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 12:24:00,220][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 12:24:00,222][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 12:24:00,222][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32
[2024-05-22 12:24:00,222][hannah.utils.utils][INFO] -   
[2024-05-22 12:24:00,223][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 12:24:00,257][root][INFO] - Configuration: 
[2024-05-22 12:24:00,260][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 12:24:00,260][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 12:24:01,034][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 12:24:01,034][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 12:24:01,102][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 12:24:01,126][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 12:24:01,133][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 12:24:01,133][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 12:24:01,133][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 12:24:01,133][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 12:24:01,133][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 12:24:01,133][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 12:24:01,133][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 12:24:01,133][root][INFO] - Starting training
[2024-05-22 12:24:02,766][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 12:24:02,766][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 12:24:02,767][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 12:24:02,767][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 12:24:02,767][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 12:24:02,767][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 12:24:02,768][hannah.modules.vision.base][INFO] - Setting up model resnet18
[2024-05-22 12:24:02,936][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:803: UserWarning: Overwriting focalnet_tiny_srf in registry with hannah.models._vendor.focalnet.focalnet_tiny_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:24:02,936][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:824: UserWarning: Overwriting focalnet_small_srf in registry with hannah.models._vendor.focalnet.focalnet_small_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:24:02,936][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:843: UserWarning: Overwriting focalnet_base_srf in registry with hannah.models._vendor.focalnet.focalnet_base_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:24:02,937][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:862: UserWarning: Overwriting focalnet_tiny_lrf in registry with hannah.models._vendor.focalnet.focalnet_tiny_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:24:02,937][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:885: UserWarning: Overwriting focalnet_small_lrf in registry with hannah.models._vendor.focalnet.focalnet_small_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:24:02,937][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:906: UserWarning: Overwriting focalnet_base_lrf in registry with hannah.models._vendor.focalnet.focalnet_base_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:24:02,937][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1010: UserWarning: Overwriting focalnet_large_fl3 in registry with hannah.models._vendor.focalnet.focalnet_large_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:24:02,937][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1031: UserWarning: Overwriting focalnet_large_fl4 in registry with hannah.models._vendor.focalnet.focalnet_large_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:24:02,937][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1052: UserWarning: Overwriting focalnet_xlarge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:24:02,937][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1073: UserWarning: Overwriting focalnet_xlarge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:24:02,937][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1094: UserWarning: Overwriting focalnet_huge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:24:02,937][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1115: UserWarning: Overwriting focalnet_huge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 12:24:03,073][hannah.models.timm][INFO] - Using default logger for automatic stem creation
[2024-05-22 12:24:03,073][hannah.models.timm][INFO] - Small input size detected trying to adopt small input size
[2024-05-22 12:24:03,089][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '

[2024-05-22 12:24:03,508][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)
[2024-05-22 12:24:03,513][hannah.modules.vision.base][INFO] - Running dummy forward to initialize lazy modules
[2024-05-22 12:24:03,525][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 12:24:03,907][pytorch_lightning.utilities.rank_zero][INFO] - Loading `train_dataloader` to estimate number of stepping batches.
[2024-05-22 12:24:04,477][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

[2024-05-22 12:24:04,938][pytorch_lightning.callbacks.model_summary][INFO] - 
  | Name           | Type                           | Params | In sizes       | Out sizes                          
-------------------------------------------------------------------------------------------------------------------------
0 | val_metrics    | MetricCollection               | 0      | ?              | ?                                  
1 | test_metrics   | MetricCollection               | 0      | ?              | ?                                  
2 | train_metrics  | MetricCollection               | 0      | ?              | ?                                  
3 | model          | TimmModel                      | 11.2 M | [1, 3, 32, 32] | [[1, 512, 4, 4], [0], [0], [1, 10]]
4 | test_confusion | MulticlassConfusionMatrix      | 0      | ?              | ?                                  
5 | test_roc       | MulticlassROC                  | 0      | ?              | ?                                  
6 | test_pr_curve  | MulticlassPrecisionRecallCurve | 0      | ?              | ?                                  
7 | metrics        | ModuleDict                     | 0      | ?              | ?                                  
-------------------------------------------------------------------------------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.696    Total estimated model params size (MB)
[2024-05-22 12:24:05,201][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 12:24:05,202][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 12:24:05,221][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 12:24:06,897][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 12:24:06,898][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 12:24:06,898][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 12:24:06,898][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 12:24:06,898][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 12:24:13,280][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 0, global step 21: 'val_error' reached 0.88940 (best 0.88940), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=21.ckpt' as top 1
[2024-05-22 12:24:20,032][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 1, global step 42: 'val_error' reached 0.75757 (best 0.75757), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=1-step=42.ckpt' as top 1
[2024-05-22 12:24:26,803][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 2, global step 63: 'val_error' reached 0.66455 (best 0.66455), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=2-step=63.ckpt' as top 1
[2024-05-22 12:24:33,642][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 3, global step 84: 'val_error' reached 0.65454 (best 0.65454), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=3-step=84.ckpt' as top 1
[2024-05-22 12:24:40,644][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 4, global step 105: 'val_error' was not in top 1
[2024-05-22 12:24:47,248][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 5, global step 126: 'val_error' reached 0.59985 (best 0.59985), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=5-step=126.ckpt' as top 1
[2024-05-22 12:24:54,074][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 6, global step 147: 'val_error' was not in top 1
[2024-05-22 12:25:00,631][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 7, global step 168: 'val_error' was not in top 1
[2024-05-22 12:25:07,410][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 8, global step 189: 'val_error' was not in top 1
[2024-05-22 12:25:14,155][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 9, global step 210: 'val_error' reached 0.55811 (best 0.55811), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=210.ckpt' as top 1
[2024-05-22 12:25:20,999][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 10, global step 231: 'val_error' was not in top 1
[2024-05-22 12:25:27,661][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 11, global step 252: 'val_error' reached 0.44556 (best 0.44556), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=11-step=252.ckpt' as top 1
[2024-05-22 12:25:34,650][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 12, global step 273: 'val_error' reached 0.44141 (best 0.44141), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=12-step=273.ckpt' as top 1
[2024-05-22 12:25:41,513][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 13, global step 294: 'val_error' was not in top 1
[2024-05-22 12:25:48,223][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 14, global step 315: 'val_error' reached 0.39941 (best 0.39941), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=14-step=315.ckpt' as top 1
[2024-05-22 12:25:55,130][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 15, global step 336: 'val_error' reached 0.35034 (best 0.35034), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=15-step=336.ckpt' as top 1
[2024-05-22 12:26:02,018][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 16, global step 357: 'val_error' was not in top 1
[2024-05-22 12:26:08,638][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 17, global step 378: 'val_error' was not in top 1
[2024-05-22 12:26:15,332][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 18, global step 399: 'val_error' was not in top 1
[2024-05-22 12:26:21,965][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 19, global step 420: 'val_error' was not in top 1
[2024-05-22 12:26:28,580][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 20, global step 441: 'val_error' was not in top 1
[2024-05-22 12:26:35,365][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 21, global step 462: 'val_error' reached 0.29468 (best 0.29468), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=21-step=462.ckpt' as top 1
[2024-05-22 12:26:42,145][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 22, global step 483: 'val_error' was not in top 1
[2024-05-22 12:26:49,126][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 23, global step 504: 'val_error' was not in top 1
[2024-05-22 12:26:55,756][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 24, global step 525: 'val_error' was not in top 1
[2024-05-22 12:27:02,420][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 25, global step 546: 'val_error' reached 0.29175 (best 0.29175), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=25-step=546.ckpt' as top 1
[2024-05-22 12:27:09,282][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 26, global step 567: 'val_error' was not in top 1
[2024-05-22 12:27:16,004][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 27, global step 588: 'val_error' reached 0.27637 (best 0.27637), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=27-step=588.ckpt' as top 1
[2024-05-22 12:27:23,016][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 28, global step 609: 'val_error' reached 0.24512 (best 0.24512), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=28-step=609.ckpt' as top 1
[2024-05-22 12:27:29,889][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 29, global step 630: 'val_error' reached 0.23706 (best 0.23706), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=29-step=630.ckpt' as top 1
[2024-05-22 12:27:36,943][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 30, global step 651: 'val_error' reached 0.23218 (best 0.23218), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=30-step=651.ckpt' as top 1
[2024-05-22 12:27:43,833][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 31, global step 672: 'val_error' reached 0.23047 (best 0.23047), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=31-step=672.ckpt' as top 1
[2024-05-22 12:27:50,716][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 32, global step 693: 'val_error' was not in top 1
[2024-05-22 12:27:57,397][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 33, global step 714: 'val_error' reached 0.22778 (best 0.22778), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=33-step=714.ckpt' as top 1
[2024-05-22 12:28:04,236][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 34, global step 735: 'val_error' was not in top 1
[2024-05-22 12:28:10,949][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 35, global step 756: 'val_error' was not in top 1
[2024-05-22 12:28:17,597][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 36, global step 777: 'val_error' reached 0.22583 (best 0.22583), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=36-step=777.ckpt' as top 1
[2024-05-22 12:28:24,500][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 37, global step 798: 'val_error' reached 0.22437 (best 0.22437), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=37-step=798.ckpt' as top 1
[2024-05-22 12:28:31,248][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 38, global step 819: 'val_error' was not in top 1
[2024-05-22 12:28:37,774][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 39, global step 840: 'val_error' was not in top 1
[2024-05-22 12:28:44,465][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 40, global step 861: 'val_error' was not in top 1
[2024-05-22 12:28:51,163][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 41, global step 882: 'val_error' was not in top 1
[2024-05-22 12:28:57,887][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 42, global step 903: 'val_error' reached 0.22290 (best 0.22290), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=42-step=903.ckpt' as top 1
[2024-05-22 12:29:04,771][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 43, global step 924: 'val_error' reached 0.22241 (best 0.22241), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=43-step=924.ckpt' as top 1
[2024-05-22 12:29:11,528][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 44, global step 945: 'val_error' reached 0.22119 (best 0.22119), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=44-step=945.ckpt' as top 1
[2024-05-22 12:29:18,275][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 45, global step 966: 'val_error' was not in top 1
[2024-05-22 12:29:24,884][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 46, global step 987: 'val_error' reached 0.22095 (best 0.22095), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=46-step=987.ckpt' as top 1
[2024-05-22 12:29:31,592][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 47, global step 1008: 'val_error' was not in top 1
[2024-05-22 12:29:38,290][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 48, global step 1029: 'val_error' was not in top 1
[2024-05-22 12:29:45,124][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 49, global step 1050: 'val_error' was not in top 1
[2024-05-22 12:29:45,337][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer.fit` stopped: `max_epochs=50` reached.
[2024-05-22 12:29:45,864][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 12:29:45,865][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 12:29:45,866][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=46-step=987.ckpt
[2024-05-22 12:29:45,917][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 12:29:46,457][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 12:29:46,457][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 12:29:46,459][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 12:29:46,690][pytorch_lightning.utilities.rank_zero][INFO] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=46-step=987.ckpt
[2024-05-22 12:29:48,085][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 12:29:48,086][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 12:29:48,088][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=46-step=987.ckpt
[2024-05-22 12:29:48,128][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 12:29:48,658][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 12:29:48,659][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 12:29:48,661][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 12:29:48,884][pytorch_lightning.utilities.rank_zero][INFO] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=46-step=987.ckpt
[2024-05-22 12:29:50,459][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 12:29:50,459][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 12:29:50,460][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 12:29:50,460][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 12:29:50,460][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 12:29:50,461][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 12:29:50,462][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 12:29:51,004][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 12:29:51,155][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 12:29:51,468][hannah.train][INFO] - Averaged Result Metrics:
| Metric               |     Mean |   Std |   Count |
|----------------------|----------|-------|---------|
| test_classifier_loss | 0.847495 |     0 |       1 |
| test_accuracy        | 0.779663 |     0 |       1 |
| test_error           | 0.220337 |     0 |       1 |
| test_f1              | 0.779137 |     0 |       1 |
| test_precision       | 0.779131 |     0 |       1 |
| test_recall          | 0.780323 |     0 |       1 |
| test_loss            | 0.847495 |     0 |       1 |
[2024-05-22 12:29:51,479][hannah.train][INFO] - Averaged Result Metrics:
| Metric              |     Mean |   Std |   Count |
|---------------------|----------|-------|---------|
| val_classifier_loss | 0.84375  |     0 |       1 |
| val_accuracy        | 0.779053 |     0 |       1 |
| val_error           | 0.220947 |     0 |       1 |
| val_f1              | 0.777967 |     0 |       1 |
| val_precision       | 0.77821  |     0 |       1 |
| val_recall          | 0.778309 |     0 |       1 |
| val_loss            | 0.84375  |     0 |       1 |
[2024-05-22 13:11:29,760][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 13:11:29,864][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 13:11:29,865][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 13:11:29,869][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 13:11:29,869][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 13:11:29,869][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 13:11:29,869][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 13:11:29,869][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 13:11:29,869][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 13:11:29,869][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 13:11:29,870][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 13:11:29,871][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32
[2024-05-22 13:11:29,871][hannah.utils.utils][INFO] -   
[2024-05-22 13:11:29,872][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 13:11:29,905][root][INFO] - Configuration: 
[2024-05-22 13:11:29,908][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 13:11:29,908][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 13:11:30,674][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 13:11:30,674][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 13:11:30,742][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 13:11:30,766][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 13:11:30,772][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 13:11:30,772][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 13:11:30,772][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 13:11:30,772][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 13:11:30,773][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 13:11:30,773][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 13:11:30,773][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 13:11:30,773][root][INFO] - Starting training
[2024-05-22 13:11:32,504][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 13:11:32,504][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 13:11:32,504][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 13:11:32,505][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 13:11:32,505][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 13:11:32,505][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 13:11:32,506][hannah.modules.vision.base][INFO] - Setting up model resnet18
[2024-05-22 13:11:32,678][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:803: UserWarning: Overwriting focalnet_tiny_srf in registry with hannah.models._vendor.focalnet.focalnet_tiny_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 13:11:32,678][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:824: UserWarning: Overwriting focalnet_small_srf in registry with hannah.models._vendor.focalnet.focalnet_small_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 13:11:32,678][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:843: UserWarning: Overwriting focalnet_base_srf in registry with hannah.models._vendor.focalnet.focalnet_base_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 13:11:32,678][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:862: UserWarning: Overwriting focalnet_tiny_lrf in registry with hannah.models._vendor.focalnet.focalnet_tiny_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 13:11:32,678][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:885: UserWarning: Overwriting focalnet_small_lrf in registry with hannah.models._vendor.focalnet.focalnet_small_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 13:11:32,679][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:906: UserWarning: Overwriting focalnet_base_lrf in registry with hannah.models._vendor.focalnet.focalnet_base_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 13:11:32,679][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1010: UserWarning: Overwriting focalnet_large_fl3 in registry with hannah.models._vendor.focalnet.focalnet_large_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 13:11:32,679][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1031: UserWarning: Overwriting focalnet_large_fl4 in registry with hannah.models._vendor.focalnet.focalnet_large_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 13:11:32,679][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1052: UserWarning: Overwriting focalnet_xlarge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 13:11:32,679][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1073: UserWarning: Overwriting focalnet_xlarge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 13:11:32,679][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1094: UserWarning: Overwriting focalnet_huge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 13:11:32,679][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1115: UserWarning: Overwriting focalnet_huge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 13:11:32,822][hannah.models.timm][INFO] - Using default logger for automatic stem creation
[2024-05-22 13:11:32,822][hannah.models.timm][INFO] - Small input size detected trying to adopt small input size
[2024-05-22 13:11:32,839][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '

[2024-05-22 13:11:33,267][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)
[2024-05-22 13:11:33,272][hannah.modules.vision.base][INFO] - Running dummy forward to initialize lazy modules
[2024-05-22 13:11:33,287][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 13:11:33,668][pytorch_lightning.utilities.rank_zero][INFO] - Loading `train_dataloader` to estimate number of stepping batches.
[2024-05-22 13:11:34,171][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

[2024-05-22 13:11:34,627][pytorch_lightning.callbacks.model_summary][INFO] - 
  | Name           | Type                           | Params | In sizes       | Out sizes                          
-------------------------------------------------------------------------------------------------------------------------
0 | val_metrics    | MetricCollection               | 0      | ?              | ?                                  
1 | test_metrics   | MetricCollection               | 0      | ?              | ?                                  
2 | train_metrics  | MetricCollection               | 0      | ?              | ?                                  
3 | model          | TimmModel                      | 11.2 M | [1, 3, 32, 32] | [[1, 512, 4, 4], [0], [0], [1, 10]]
4 | test_confusion | MulticlassConfusionMatrix      | 0      | ?              | ?                                  
5 | test_roc       | MulticlassROC                  | 0      | ?              | ?                                  
6 | test_pr_curve  | MulticlassPrecisionRecallCurve | 0      | ?              | ?                                  
7 | metrics        | ModuleDict                     | 0      | ?              | ?                                  
-------------------------------------------------------------------------------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.696    Total estimated model params size (MB)
[2024-05-22 13:11:34,917][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 13:11:34,917][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 13:11:34,940][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 13:11:36,589][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 13:11:36,590][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 13:11:36,590][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 13:11:36,590][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 13:11:36,590][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 13:11:42,940][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 0, global step 21: 'val_error' reached 0.88940 (best 0.88940), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=21.ckpt' as top 1
[2024-05-22 13:11:46,470][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...

[2024-05-22 13:11:46,477][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 13:11:46,478][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 13:11:46,481][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=21.ckpt
[2024-05-22 13:11:46,742][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 13:11:46,860][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 13:11:46,861][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 13:11:46,862][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 13:11:47,022][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 13:11:47,023][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 13:11:47,024][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=21.ckpt
[2024-05-22 13:11:47,277][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 13:13:57,887][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 13:13:57,989][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 13:13:57,990][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 13:13:57,994][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 13:13:57,994][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 13:13:57,994][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 13:13:57,994][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 13:13:57,994][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 13:13:57,994][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 13:13:57,994][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 13:13:57,996][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 13:13:57,996][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32
[2024-05-22 13:13:57,996][hannah.utils.utils][INFO] -   
[2024-05-22 13:13:57,997][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 13:13:58,028][root][INFO] - Configuration: 
[2024-05-22 13:13:58,031][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 13:13:58,031][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 13:13:58,843][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 13:13:58,843][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 13:13:58,915][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 13:13:58,939][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 13:13:58,946][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 13:13:58,946][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 13:13:58,946][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 13:13:58,946][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 13:13:58,946][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 13:13:58,946][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 13:13:58,946][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 13:13:58,946][root][INFO] - Starting training
[2024-05-22 13:14:00,707][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 13:14:00,707][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 13:14:00,707][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 13:14:00,708][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 13:14:00,708][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 13:14:00,708][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 13:28:22,004][root][ERROR] - Exception Message: 
Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 949, in _run
    call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 94, in _call_setup_hook
    _call_lightning_module_hook(trainer, "setup", stage=fn)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 93, in setup
    example_data = self._decode_batch(self.test_set[0])["data"].unsqueeze(0)
                                      ~~~~~~~~~~~~~^^^
  File "/local/gerum/hannah/hannah/datasets/vision/base.py", line 68, in __getitem__
    return data["image"], data["labels"]
           ^^^^
  File "/usr/lib64/python3.11/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib64/python3.11/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
                      ^^^^^^^^^^^^^
bdb.BdbQuit
[2024-05-22 13:28:36,936][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 13:28:37,038][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 13:28:37,039][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 13:28:37,042][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 13:28:37,042][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 13:28:37,043][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 13:28:37,043][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 13:28:37,043][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 13:28:37,043][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 13:28:37,043][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 13:28:37,044][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 13:28:37,044][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32
[2024-05-22 13:28:37,044][hannah.utils.utils][INFO] -   
[2024-05-22 13:28:37,045][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 13:28:37,047][root][INFO] - Configuration: 
[2024-05-22 13:28:37,050][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 13:28:37,050][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 13:28:37,842][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 13:28:37,842][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 13:28:37,910][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 13:28:37,934][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 13:28:37,940][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 13:28:37,940][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 13:28:37,940][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 13:28:37,940][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 13:28:37,941][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 13:28:37,941][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 13:28:37,941][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 13:28:37,941][root][INFO] - Starting training
[2024-05-22 13:28:42,911][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 13:28:42,911][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 13:28:42,911][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 13:28:42,912][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 13:28:42,912][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 13:28:42,912][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 13:32:36,942][root][ERROR] - Exception Message: 
Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 949, in _run
    call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 94, in _call_setup_hook
    _call_lightning_module_hook(trainer, "setup", stage=fn)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib64/python3.11/bdb.py", line 96, in trace_dispatch
    return self.dispatch_exception(frame, arg)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib64/python3.11/bdb.py", line 176, in dispatch_exception
    if self.quitting: raise BdbQuit
                      ^^^^^^^^^^^^^
bdb.BdbQuit
[2024-05-22 13:32:55,314][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 13:32:55,417][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 13:32:55,418][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 13:32:55,422][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 13:32:55,422][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 13:32:55,422][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 13:32:55,422][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 13:32:55,422][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 13:32:55,422][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 13:32:55,422][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 13:32:55,423][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 13:32:55,424][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train
[2024-05-22 13:32:55,424][hannah.utils.utils][INFO] -   
[2024-05-22 13:32:55,425][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 13:32:55,426][root][INFO] - Configuration: 
[2024-05-22 13:32:55,429][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 13:32:55,430][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 13:32:56,181][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 13:32:56,181][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 13:32:56,259][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 13:32:56,283][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 13:32:56,290][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 13:32:56,290][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 13:32:56,290][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 13:32:56,290][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 13:32:56,290][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 13:32:56,290][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 13:32:56,290][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 13:32:56,290][root][INFO] - Starting training
[2024-05-22 13:32:57,012][hydra.utils][ERROR] - Error getting class at hannah.datasets.vision.Cifar10Dataset: Error loading 'hannah.datasets.vision.Cifar10Dataset':
SyntaxError("closing parenthesis ')' does not match opening parenthesis '['", ('/local/gerum/hannah/hannah/datasets/vision/albumentations.py', 9, 155, '    def __init__(self, mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), sensor: Optional[Mapping[str, Any] = None, resolution = Optional[Tuple[int, int]] = None):    ', 9, 155))
[2024-05-22 13:32:57,012][root][ERROR] - Exception Message: Error loading 'hannah.datasets.vision.Cifar10Dataset':
SyntaxError("closing parenthesis ')' does not match opening parenthesis '['", ('/local/gerum/hannah/hannah/datasets/vision/albumentations.py', 9, 155, '    def __init__(self, mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), sensor: Optional[Mapping[str, Any] = None, resolution = Optional[Tuple[int, int]] = None):    ', 9, 155))
Traceback (most recent call last):
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 644, in _locate
    obj = getattr(obj, part)
          ^^^^^^^^^^^^^^^^^^
AttributeError: module 'hannah.datasets' has no attribute 'vision'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 650, in _locate
    obj = import_module(mod)
          ^^^^^^^^^^^^^^^^^^
  File "/usr/lib64/python3.11/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1147, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/local/gerum/hannah/hannah/datasets/vision/__init__.py", line 19, in <module>
    from .cifar import Cifar10Dataset
  File "/local/gerum/hannah/hannah/datasets/vision/cifar.py", line 27, in <module>
    from . import albumentations
  File "/local/gerum/hannah/hannah/datasets/vision/albumentations.py", line 9
    def __init__(self, mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), sensor: Optional[Mapping[str, Any] = None, resolution = Optional[Tuple[int, int]] = None):    
                                                                                                                                                          ^
SyntaxError: closing parenthesis ')' does not match opening parenthesis '['

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 947, in _run
    self._data_connector.prepare_data()
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py", line 100, in prepare_data
    call._call_lightning_module_hook(trainer, "prepare_data")
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 205, in prepare_data
    get_class(self.hparams.dataset.cls).prepare(self.hparams.dataset)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/utils.py", line 40, in get_class
    raise e
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/utils.py", line 31, in get_class
    cls = _locate(path)
          ^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 658, in _locate
    raise ImportError(
ImportError: Error loading 'hannah.datasets.vision.Cifar10Dataset':
SyntaxError("closing parenthesis ')' does not match opening parenthesis '['", ('/local/gerum/hannah/hannah/datasets/vision/albumentations.py', 9, 155, '    def __init__(self, mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), sensor: Optional[Mapping[str, Any] = None, resolution = Optional[Tuple[int, int]] = None):    ', 9, 155))
[2024-05-22 13:34:25,710][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 13:34:25,812][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 13:34:25,813][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 13:34:25,817][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 13:34:25,817][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 13:34:25,817][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 13:34:25,817][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 13:34:25,817][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 13:34:25,817][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 13:34:25,817][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 13:34:25,819][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 13:34:25,819][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train
[2024-05-22 13:34:25,819][hannah.utils.utils][INFO] -   
[2024-05-22 13:34:25,820][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 13:34:25,821][root][INFO] - Configuration: 
[2024-05-22 13:34:25,824][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 13:34:25,825][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 13:34:26,592][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 13:34:26,593][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 13:34:26,661][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 13:34:26,685][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 13:34:26,692][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 13:34:26,692][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 13:34:26,692][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 13:34:26,693][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 13:34:26,693][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 13:34:26,693][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 13:34:26,693][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 13:34:26,693][root][INFO] - Starting training
[2024-05-22 13:34:27,408][hydra.utils][ERROR] - Error getting class at hannah.datasets.vision.Cifar10Dataset: Error loading 'hannah.datasets.vision.Cifar10Dataset':
SyntaxError("closing parenthesis ')' does not match opening parenthesis '['", ('/local/gerum/hannah/hannah/datasets/vision/albumentations.py', 9, 155, '    def __init__(self, mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), sensor: Optional[Mapping[str, Any] = None, resolution = Optional[Tuple[int, int]] = None):    ', 9, 155))
[2024-05-22 13:34:27,409][root][ERROR] - Exception Message: Error loading 'hannah.datasets.vision.Cifar10Dataset':
SyntaxError("closing parenthesis ')' does not match opening parenthesis '['", ('/local/gerum/hannah/hannah/datasets/vision/albumentations.py', 9, 155, '    def __init__(self, mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), sensor: Optional[Mapping[str, Any] = None, resolution = Optional[Tuple[int, int]] = None):    ', 9, 155))
Traceback (most recent call last):
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 644, in _locate
    obj = getattr(obj, part)
          ^^^^^^^^^^^^^^^^^^
AttributeError: module 'hannah.datasets' has no attribute 'vision'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 650, in _locate
    obj = import_module(mod)
          ^^^^^^^^^^^^^^^^^^
  File "/usr/lib64/python3.11/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1147, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/local/gerum/hannah/hannah/datasets/vision/__init__.py", line 19, in <module>
    from .cifar import Cifar10Dataset
  File "/local/gerum/hannah/hannah/datasets/vision/cifar.py", line 27, in <module>
    from . import albumentations
  File "/local/gerum/hannah/hannah/datasets/vision/albumentations.py", line 9
    def __init__(self, mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), sensor: Optional[Mapping[str, Any] = None, resolution = Optional[Tuple[int, int]] = None):    
                                                                                                                                                          ^
SyntaxError: closing parenthesis ')' does not match opening parenthesis '['

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 947, in _run
    self._data_connector.prepare_data()
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py", line 100, in prepare_data
    call._call_lightning_module_hook(trainer, "prepare_data")
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 205, in prepare_data
    get_class(self.hparams.dataset.cls).prepare(self.hparams.dataset)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/utils.py", line 40, in get_class
    raise e
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/utils.py", line 31, in get_class
    cls = _locate(path)
          ^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 658, in _locate
    raise ImportError(
ImportError: Error loading 'hannah.datasets.vision.Cifar10Dataset':
SyntaxError("closing parenthesis ')' does not match opening parenthesis '['", ('/local/gerum/hannah/hannah/datasets/vision/albumentations.py', 9, 155, '    def __init__(self, mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), sensor: Optional[Mapping[str, Any] = None, resolution = Optional[Tuple[int, int]] = None):    ', 9, 155))
[2024-05-22 13:38:36,693][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 13:38:36,794][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 13:38:36,795][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 13:38:36,799][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 13:38:36,799][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 13:38:36,799][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 13:38:36,799][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 13:38:36,799][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 13:38:36,799][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 13:38:36,799][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 13:38:36,801][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 13:38:36,801][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train
[2024-05-22 13:38:36,801][hannah.utils.utils][INFO] -   
[2024-05-22 13:38:36,802][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 13:38:36,803][root][INFO] - Configuration: 
[2024-05-22 13:38:36,806][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 13:38:36,806][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 13:38:37,577][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 13:38:37,577][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 13:38:37,646][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 13:38:37,670][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 13:38:37,677][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 13:38:37,677][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 13:38:37,677][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 13:38:37,677][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 13:38:37,678][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 13:38:37,678][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 13:38:37,678][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 13:38:37,678][root][INFO] - Starting training
[2024-05-22 13:38:38,407][hydra.utils][ERROR] - Error getting class at hannah.datasets.vision.Cifar10Dataset: Error loading 'hannah.datasets.vision.Cifar10Dataset':
SyntaxError('invalid syntax', ('/local/gerum/hannah/hannah/datasets/vision/albumentations.py', 11, 101, '                 sensor: Optional[Mapping[str, Any]] = None, resolution = Optional[Tuple[int, int]] = None):    \n', 11, 102))
[2024-05-22 13:38:38,407][root][ERROR] - Exception Message: Error loading 'hannah.datasets.vision.Cifar10Dataset':
SyntaxError('invalid syntax', ('/local/gerum/hannah/hannah/datasets/vision/albumentations.py', 11, 101, '                 sensor: Optional[Mapping[str, Any]] = None, resolution = Optional[Tuple[int, int]] = None):    \n', 11, 102))
Traceback (most recent call last):
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 644, in _locate
    obj = getattr(obj, part)
          ^^^^^^^^^^^^^^^^^^
AttributeError: module 'hannah.datasets' has no attribute 'vision'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 650, in _locate
    obj = import_module(mod)
          ^^^^^^^^^^^^^^^^^^
  File "/usr/lib64/python3.11/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1147, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/local/gerum/hannah/hannah/datasets/vision/__init__.py", line 19, in <module>
    from .cifar import Cifar10Dataset
  File "/local/gerum/hannah/hannah/datasets/vision/cifar.py", line 27, in <module>
    from . import albumentations
  File "/local/gerum/hannah/hannah/datasets/vision/albumentations.py", line 11
    sensor: Optional[Mapping[str, Any]] = None, resolution = Optional[Tuple[int, int]] = None):    
                                                                                       ^
SyntaxError: invalid syntax

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 947, in _run
    self._data_connector.prepare_data()
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py", line 100, in prepare_data
    call._call_lightning_module_hook(trainer, "prepare_data")
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 205, in prepare_data
    get_class(self.hparams.dataset.cls).prepare(self.hparams.dataset)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/utils.py", line 40, in get_class
    raise e
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/utils.py", line 31, in get_class
    cls = _locate(path)
          ^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 658, in _locate
    raise ImportError(
ImportError: Error loading 'hannah.datasets.vision.Cifar10Dataset':
SyntaxError('invalid syntax', ('/local/gerum/hannah/hannah/datasets/vision/albumentations.py', 11, 101, '                 sensor: Optional[Mapping[str, Any]] = None, resolution = Optional[Tuple[int, int]] = None):    \n', 11, 102))
[2024-05-22 13:39:13,877][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 13:39:13,975][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 13:39:13,976][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 13:39:13,979][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 13:39:13,980][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 13:39:13,980][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 13:39:13,980][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 13:39:13,980][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 13:39:13,980][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 13:39:13,980][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 13:39:13,981][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 13:39:13,981][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train
[2024-05-22 13:39:13,981][hannah.utils.utils][INFO] -   
[2024-05-22 13:39:13,982][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 13:39:13,984][root][INFO] - Configuration: 
[2024-05-22 13:39:13,987][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 13:39:13,987][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 13:39:14,739][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 13:39:14,740][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 13:39:14,806][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 13:39:14,830][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 13:39:14,837][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 13:39:14,837][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 13:39:14,837][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 13:39:14,837][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 13:39:14,837][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 13:39:14,837][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 13:39:14,837][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 13:39:14,838][root][INFO] - Starting training
[2024-05-22 13:39:19,861][root][ERROR] - Exception Message: argument of type 'NoneType' is not iterable
Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 949, in _run
    call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 94, in _call_setup_hook
    _call_lightning_module_hook(trainer, "setup", stage=fn)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 60, in setup
    data_splits: Tuple[Any] = dataset_cls.splits(self.hparams.dataset)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/cifar.py", line 73, in splits
    transforms = albumentations.Albumentations(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/albumentations.py", line 19, in __init__
    if "resolution" in sensor:
       ^^^^^^^^^^^^^^^^^^^^^^
TypeError: argument of type 'NoneType' is not iterable
[2024-05-22 13:40:11,470][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 13:40:11,568][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 13:40:11,569][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 13:40:11,572][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 13:40:11,572][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 13:40:11,573][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 13:40:11,573][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 13:40:11,573][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 13:40:11,573][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 13:40:11,573][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 13:40:11,574][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 13:40:11,574][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train
[2024-05-22 13:40:11,574][hannah.utils.utils][INFO] -   
[2024-05-22 13:40:11,575][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 13:40:11,577][root][INFO] - Configuration: 
[2024-05-22 13:40:11,580][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 13:40:11,580][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 13:40:12,331][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 13:40:12,331][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 13:40:12,398][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 13:40:12,422][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 13:40:12,430][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 13:40:12,430][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 13:40:12,430][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 13:40:12,430][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 13:40:12,430][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 13:40:12,430][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 13:40:12,430][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 13:40:12,430][root][INFO] - Starting training
[2024-05-22 13:40:17,455][root][ERROR] - Exception Message: name 'Normalize' is not defined
Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 949, in _run
    call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 94, in _call_setup_hook
    _call_lightning_module_hook(trainer, "setup", stage=fn)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 60, in setup
    data_splits: Tuple[Any] = dataset_cls.splits(self.hparams.dataset)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/cifar.py", line 80, in splits
    train_transform = transforms.get_transform(train=True)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/albumentations.py", line 29, in get_transform
    Normalize(mean=self.mean, std=self.std),
    ^^^^^^^^^
NameError: name 'Normalize' is not defined
[2024-05-22 13:40:47,631][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 13:40:47,748][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 13:40:47,749][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 13:40:47,752][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 13:40:47,753][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 13:40:47,753][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 13:40:47,753][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 13:40:47,753][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 13:40:47,753][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 13:40:47,753][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 13:40:47,754][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 13:40:47,755][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train
[2024-05-22 13:40:47,755][hannah.utils.utils][INFO] -   
[2024-05-22 13:40:47,756][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 13:40:47,757][root][INFO] - Configuration: 
[2024-05-22 13:40:47,760][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 13:40:47,760][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 13:40:48,523][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 13:40:48,523][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 13:40:48,594][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 13:40:48,619][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 13:40:48,626][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 13:40:48,626][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 13:40:48,626][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 13:40:48,626][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 13:40:48,626][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 13:40:48,627][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 13:40:48,627][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 13:40:48,627][root][INFO] - Starting training
[2024-05-22 13:40:52,366][hydra.utils][ERROR] - Error getting class at hannah.datasets.vision.Cifar10Dataset: Error loading 'hannah.datasets.vision.Cifar10Dataset':
ImportError("cannot import name 'ToTensorV2' from 'albumentations' (/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/albumentations/__init__.py)")
[2024-05-22 13:40:52,366][root][ERROR] - Exception Message: Error loading 'hannah.datasets.vision.Cifar10Dataset':
ImportError("cannot import name 'ToTensorV2' from 'albumentations' (/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/albumentations/__init__.py)")
Traceback (most recent call last):
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 644, in _locate
    obj = getattr(obj, part)
          ^^^^^^^^^^^^^^^^^^
AttributeError: module 'hannah.datasets' has no attribute 'vision'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 650, in _locate
    obj = import_module(mod)
          ^^^^^^^^^^^^^^^^^^
  File "/usr/lib64/python3.11/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1147, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/local/gerum/hannah/hannah/datasets/vision/__init__.py", line 19, in <module>
    from .cifar import Cifar10Dataset
  File "/local/gerum/hannah/hannah/datasets/vision/cifar.py", line 27, in <module>
    from . import albumentations
  File "/local/gerum/hannah/hannah/datasets/vision/albumentations.py", line 2, in <module>
    from albumentations import Compose, RandomCrop, CenterCrop, Normalize, ToTensorV2
ImportError: cannot import name 'ToTensorV2' from 'albumentations' (/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/albumentations/__init__.py)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 947, in _run
    self._data_connector.prepare_data()
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py", line 100, in prepare_data
    call._call_lightning_module_hook(trainer, "prepare_data")
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 205, in prepare_data
    get_class(self.hparams.dataset.cls).prepare(self.hparams.dataset)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/utils.py", line 40, in get_class
    raise e
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/utils.py", line 31, in get_class
    cls = _locate(path)
          ^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 658, in _locate
    raise ImportError(
ImportError: Error loading 'hannah.datasets.vision.Cifar10Dataset':
ImportError("cannot import name 'ToTensorV2' from 'albumentations' (/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/albumentations/__init__.py)")
[2024-05-22 13:41:47,902][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 13:41:48,005][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 13:41:48,005][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 13:41:48,009][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 13:41:48,009][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 13:41:48,009][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 13:41:48,009][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 13:41:48,010][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 13:41:48,010][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 13:41:48,010][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 13:41:48,011][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 13:41:48,011][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train
[2024-05-22 13:41:48,011][hannah.utils.utils][INFO] -   
[2024-05-22 13:41:48,012][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 13:41:48,014][root][INFO] - Configuration: 
[2024-05-22 13:41:48,017][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 13:41:48,017][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 13:41:48,762][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 13:41:48,762][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 13:41:48,830][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 13:41:48,854][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 13:41:48,861][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 13:41:48,861][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 13:41:48,861][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 13:41:48,861][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 13:41:48,861][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 13:41:48,861][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 13:41:48,861][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 13:41:48,861][root][INFO] - Starting training
[2024-05-22 13:41:53,875][root][ERROR] - Exception Message: 4 validation errors for InitSchema
mean.float
  Input should be a valid number [type=float_type, input_value=<property object at 0x7f10ef258a40>, input_type=property]
    For further information visit https://errors.pydantic.dev/2.7/v/float_type
mean.json-or-python[json=list[float],python=chain[is-instance[Sequence],function-wrap[sequence_validator()]]]
  Input should be an instance of Sequence [type=is_instance_of, input_value=<property object at 0x7f10ef258a40>, input_type=property]
    For further information visit https://errors.pydantic.dev/2.7/v/is_instance_of
std.float
  Input should be a valid number [type=float_type, input_value=<property object at 0x7f10ef258f90>, input_type=property]
    For further information visit https://errors.pydantic.dev/2.7/v/float_type
std.json-or-python[json=list[float],python=chain[is-instance[Sequence],function-wrap[sequence_validator()]]]
  Input should be an instance of Sequence [type=is_instance_of, input_value=<property object at 0x7f10ef258f90>, input_type=property]
    For further information visit https://errors.pydantic.dev/2.7/v/is_instance_of
Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 949, in _run
    call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 94, in _call_setup_hook
    _call_lightning_module_hook(trainer, "setup", stage=fn)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 60, in setup
    data_splits: Tuple[Any] = dataset_cls.splits(self.hparams.dataset)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/cifar.py", line 80, in splits
    train_transform = transforms.get_transform(train=True)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/albumentations.py", line 30, in get_transform
    Normalize(mean=self.mean, std=self.std),
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/albumentations/core/validation.py", line 29, in custom_init
    config = dct["InitSchema"](**full_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pydantic/main.py", line 176, in __init__
    self.__pydantic_validator__.validate_python(data, self_instance=self)
pydantic_core._pydantic_core.ValidationError: 4 validation errors for InitSchema
mean.float
  Input should be a valid number [type=float_type, input_value=<property object at 0x7f10ef258a40>, input_type=property]
    For further information visit https://errors.pydantic.dev/2.7/v/float_type
mean.json-or-python[json=list[float],python=chain[is-instance[Sequence],function-wrap[sequence_validator()]]]
  Input should be an instance of Sequence [type=is_instance_of, input_value=<property object at 0x7f10ef258a40>, input_type=property]
    For further information visit https://errors.pydantic.dev/2.7/v/is_instance_of
std.float
  Input should be a valid number [type=float_type, input_value=<property object at 0x7f10ef258f90>, input_type=property]
    For further information visit https://errors.pydantic.dev/2.7/v/float_type
std.json-or-python[json=list[float],python=chain[is-instance[Sequence],function-wrap[sequence_validator()]]]
  Input should be an instance of Sequence [type=is_instance_of, input_value=<property object at 0x7f10ef258f90>, input_type=property]
    For further information visit https://errors.pydantic.dev/2.7/v/is_instance_of
[2024-05-22 13:44:12,760][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 13:44:12,858][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 13:44:12,859][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 13:44:12,863][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 13:44:12,863][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 13:44:12,863][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 13:44:12,863][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 13:44:12,863][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 13:44:12,863][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 13:44:12,863][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 13:44:12,865][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 13:44:12,865][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train
[2024-05-22 13:44:12,865][hannah.utils.utils][INFO] -   
[2024-05-22 13:44:12,866][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 13:44:12,867][root][INFO] - Configuration: 
[2024-05-22 13:44:12,870][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 13:44:12,871][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 13:44:13,614][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 13:44:13,614][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 13:44:13,670][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 13:44:13,694][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 13:44:13,701][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 13:44:13,701][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 13:44:13,701][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 13:44:13,701][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 13:44:13,701][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 13:44:13,701][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 13:44:13,701][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 13:44:13,701][root][INFO] - Starting training
[2024-05-22 13:44:15,140][root][ERROR] - Exception Message: 4 validation errors for InitSchema
mean.float
  Input should be a valid number [type=float_type, input_value=<property object at 0x7fa3e8e38950>, input_type=property]
    For further information visit https://errors.pydantic.dev/2.7/v/float_type
mean.json-or-python[json=list[float],python=chain[is-instance[Sequence],function-wrap[sequence_validator()]]]
  Input should be an instance of Sequence [type=is_instance_of, input_value=<property object at 0x7fa3e8e38950>, input_type=property]
    For further information visit https://errors.pydantic.dev/2.7/v/is_instance_of
std.float
  Input should be a valid number [type=float_type, input_value=<property object at 0x7fa3e8e38ef0>, input_type=property]
    For further information visit https://errors.pydantic.dev/2.7/v/float_type
std.json-or-python[json=list[float],python=chain[is-instance[Sequence],function-wrap[sequence_validator()]]]
  Input should be an instance of Sequence [type=is_instance_of, input_value=<property object at 0x7fa3e8e38ef0>, input_type=property]
    For further information visit https://errors.pydantic.dev/2.7/v/is_instance_of
Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 949, in _run
    call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 94, in _call_setup_hook
    _call_lightning_module_hook(trainer, "setup", stage=fn)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 60, in setup
    data_splits: Tuple[Any] = dataset_cls.splits(self.hparams.dataset)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/cifar.py", line 80, in splits
    train_transform = transforms.get_transform(train=True)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/albumentations.py", line 30, in get_transform
    Normalize(mean=self.mean, std=self.std),
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/albumentations/core/validation.py", line 29, in custom_init
    config = dct["InitSchema"](**full_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pydantic/main.py", line 176, in __init__
    self.__pydantic_validator__.validate_python(data, self_instance=self)
pydantic_core._pydantic_core.ValidationError: 4 validation errors for InitSchema
mean.float
  Input should be a valid number [type=float_type, input_value=<property object at 0x7fa3e8e38950>, input_type=property]
    For further information visit https://errors.pydantic.dev/2.7/v/float_type
mean.json-or-python[json=list[float],python=chain[is-instance[Sequence],function-wrap[sequence_validator()]]]
  Input should be an instance of Sequence [type=is_instance_of, input_value=<property object at 0x7fa3e8e38950>, input_type=property]
    For further information visit https://errors.pydantic.dev/2.7/v/is_instance_of
std.float
  Input should be a valid number [type=float_type, input_value=<property object at 0x7fa3e8e38ef0>, input_type=property]
    For further information visit https://errors.pydantic.dev/2.7/v/float_type
std.json-or-python[json=list[float],python=chain[is-instance[Sequence],function-wrap[sequence_validator()]]]
  Input should be an instance of Sequence [type=is_instance_of, input_value=<property object at 0x7fa3e8e38ef0>, input_type=property]
    For further information visit https://errors.pydantic.dev/2.7/v/is_instance_of
[2024-05-22 13:57:56,673][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 13:57:56,770][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 13:57:56,771][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 13:57:56,775][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 13:57:56,775][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 13:57:56,775][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 13:57:56,775][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 13:57:56,775][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 13:57:56,775][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 13:57:56,775][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 13:57:56,776][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 13:57:56,777][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train
[2024-05-22 13:57:56,777][hannah.utils.utils][INFO] -   
[2024-05-22 13:57:56,778][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 13:57:56,779][root][INFO] - Configuration: 
[2024-05-22 13:57:56,782][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 13:57:56,782][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 13:57:57,529][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 13:57:57,530][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 13:57:57,599][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 13:57:57,623][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 13:57:57,629][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 13:57:57,629][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 13:57:57,630][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 13:57:57,630][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 13:57:57,630][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 13:57:57,630][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 13:57:57,630][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 13:57:57,630][root][INFO] - Starting training
[2024-05-22 13:58:02,683][root][ERROR] - Exception Message: 4 validation errors for InitSchema
mean.float
  Input should be a valid number [type=float_type, input_value=<property object at 0x7f58d11195d0>, input_type=property]
    For further information visit https://errors.pydantic.dev/2.7/v/float_type
mean.json-or-python[json=list[float],python=chain[is-instance[Sequence],function-wrap[sequence_validator()]]]
  Input should be an instance of Sequence [type=is_instance_of, input_value=<property object at 0x7f58d11195d0>, input_type=property]
    For further information visit https://errors.pydantic.dev/2.7/v/is_instance_of
std.float
  Input should be a valid number [type=float_type, input_value=<property object at 0x7f58d1119940>, input_type=property]
    For further information visit https://errors.pydantic.dev/2.7/v/float_type
std.json-or-python[json=list[float],python=chain[is-instance[Sequence],function-wrap[sequence_validator()]]]
  Input should be an instance of Sequence [type=is_instance_of, input_value=<property object at 0x7f58d1119940>, input_type=property]
    For further information visit https://errors.pydantic.dev/2.7/v/is_instance_of
Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 949, in _run
    call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 94, in _call_setup_hook
    _call_lightning_module_hook(trainer, "setup", stage=fn)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 60, in setup
    data_splits: Tuple[Any] = dataset_cls.splits(self.hparams.dataset)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/cifar.py", line 80, in splits
    train_transform = transforms.get_transform(train=True)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/albumentations.py", line 30, in get_transform
    Normalize(mean=self.mean, std=self.std),
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/albumentations/core/validation.py", line 29, in custom_init
    config = dct["InitSchema"](**full_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pydantic/main.py", line 176, in __init__
    self.__pydantic_validator__.validate_python(data, self_instance=self)
pydantic_core._pydantic_core.ValidationError: 4 validation errors for InitSchema
mean.float
  Input should be a valid number [type=float_type, input_value=<property object at 0x7f58d11195d0>, input_type=property]
    For further information visit https://errors.pydantic.dev/2.7/v/float_type
mean.json-or-python[json=list[float],python=chain[is-instance[Sequence],function-wrap[sequence_validator()]]]
  Input should be an instance of Sequence [type=is_instance_of, input_value=<property object at 0x7f58d11195d0>, input_type=property]
    For further information visit https://errors.pydantic.dev/2.7/v/is_instance_of
std.float
  Input should be a valid number [type=float_type, input_value=<property object at 0x7f58d1119940>, input_type=property]
    For further information visit https://errors.pydantic.dev/2.7/v/float_type
std.json-or-python[json=list[float],python=chain[is-instance[Sequence],function-wrap[sequence_validator()]]]
  Input should be an instance of Sequence [type=is_instance_of, input_value=<property object at 0x7f58d1119940>, input_type=property]
    For further information visit https://errors.pydantic.dev/2.7/v/is_instance_of
[2024-05-22 13:59:23,044][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 13:59:23,147][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 13:59:23,147][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 13:59:23,151][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 13:59:23,151][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 13:59:23,151][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 13:59:23,151][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 13:59:23,152][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 13:59:23,152][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 13:59:23,152][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 13:59:23,153][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 13:59:23,153][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train
[2024-05-22 13:59:23,153][hannah.utils.utils][INFO] -   
[2024-05-22 13:59:23,154][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 13:59:23,156][root][INFO] - Configuration: 
[2024-05-22 13:59:23,159][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 13:59:23,159][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 13:59:23,913][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 13:59:23,913][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 13:59:23,979][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 13:59:24,003][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 13:59:24,010][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 13:59:24,010][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 13:59:24,010][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 13:59:24,010][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 13:59:24,010][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 13:59:24,010][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 13:59:24,010][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 13:59:24,010][root][INFO] - Starting training
[2024-05-22 13:59:52,702][root][ERROR] - Exception Message: 
Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 949, in _run
    call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 94, in _call_setup_hook
    _call_lightning_module_hook(trainer, "setup", stage=fn)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 60, in setup
    data_splits: Tuple[Any] = dataset_cls.splits(self.hparams.dataset)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/cifar.py", line 73, in splits
    transforms = albumentations.Albumentations(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/albumentations.py", line 17, in __init__
    self.mean = mean
                ^^^^
  File "/usr/lib64/python3.11/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib64/python3.11/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
                      ^^^^^^^^^^^^^
bdb.BdbQuit
[2024-05-22 14:00:39,502][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 14:00:39,604][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 14:00:39,605][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 14:00:39,608][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 14:00:39,608][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 14:00:39,609][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 14:00:39,609][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 14:00:39,609][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 14:00:39,609][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 14:00:39,609][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 14:00:39,610][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 14:00:39,611][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train
[2024-05-22 14:00:39,611][hannah.utils.utils][INFO] -   
[2024-05-22 14:00:39,612][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 14:00:39,613][root][INFO] - Configuration: 
[2024-05-22 14:00:39,616][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 14:00:39,616][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 14:00:40,353][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 14:00:40,353][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 14:00:40,422][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 14:00:40,446][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 14:00:40,453][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 14:00:40,453][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 14:00:40,453][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 14:00:40,453][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 14:00:40,453][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 14:00:40,453][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:00:40,453][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:00:40,453][root][INFO] - Starting training
[2024-05-22 14:00:56,231][hydra.utils][ERROR] - Error getting class at hannah.datasets.vision.Cifar10Dataset: Error loading 'hannah.datasets.vision.Cifar10Dataset':
SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('/local/gerum/hannah/hannah/datasets/vision/cifar.py', 75, 19, '            std = (0.247, 0.243, 0.261)\n', 76, 19))
[2024-05-22 14:00:56,231][root][ERROR] - Exception Message: Error loading 'hannah.datasets.vision.Cifar10Dataset':
SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('/local/gerum/hannah/hannah/datasets/vision/cifar.py', 75, 19, '            std = (0.247, 0.243, 0.261)\n', 76, 19))
Traceback (most recent call last):
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 644, in _locate
    obj = getattr(obj, part)
          ^^^^^^^^^^^^^^^^^^
AttributeError: module 'hannah.datasets' has no attribute 'vision'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 650, in _locate
    obj = import_module(mod)
          ^^^^^^^^^^^^^^^^^^
  File "/usr/lib64/python3.11/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1147, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/local/gerum/hannah/hannah/datasets/vision/__init__.py", line 19, in <module>
    from .cifar import Cifar10Dataset
  File "/local/gerum/hannah/hannah/datasets/vision/cifar.py", line 75
    std = (0.247, 0.243, 0.261)
          ^
SyntaxError: invalid syntax. Perhaps you forgot a comma?

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 947, in _run
    self._data_connector.prepare_data()
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py", line 100, in prepare_data
    call._call_lightning_module_hook(trainer, "prepare_data")
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 205, in prepare_data
    get_class(self.hparams.dataset.cls).prepare(self.hparams.dataset)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/utils.py", line 40, in get_class
    raise e
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/utils.py", line 31, in get_class
    cls = _locate(path)
          ^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 658, in _locate
    raise ImportError(
ImportError: Error loading 'hannah.datasets.vision.Cifar10Dataset':
SyntaxError('invalid syntax. Perhaps you forgot a comma?', ('/local/gerum/hannah/hannah/datasets/vision/cifar.py', 75, 19, '            std = (0.247, 0.243, 0.261)\n', 76, 19))
[2024-05-22 14:01:48,542][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 14:01:48,643][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 14:01:48,644][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 14:01:48,648][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 14:01:48,648][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 14:01:48,648][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 14:01:48,648][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 14:01:48,648][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 14:01:48,649][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 14:01:48,649][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 14:01:48,650][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 14:01:48,650][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train
[2024-05-22 14:01:48,650][hannah.utils.utils][INFO] -   
[2024-05-22 14:01:48,651][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 14:01:48,652][root][INFO] - Configuration: 
[2024-05-22 14:01:48,656][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 14:01:48,656][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 14:01:49,424][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 14:01:49,424][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 14:01:49,492][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 14:01:49,517][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 14:01:49,523][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 14:01:49,524][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 14:01:49,524][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 14:01:49,524][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 14:01:49,524][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 14:01:49,524][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:01:49,524][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:01:49,524][root][INFO] - Starting training
[2024-05-22 14:02:27,071][root][ERROR] - Exception Message: TorchvisionDatasetBase.__init__() got an unexpected keyword argument 'transforms'
Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 949, in _run
    call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 94, in _call_setup_hook
    _call_lightning_module_hook(trainer, "setup", stage=fn)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 60, in setup
    data_splits: Tuple[Any] = dataset_cls.splits(self.hparams.dataset)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/cifar.py", line 84, in splits
    cls(config, train_set, transforms=train_transform),
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: TorchvisionDatasetBase.__init__() got an unexpected keyword argument 'transforms'
[2024-05-22 14:03:48,546][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 14:03:48,650][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 14:03:48,651][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 14:03:48,655][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 14:03:48,655][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 14:03:48,655][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 14:03:48,655][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 14:03:48,655][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 14:03:48,655][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 14:03:48,655][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 14:03:48,656][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 14:03:48,657][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train
[2024-05-22 14:03:48,657][hannah.utils.utils][INFO] -   
[2024-05-22 14:03:48,658][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 14:03:48,659][root][INFO] - Configuration: 
[2024-05-22 14:03:48,662][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 14:03:48,662][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 14:03:49,430][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 14:03:49,430][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 14:03:49,486][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 14:03:49,510][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 14:03:49,517][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 14:03:49,517][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 14:03:49,517][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 14:03:49,517][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 14:03:49,517][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 14:03:49,517][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:03:49,517][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:03:49,517][root][INFO] - Starting training
[2024-05-22 14:03:57,545][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 14:03:57,545][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 14:03:57,546][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 14:03:57,546][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 14:03:57,546][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 14:03:57,546][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 14:06:06,499][root][ERROR] - Exception Message: image must be numpy array type
Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 949, in _run
    call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 94, in _call_setup_hook
    _call_lightning_module_hook(trainer, "setup", stage=fn)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 93, in setup
    example_data = self._decode_batch(self.test_set[0])["data"].unsqueeze(0)
                                      ~~~~~~~~~~~~~^^^
  File "/local/gerum/hannah/hannah/datasets/vision/base.py", line 67, in __getitem__
    data = self.transform(image=data, labels=target)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/albumentations/core/composition.py", line 247, in __call__
    self._check_args(**data)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/albumentations/core/composition.py", line 320, in _check_args
    raise TypeError(f"{data_name} must be numpy array type")
TypeError: image must be numpy array type
[2024-05-22 14:10:08,662][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 14:10:08,762][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 14:10:08,762][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 14:10:08,766][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 14:10:08,766][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 14:10:08,766][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 14:10:08,766][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 14:10:08,766][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 14:10:08,766][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 14:10:08,767][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 14:10:08,768][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 14:10:08,768][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train
[2024-05-22 14:10:08,768][hannah.utils.utils][INFO] -   
[2024-05-22 14:10:08,769][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 14:10:08,771][root][INFO] - Configuration: 
[2024-05-22 14:10:08,774][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 14:10:08,774][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 14:10:09,548][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 14:10:09,548][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 14:10:09,616][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 14:10:09,640][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 14:10:09,647][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 14:10:09,647][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 14:10:09,647][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 14:10:09,647][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 14:10:09,647][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 14:10:09,647][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:10:09,647][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:10:09,647][root][INFO] - Starting training
[2024-05-22 14:10:17,650][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 14:10:17,651][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 14:10:17,651][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 14:10:17,651][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 14:10:17,651][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 14:10:17,651][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 14:10:17,658][root][ERROR] - Exception Message: expected a sequence of integers or a single integer, got '<PIL.Image.Image image mode=RGB size=32x32 at 0x7EFF99C81890>'
Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 949, in _run
    call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 94, in _call_setup_hook
    _call_lightning_module_hook(trainer, "setup", stage=fn)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 93, in setup
    example_data = self._decode_batch(self.test_set[0])["data"].unsqueeze(0)
                                      ~~~~~~~~~~~~~^^^
  File "/local/gerum/hannah/hannah/datasets/vision/base.py", line 66, in __getitem__
    data = np.ndarray(data)
           ^^^^^^^^^^^^^^^^
TypeError: expected a sequence of integers or a single integer, got '<PIL.Image.Image image mode=RGB size=32x32 at 0x7EFF99C81890>'
[2024-05-22 14:11:58,744][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 14:11:58,843][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 14:11:58,844][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 14:11:58,847][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 14:11:58,847][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 14:11:58,848][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 14:11:58,848][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 14:11:58,848][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 14:11:58,848][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 14:11:58,848][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 14:11:58,849][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 14:11:58,850][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32
[2024-05-22 14:11:58,850][hannah.utils.utils][INFO] -   
[2024-05-22 14:11:58,851][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 14:11:58,852][root][INFO] - Configuration: 
[2024-05-22 14:11:58,855][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 14:11:58,855][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 14:11:59,594][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 14:11:59,594][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 14:11:59,662][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 14:11:59,686][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 14:11:59,693][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 14:11:59,693][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 14:11:59,693][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 14:11:59,693][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 14:11:59,693][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 14:11:59,693][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:11:59,693][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:11:59,694][root][INFO] - Starting training
[2024-05-22 14:12:01,733][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 14:12:01,734][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 14:12:01,734][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 14:12:01,734][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 14:12:01,734][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 14:12:01,734][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 14:12:01,741][root][ERROR] - Exception Message: Key labels is not in available keys.
Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 949, in _run
    call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 94, in _call_setup_hook
    _call_lightning_module_hook(trainer, "setup", stage=fn)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 93, in setup
    example_data = self._decode_batch(self.test_set[0])["data"].unsqueeze(0)
                                      ~~~~~~~~~~~~~^^^
  File "/local/gerum/hannah/hannah/datasets/vision/base.py", line 67, in __getitem__
    data = self.transform(image=data, labels=target)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/albumentations/core/composition.py", line 247, in __call__
    self._check_args(**data)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/albumentations/core/composition.py", line 316, in _check_args
    raise ValueError(msg)
ValueError: Key labels is not in available keys.
[2024-05-22 14:15:46,398][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 14:15:46,500][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 14:15:46,501][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 14:15:46,505][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 14:15:46,505][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 14:15:46,505][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 14:15:46,505][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 14:15:46,505][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 14:15:46,505][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 14:15:46,505][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 14:15:46,507][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 14:15:46,507][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32
[2024-05-22 14:15:46,507][hannah.utils.utils][INFO] -   
[2024-05-22 14:15:46,508][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 14:15:46,509][root][INFO] - Configuration: 
[2024-05-22 14:15:46,512][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 14:15:46,512][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 14:15:47,254][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 14:15:47,255][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 14:15:47,323][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 14:15:47,348][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 14:15:47,354][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 14:15:47,354][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 14:15:47,355][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 14:15:47,355][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 14:15:47,355][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 14:15:47,355][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:15:47,355][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:15:47,355][root][INFO] - Starting training
[2024-05-22 14:15:48,763][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 14:15:48,763][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 14:15:48,763][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 14:15:48,764][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 14:15:48,764][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 14:15:48,764][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 14:15:48,771][root][ERROR] - Exception Message: Key labels is not in available keys.
Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 949, in _run
    call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 94, in _call_setup_hook
    _call_lightning_module_hook(trainer, "setup", stage=fn)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 93, in setup
    example_data = self._decode_batch(self.test_set[0])["data"].unsqueeze(0)
                                      ~~~~~~~~~~~~~^^^
  File "/local/gerum/hannah/hannah/datasets/vision/base.py", line 67, in __getitem__
    data = self.transform(image=data, labels=target)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/albumentations/core/composition.py", line 247, in __call__
    self._check_args(**data)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/albumentations/core/composition.py", line 316, in _check_args
    raise ValueError(msg)
ValueError: Key labels is not in available keys.
[2024-05-22 14:17:14,826][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 14:17:14,930][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 14:17:14,931][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 14:17:14,934][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 14:17:14,934][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 14:17:14,935][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 14:17:14,935][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 14:17:14,935][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 14:17:14,935][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 14:17:14,935][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 14:17:14,936][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 14:17:14,936][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32
[2024-05-22 14:17:14,936][hannah.utils.utils][INFO] -   
[2024-05-22 14:17:14,937][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 14:17:14,939][root][INFO] - Configuration: 
[2024-05-22 14:17:14,942][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 14:17:14,942][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 14:17:15,683][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 14:17:15,683][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 14:17:15,750][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 14:17:15,774][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 14:17:15,781][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 14:17:15,781][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 14:17:15,781][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 14:17:15,781][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 14:17:15,781][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 14:17:15,781][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:17:15,781][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:17:15,781][root][INFO] - Starting training
[2024-05-22 14:17:26,853][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 14:17:26,853][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 14:17:26,853][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 14:17:26,853][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 14:17:26,853][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 14:17:26,853][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 14:17:26,860][root][ERROR] - Exception Message: Requested crop size (224, 224) is larger than the image size (32, 32)
Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 949, in _run
    call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 94, in _call_setup_hook
    _call_lightning_module_hook(trainer, "setup", stage=fn)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 93, in setup
    example_data = self._decode_batch(self.test_set[0])["data"].unsqueeze(0)
                                      ~~~~~~~~~~~~~^^^
  File "/local/gerum/hannah/hannah/datasets/vision/base.py", line 67, in __getitem__
    data = self.transform(image=data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/albumentations/core/composition.py", line 256, in __call__
    data = t(**data)
           ^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/albumentations/core/transforms_interface.py", line 97, in __call__
    return self.apply_with_params(params, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/albumentations/core/transforms_interface.py", line 108, in apply_with_params
    res[key] = target_function(arg, **params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/albumentations/augmentations/crops/transforms.py", line 127, in apply
    return F.center_crop(img, self.height, self.width)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/albumentations/augmentations/crops/functional.py", line 164, in center_crop
    raise ValueError(
ValueError: Requested crop size (224, 224) is larger than the image size (32, 32)
[2024-05-22 14:18:50,862][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 14:18:50,974][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 14:18:50,975][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 14:18:50,979][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 14:18:50,979][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 14:18:50,979][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 14:18:50,979][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 14:18:50,979][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 14:18:50,979][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 14:18:50,979][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 14:18:50,981][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 14:18:50,981][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32
[2024-05-22 14:18:50,981][hannah.utils.utils][INFO] -   
[2024-05-22 14:18:50,982][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 14:18:50,983][root][INFO] - Configuration: 
[2024-05-22 14:18:50,986][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
  sensor:
    resolution:
    - 32
    - 32
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 14:18:50,987][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 14:18:51,742][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 14:18:51,742][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 14:18:51,797][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 14:18:51,821][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 14:18:51,828][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 14:18:51,828][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 14:18:51,828][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 14:18:51,828][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 14:18:51,828][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 14:18:51,828][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:18:51,828][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:18:51,828][root][INFO] - Starting training
[2024-05-22 14:18:56,866][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 14:18:56,867][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 14:18:56,867][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 14:18:56,867][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 14:18:56,867][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 14:18:56,867][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 14:18:56,875][root][ERROR] - Exception Message: 'labels'
Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 949, in _run
    call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 94, in _call_setup_hook
    _call_lightning_module_hook(trainer, "setup", stage=fn)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 93, in setup
    example_data = self._decode_batch(self.test_set[0])["data"].unsqueeze(0)
                                      ~~~~~~~~~~~~~^^^
  File "/local/gerum/hannah/hannah/datasets/vision/base.py", line 68, in __getitem__
    return data["image"], data["labels"]
                          ~~~~^^^^^^^^^^
KeyError: 'labels'
[2024-05-22 14:19:41,935][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 14:19:42,034][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 14:19:42,035][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 14:19:42,039][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 14:19:42,039][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 14:19:42,039][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 14:19:42,039][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 14:19:42,039][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 14:19:42,039][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 14:19:42,039][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 14:19:42,041][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 14:19:42,041][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32
[2024-05-22 14:19:42,041][hannah.utils.utils][INFO] -   
[2024-05-22 14:19:42,042][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 14:19:42,043][root][INFO] - Configuration: 
[2024-05-22 14:19:42,047][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
  sensor:
    resolution:
    - 32
    - 32
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 14:19:42,047][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 14:19:42,801][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 14:19:42,801][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 14:19:42,869][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 14:19:42,893][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 14:19:42,900][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 14:19:42,900][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 14:19:42,900][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 14:19:42,900][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 14:19:42,900][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 14:19:42,900][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:19:42,900][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:19:42,900][root][INFO] - Starting training
[2024-05-22 14:19:53,880][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 14:19:53,880][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 14:19:53,880][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 14:19:53,880][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 14:19:53,880][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 14:19:53,880][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 14:19:53,881][hannah.modules.vision.base][INFO] - Setting up model resnet18
[2024-05-22 14:19:54,050][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:803: UserWarning: Overwriting focalnet_tiny_srf in registry with hannah.models._vendor.focalnet.focalnet_tiny_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:19:54,050][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:824: UserWarning: Overwriting focalnet_small_srf in registry with hannah.models._vendor.focalnet.focalnet_small_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:19:54,050][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:843: UserWarning: Overwriting focalnet_base_srf in registry with hannah.models._vendor.focalnet.focalnet_base_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:19:54,050][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:862: UserWarning: Overwriting focalnet_tiny_lrf in registry with hannah.models._vendor.focalnet.focalnet_tiny_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:19:54,051][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:885: UserWarning: Overwriting focalnet_small_lrf in registry with hannah.models._vendor.focalnet.focalnet_small_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:19:54,051][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:906: UserWarning: Overwriting focalnet_base_lrf in registry with hannah.models._vendor.focalnet.focalnet_base_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:19:54,051][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1010: UserWarning: Overwriting focalnet_large_fl3 in registry with hannah.models._vendor.focalnet.focalnet_large_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:19:54,051][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1031: UserWarning: Overwriting focalnet_large_fl4 in registry with hannah.models._vendor.focalnet.focalnet_large_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:19:54,051][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1052: UserWarning: Overwriting focalnet_xlarge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:19:54,051][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1073: UserWarning: Overwriting focalnet_xlarge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:19:54,051][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1094: UserWarning: Overwriting focalnet_huge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:19:54,051][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1115: UserWarning: Overwriting focalnet_huge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:19:54,220][hannah.models.timm][INFO] - Using default logger for automatic stem creation
[2024-05-22 14:19:54,220][hannah.models.timm][INFO] - Small input size detected trying to adopt small input size
[2024-05-22 14:19:54,236][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '

[2024-05-22 14:19:54,652][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)
[2024-05-22 14:19:54,656][hannah.modules.vision.base][INFO] - Running dummy forward to initialize lazy modules
[2024-05-22 14:19:54,682][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 14:19:55,044][pytorch_lightning.utilities.rank_zero][INFO] - Loading `train_dataloader` to estimate number of stepping batches.
[2024-05-22 14:19:55,470][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

[2024-05-22 14:19:55,847][pytorch_lightning.callbacks.model_summary][INFO] - 
  | Name           | Type                           | Params | In sizes       | Out sizes                          
-------------------------------------------------------------------------------------------------------------------------
0 | val_metrics    | MetricCollection               | 0      | ?              | ?                                  
1 | test_metrics   | MetricCollection               | 0      | ?              | ?                                  
2 | train_metrics  | MetricCollection               | 0      | ?              | ?                                  
3 | model          | TimmModel                      | 11.2 M | [1, 3, 32, 32] | [[1, 512, 4, 4], [0], [0], [1, 10]]
4 | test_confusion | MulticlassConfusionMatrix      | 0      | ?              | ?                                  
5 | test_roc       | MulticlassROC                  | 0      | ?              | ?                                  
6 | test_pr_curve  | MulticlassPrecisionRecallCurve | 0      | ?              | ?                                  
7 | metrics        | ModuleDict                     | 0      | ?              | ?                                  
-------------------------------------------------------------------------------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.696    Total estimated model params size (MB)
[2024-05-22 14:19:56,099][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 14:19:56,100][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 14:19:56,123][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 14:19:57,722][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 14:19:57,723][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 14:19:57,723][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 14:19:57,723][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 14:19:57,723][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 14:20:04,013][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 0, global step 21: 'val_error' reached 0.77930 (best 0.77930), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=21.ckpt' as top 1
[2024-05-22 14:20:10,614][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 1, global step 42: 'val_error' reached 0.69702 (best 0.69702), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=1-step=42.ckpt' as top 1
[2024-05-22 14:20:17,477][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 2, global step 63: 'val_error' reached 0.65405 (best 0.65405), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=2-step=63.ckpt' as top 1
[2024-05-22 14:20:23,451][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...

[2024-05-22 14:20:23,460][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 14:20:23,461][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 14:20:23,463][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=2-step=63.ckpt
[2024-05-22 14:20:23,732][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 14:20:23,843][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 14:20:23,844][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 14:20:23,845][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 14:20:23,951][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 14:20:23,952][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 14:20:23,953][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=2-step=63.ckpt
[2024-05-22 14:20:23,989][hannah.train][INFO] - Averaged Result Metrics:
| Metric              |     Mean |   Std |   Count |
|---------------------|----------|-------|---------|
| val_classifier_loss | 1.78265  |     0 |       1 |
| val_accuracy        | 0.345947 |     0 |       1 |
| val_error           | 0.654053 |     0 |       1 |
| val_f1              | 0.342125 |     0 |       1 |
| val_precision       | 0.351876 |     0 |       1 |
| val_recall          | 0.345379 |     0 |       1 |
| val_loss            | 1.78265  |     0 |       1 |
[2024-05-22 14:31:17,137][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 14:31:17,221][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 14:31:17,221][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 14:31:17,225][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 14:31:17,225][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 14:31:17,225][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 14:31:17,225][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 14:31:17,225][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 14:31:17,225][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 14:31:17,225][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 14:31:17,226][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 14:31:17,226][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32
[2024-05-22 14:31:17,227][hannah.utils.utils][INFO] -   
[2024-05-22 14:31:17,227][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 14:31:17,259][root][INFO] - Configuration: 
[2024-05-22 14:31:17,262][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
  sensor:
    resolution:
    - 32
    - 32
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 14:31:17,262][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 14:31:18,025][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 14:31:18,025][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 14:31:18,095][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 14:31:18,119][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 14:31:18,126][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 14:31:18,127][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 14:31:18,127][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 14:31:18,127][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 14:31:18,127][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 14:31:18,127][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:31:18,127][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:31:18,127][root][INFO] - Starting training
[2024-05-22 14:31:20,163][root][ERROR] - Exception Message: module 'albumentations' has no attribute 'RandomContrast'
Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 949, in _run
    call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 94, in _call_setup_hook
    _call_lightning_module_hook(trainer, "setup", stage=fn)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 60, in setup
    data_splits: Tuple[Any] = dataset_cls.splits(self.hparams.dataset)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/cifar.py", line 80, in splits
    train_transform = transforms.get_transform(train=True)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/albumentations.py", line 57, in get_transform
    default_augment(),
    ^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/albumentations.py", line 13, in default_augment
    A.RandomContrast(limit=M*.1, p=proba),
    ^^^^^^^^^^^^^^^^
AttributeError: module 'albumentations' has no attribute 'RandomContrast'
[2024-05-22 14:32:01,479][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 14:32:01,585][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 14:32:01,586][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 14:32:01,590][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 14:32:01,590][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 14:32:01,590][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 14:32:01,590][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 14:32:01,590][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 14:32:01,590][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 14:32:01,591][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 14:32:01,592][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 14:32:01,592][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32
[2024-05-22 14:32:01,592][hannah.utils.utils][INFO] -   
[2024-05-22 14:32:01,593][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 14:32:01,595][root][INFO] - Configuration: 
[2024-05-22 14:32:01,598][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
  sensor:
    resolution:
    - 32
    - 32
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 14:32:01,598][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 14:32:02,349][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 14:32:02,349][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 14:32:02,417][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 14:32:02,441][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 14:32:02,448][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 14:32:02,448][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 14:32:02,448][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 14:32:02,448][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 14:32:02,448][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 14:32:02,448][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:32:02,448][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:32:02,448][root][INFO] - Starting training
[2024-05-22 14:32:04,472][root][ERROR] - Exception Message: module 'albumentations' has no attribute 'RandomBrightness'
Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 949, in _run
    call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 94, in _call_setup_hook
    _call_lightning_module_hook(trainer, "setup", stage=fn)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 60, in setup
    data_splits: Tuple[Any] = dataset_cls.splits(self.hparams.dataset)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/cifar.py", line 80, in splits
    train_transform = transforms.get_transform(train=True)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/albumentations.py", line 57, in get_transform
    default_augment(),
    ^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/albumentations.py", line 14, in default_augment
    A.RandomBrightness(limit=M*.1, p=proba),
    ^^^^^^^^^^^^^^^^^^
AttributeError: module 'albumentations' has no attribute 'RandomBrightness'
[2024-05-22 14:32:59,076][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 14:32:59,179][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 14:32:59,180][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 14:32:59,184][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 14:32:59,184][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 14:32:59,184][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 14:32:59,184][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 14:32:59,184][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 14:32:59,184][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 14:32:59,184][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 14:32:59,186][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 14:32:59,186][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32
[2024-05-22 14:32:59,186][hannah.utils.utils][INFO] -   
[2024-05-22 14:32:59,187][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 14:32:59,188][root][INFO] - Configuration: 
[2024-05-22 14:32:59,191][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
  sensor:
    resolution:
    - 32
    - 32
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 14:32:59,192][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 14:32:59,925][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 14:32:59,925][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 14:32:59,992][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 14:33:00,017][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 14:33:00,024][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 14:33:00,024][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 14:33:00,024][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 14:33:00,024][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 14:33:00,024][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 14:33:00,024][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:33:00,024][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:33:00,024][root][INFO] - Starting training
[2024-05-22 14:33:08,071][root][ERROR] - Exception Message: 1 validation error for InitSchema
p
  Input should be less than or equal to 1 [type=less_than_equal, input_value=4.333333333333333, input_type=float]
    For further information visit https://errors.pydantic.dev/2.7/v/less_than_equal
Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 949, in _run
    call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 94, in _call_setup_hook
    _call_lightning_module_hook(trainer, "setup", stage=fn)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 60, in setup
    data_splits: Tuple[Any] = dataset_cls.splits(self.hparams.dataset)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/cifar.py", line 80, in splits
    train_transform = transforms.get_transform(train=True)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/albumentations.py", line 56, in get_transform
    default_augment(),
    ^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/albumentations.py", line 13, in default_augment
    A.RandomBrightnessContrast(limit=M*.1, p=proba),
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/albumentations/core/validation.py", line 29, in custom_init
    config = dct["InitSchema"](**full_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pydantic/main.py", line 176, in __init__
    self.__pydantic_validator__.validate_python(data, self_instance=self)
pydantic_core._pydantic_core.ValidationError: 1 validation error for InitSchema
p
  Input should be less than or equal to 1 [type=less_than_equal, input_value=4.333333333333333, input_type=float]
    For further information visit https://errors.pydantic.dev/2.7/v/less_than_equal
[2024-05-22 14:34:56,889][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 14:34:57,014][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 14:34:57,015][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 14:34:57,018][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 14:34:57,019][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 14:34:57,019][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 14:34:57,019][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 14:34:57,019][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 14:34:57,019][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 14:34:57,019][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 14:34:57,020][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 14:34:57,021][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32
[2024-05-22 14:34:57,021][hannah.utils.utils][INFO] -   
[2024-05-22 14:34:57,022][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 14:34:57,023][root][INFO] - Configuration: 
[2024-05-22 14:34:57,026][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
  sensor:
    resolution:
    - 32
    - 32
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 14:34:57,027][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 14:34:57,778][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 14:34:57,778][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 14:34:57,850][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 14:34:57,876][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 14:34:57,883][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 14:34:57,883][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 14:34:57,883][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 14:34:57,883][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 14:34:57,883][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 14:34:57,883][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:34:57,883][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:34:57,884][root][INFO] - Starting training
[2024-05-22 14:35:02,892][root][ERROR] - Exception Message: 1 validation error for InitSchema
p
  Input should be less than or equal to 1 [type=less_than_equal, input_value=4.333333333333333, input_type=float]
    For further information visit https://errors.pydantic.dev/2.7/v/less_than_equal
Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 949, in _run
    call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 94, in _call_setup_hook
    _call_lightning_module_hook(trainer, "setup", stage=fn)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 60, in setup
    data_splits: Tuple[Any] = dataset_cls.splits(self.hparams.dataset)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/cifar.py", line 80, in splits
    train_transform = transforms.get_transform(train=True)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/albumentations.py", line 57, in get_transform
    default_augment(),
    ^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/albumentations.py", line 13, in default_augment
    A.RandomBrightnessContrast(limit=M*.1, p=proba),
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/albumentations/core/validation.py", line 29, in custom_init
    config = dct["InitSchema"](**full_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pydantic/main.py", line 176, in __init__
    self.__pydantic_validator__.validate_python(data, self_instance=self)
pydantic_core._pydantic_core.ValidationError: 1 validation error for InitSchema
p
  Input should be less than or equal to 1 [type=less_than_equal, input_value=4.333333333333333, input_type=float]
    For further information visit https://errors.pydantic.dev/2.7/v/less_than_equal
[2024-05-22 14:36:49,533][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 14:36:49,630][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 14:36:49,631][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 14:36:49,635][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 14:36:49,635][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 14:36:49,635][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 14:36:49,635][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 14:36:49,635][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 14:36:49,635][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 14:36:49,635][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 14:36:49,637][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 14:36:49,637][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32
[2024-05-22 14:36:49,637][hannah.utils.utils][INFO] -   
[2024-05-22 14:36:49,638][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 14:36:49,639][root][INFO] - Configuration: 
[2024-05-22 14:36:49,643][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
  sensor:
    resolution:
    - 32
    - 32
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 14:36:49,643][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 14:36:50,412][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 14:36:50,412][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 14:36:50,482][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 14:36:50,506][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 14:36:50,512][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 14:36:50,512][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 14:36:50,512][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 14:36:50,513][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 14:36:50,513][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 14:36:50,513][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:36:50,513][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:36:50,513][root][INFO] - Starting training
[2024-05-22 14:36:58,528][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 14:36:58,528][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 14:36:58,528][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 14:36:58,529][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 14:36:58,529][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 14:36:58,529][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 14:36:58,537][root][ERROR] - Exception Message: max() received an invalid combination of arguments - got (out=NoneType, axis=NoneType, ), but expected one of:
 * ()
 * (Tensor other)
 * (int dim, bool keepdim)
      didn't match because some of the keywords were incorrect: out, axis
 * (name dim, bool keepdim)
      didn't match because some of the keywords were incorrect: out, axis
Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 949, in _run
    call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 94, in _call_setup_hook
    _call_lightning_module_hook(trainer, "setup", stage=fn)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 93, in setup
    example_data = self._decode_batch(self.test_set[0])["data"].unsqueeze(0)
                                      ~~~~~~~~~~~~~^^^
  File "/local/gerum/hannah/hannah/datasets/vision/base.py", line 68, in __getitem__
    print(np.max(data["image"]), np.min(data["image"]))
          ^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/numpy/core/fromnumeric.py", line 2810, in max
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return reduction(axis=axis, out=out, **passkwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: max() received an invalid combination of arguments - got (out=NoneType, axis=NoneType, ), but expected one of:
 * ()
 * (Tensor other)
 * (int dim, bool keepdim)
      didn't match because some of the keywords were incorrect: out, axis
 * (name dim, bool keepdim)
      didn't match because some of the keywords were incorrect: out, axis

[2024-05-22 14:37:56,825][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 14:37:56,935][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 14:37:56,936][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 14:37:56,939][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 14:37:56,939][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 14:37:56,939][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 14:37:56,939][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 14:37:56,940][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 14:37:56,940][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 14:37:56,940][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 14:37:56,941][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 14:37:56,941][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32
[2024-05-22 14:37:56,941][hannah.utils.utils][INFO] -   
[2024-05-22 14:37:56,942][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 14:37:56,944][root][INFO] - Configuration: 
[2024-05-22 14:37:56,947][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
  sensor:
    resolution:
    - 32
    - 32
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 14:37:56,947][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 14:37:57,709][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 14:37:57,709][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 14:37:57,776][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 14:37:57,800][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 14:37:57,807][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 14:37:57,807][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 14:37:57,807][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 14:37:57,807][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 14:37:57,808][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 14:37:57,808][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:37:57,808][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:37:57,808][root][INFO] - Starting training
[2024-05-22 14:37:59,816][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 14:37:59,816][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 14:37:59,816][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 14:37:59,816][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 14:37:59,816][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 14:37:59,816][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 14:37:59,818][hannah.modules.vision.base][INFO] - Setting up model resnet18
[2024-05-22 14:37:59,980][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:803: UserWarning: Overwriting focalnet_tiny_srf in registry with hannah.models._vendor.focalnet.focalnet_tiny_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:37:59,980][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:824: UserWarning: Overwriting focalnet_small_srf in registry with hannah.models._vendor.focalnet.focalnet_small_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:37:59,981][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:843: UserWarning: Overwriting focalnet_base_srf in registry with hannah.models._vendor.focalnet.focalnet_base_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:37:59,981][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:862: UserWarning: Overwriting focalnet_tiny_lrf in registry with hannah.models._vendor.focalnet.focalnet_tiny_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:37:59,981][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:885: UserWarning: Overwriting focalnet_small_lrf in registry with hannah.models._vendor.focalnet.focalnet_small_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:37:59,981][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:906: UserWarning: Overwriting focalnet_base_lrf in registry with hannah.models._vendor.focalnet.focalnet_base_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:37:59,981][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1010: UserWarning: Overwriting focalnet_large_fl3 in registry with hannah.models._vendor.focalnet.focalnet_large_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:37:59,981][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1031: UserWarning: Overwriting focalnet_large_fl4 in registry with hannah.models._vendor.focalnet.focalnet_large_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:37:59,981][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1052: UserWarning: Overwriting focalnet_xlarge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:37:59,981][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1073: UserWarning: Overwriting focalnet_xlarge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:37:59,981][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1094: UserWarning: Overwriting focalnet_huge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:37:59,981][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1115: UserWarning: Overwriting focalnet_huge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:38:00,122][hannah.models.timm][INFO] - Using default logger for automatic stem creation
[2024-05-22 14:38:00,123][hannah.models.timm][INFO] - Small input size detected trying to adopt small input size
[2024-05-22 14:38:00,138][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '

[2024-05-22 14:38:00,554][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)
[2024-05-22 14:38:00,558][hannah.modules.vision.base][INFO] - Running dummy forward to initialize lazy modules
[2024-05-22 14:38:00,573][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 14:38:00,938][pytorch_lightning.utilities.rank_zero][INFO] - Loading `train_dataloader` to estimate number of stepping batches.
[2024-05-22 14:38:01,368][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

[2024-05-22 14:38:01,589][pytorch_lightning.callbacks.model_summary][INFO] - 
  | Name           | Type                           | Params | In sizes       | Out sizes                          
-------------------------------------------------------------------------------------------------------------------------
0 | val_metrics    | MetricCollection               | 0      | ?              | ?                                  
1 | test_metrics   | MetricCollection               | 0      | ?              | ?                                  
2 | train_metrics  | MetricCollection               | 0      | ?              | ?                                  
3 | model          | TimmModel                      | 11.2 M | [1, 3, 32, 32] | [[1, 512, 4, 4], [0], [0], [1, 10]]
4 | test_confusion | MulticlassConfusionMatrix      | 0      | ?              | ?                                  
5 | test_roc       | MulticlassROC                  | 0      | ?              | ?                                  
6 | test_pr_curve  | MulticlassPrecisionRecallCurve | 0      | ?              | ?                                  
7 | metrics        | ModuleDict                     | 0      | ?              | ?                                  
-------------------------------------------------------------------------------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.696    Total estimated model params size (MB)
[2024-05-22 14:38:01,728][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 14:38:01,729][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 14:38:01,734][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 14:38:03,905][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 14:38:03,906][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 14:38:03,906][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 14:38:03,906][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 14:38:03,906][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 14:38:10,825][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 0, global step 21: 'val_error' reached 0.77930 (best 0.77930), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=21.ckpt' as top 1
[2024-05-22 14:38:18,694][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...

[2024-05-22 14:38:18,712][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 14:38:18,713][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 14:38:18,717][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=21.ckpt
[2024-05-22 14:38:19,001][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 14:38:19,112][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 14:38:19,112][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 14:38:19,114][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 14:38:19,275][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 14:38:19,276][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 14:38:19,277][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=21.ckpt
[2024-05-22 14:38:19,512][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 14:38:49,571][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 14:38:49,674][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 14:38:49,675][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 14:38:49,679][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 14:38:49,679][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 14:38:49,679][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 14:38:49,679][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 14:38:49,679][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 14:38:49,679][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 14:38:49,679][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 14:38:49,681][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 14:38:49,681][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32
[2024-05-22 14:38:49,681][hannah.utils.utils][INFO] -   
[2024-05-22 14:38:49,682][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 14:38:49,711][root][INFO] - Configuration: 
[2024-05-22 14:38:49,714][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
  sensor:
    resolution:
    - 32
    - 32
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 14:38:49,714][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 14:38:50,476][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 14:38:50,476][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 14:38:50,547][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 14:38:50,571][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 14:38:50,578][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 14:38:50,578][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 14:38:50,578][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 14:38:50,578][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 14:38:50,578][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 14:38:50,578][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:38:50,578][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:38:50,578][root][INFO] - Starting training
[2024-05-22 14:38:52,565][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 14:38:52,565][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 14:38:52,565][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 14:38:52,565][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 14:38:52,565][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 14:38:52,565][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 14:38:52,566][hannah.modules.vision.base][INFO] - Setting up model resnet18
[2024-05-22 14:38:52,729][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:803: UserWarning: Overwriting focalnet_tiny_srf in registry with hannah.models._vendor.focalnet.focalnet_tiny_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:38:52,729][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:824: UserWarning: Overwriting focalnet_small_srf in registry with hannah.models._vendor.focalnet.focalnet_small_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:38:52,730][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:843: UserWarning: Overwriting focalnet_base_srf in registry with hannah.models._vendor.focalnet.focalnet_base_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:38:52,730][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:862: UserWarning: Overwriting focalnet_tiny_lrf in registry with hannah.models._vendor.focalnet.focalnet_tiny_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:38:52,730][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:885: UserWarning: Overwriting focalnet_small_lrf in registry with hannah.models._vendor.focalnet.focalnet_small_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:38:52,730][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:906: UserWarning: Overwriting focalnet_base_lrf in registry with hannah.models._vendor.focalnet.focalnet_base_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:38:52,730][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1010: UserWarning: Overwriting focalnet_large_fl3 in registry with hannah.models._vendor.focalnet.focalnet_large_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:38:52,730][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1031: UserWarning: Overwriting focalnet_large_fl4 in registry with hannah.models._vendor.focalnet.focalnet_large_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:38:52,730][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1052: UserWarning: Overwriting focalnet_xlarge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:38:52,730][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1073: UserWarning: Overwriting focalnet_xlarge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:38:52,730][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1094: UserWarning: Overwriting focalnet_huge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:38:52,730][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1115: UserWarning: Overwriting focalnet_huge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:38:52,867][hannah.models.timm][INFO] - Using default logger for automatic stem creation
[2024-05-22 14:38:52,867][hannah.models.timm][INFO] - Small input size detected trying to adopt small input size
[2024-05-22 14:38:52,883][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '

[2024-05-22 14:38:53,300][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)
[2024-05-22 14:38:53,304][hannah.modules.vision.base][INFO] - Running dummy forward to initialize lazy modules
[2024-05-22 14:38:53,336][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 14:38:53,728][pytorch_lightning.utilities.rank_zero][INFO] - Loading `train_dataloader` to estimate number of stepping batches.
[2024-05-22 14:38:54,205][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

[2024-05-22 14:38:54,593][pytorch_lightning.callbacks.model_summary][INFO] - 
  | Name           | Type                           | Params | In sizes       | Out sizes                          
-------------------------------------------------------------------------------------------------------------------------
0 | val_metrics    | MetricCollection               | 0      | ?              | ?                                  
1 | test_metrics   | MetricCollection               | 0      | ?              | ?                                  
2 | train_metrics  | MetricCollection               | 0      | ?              | ?                                  
3 | model          | TimmModel                      | 11.2 M | [1, 3, 32, 32] | [[1, 512, 4, 4], [0], [0], [1, 10]]
4 | test_confusion | MulticlassConfusionMatrix      | 0      | ?              | ?                                  
5 | test_roc       | MulticlassROC                  | 0      | ?              | ?                                  
6 | test_pr_curve  | MulticlassPrecisionRecallCurve | 0      | ?              | ?                                  
7 | metrics        | ModuleDict                     | 0      | ?              | ?                                  
-------------------------------------------------------------------------------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.696    Total estimated model params size (MB)
[2024-05-22 14:38:54,843][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 14:38:54,844][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 14:38:54,865][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 14:38:56,497][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 14:38:56,498][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 14:38:56,498][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 14:38:56,498][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 14:38:56,498][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 14:39:02,771][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 0, global step 21: 'val_error' reached 0.77930 (best 0.77930), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=21.ckpt' as top 1
[2024-05-22 14:39:09,398][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 1, global step 42: 'val_error' reached 0.69702 (best 0.69702), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=1-step=42.ckpt' as top 1
[2024-05-22 14:39:16,271][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 2, global step 63: 'val_error' reached 0.65405 (best 0.65405), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=2-step=63.ckpt' as top 1
[2024-05-22 14:39:23,229][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 3, global step 84: 'val_error' reached 0.62549 (best 0.62549), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=3-step=84.ckpt' as top 1
[2024-05-22 14:39:30,387][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 4, global step 105: 'val_error' reached 0.62231 (best 0.62231), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=4-step=105.ckpt' as top 1
[2024-05-22 14:39:37,159][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 5, global step 126: 'val_error' reached 0.60693 (best 0.60693), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=5-step=126.ckpt' as top 1
[2024-05-22 14:39:44,120][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 6, global step 147: 'val_error' reached 0.53052 (best 0.53052), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=6-step=147.ckpt' as top 1
[2024-05-22 14:39:50,993][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...

[2024-05-22 14:39:51,004][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 14:39:51,005][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 14:39:51,008][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=6-step=147.ckpt
[2024-05-22 14:39:51,276][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 14:39:51,388][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 14:39:51,388][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 14:39:51,390][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 14:39:51,525][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 14:39:51,525][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 14:39:51,527][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=6-step=147.ckpt
[2024-05-22 14:39:51,768][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 14:39:52,036][hannah.train][INFO] - Averaged Result Metrics:
| Metric              |     Mean |   Std |   Count |
|---------------------|----------|-------|---------|
| val_classifier_loss | 1.56282  |     0 |       1 |
| val_accuracy        | 0.459717 |     0 |       1 |
| val_error           | 0.540283 |     0 |       1 |
| val_f1              | 0.456949 |     0 |       1 |
| val_precision       | 0.509687 |     0 |       1 |
| val_recall          | 0.460501 |     0 |       1 |
| val_loss            | 1.56282  |     0 |       1 |
[2024-05-22 14:40:06,474][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 14:40:06,576][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 14:40:06,577][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 14:40:06,581][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 14:40:06,581][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 14:40:06,581][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 14:40:06,581][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 14:40:06,581][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 14:40:06,581][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 14:40:06,581][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 14:40:06,583][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 14:40:06,583][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32
[2024-05-22 14:40:06,583][hannah.utils.utils][INFO] -   
[2024-05-22 14:40:06,584][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 14:40:06,619][root][INFO] - Configuration: 
[2024-05-22 14:40:06,622][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
  sensor:
    resolution:
    - 32
    - 32
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 14:40:06,623][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 14:40:07,369][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 14:40:07,369][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 14:40:07,437][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 14:40:07,461][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 14:40:07,468][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 14:40:07,468][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 14:40:07,468][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 14:40:07,468][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 14:40:07,468][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 14:40:07,468][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:40:07,468][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:40:07,468][root][INFO] - Starting training
[2024-05-22 14:40:24,418][root][ERROR] - Exception Message: 1 validation error for InitSchema
p
  Input should be less than or equal to 1 [type=less_than_equal, input_value=4.333333333333333, input_type=float]
    For further information visit https://errors.pydantic.dev/2.7/v/less_than_equal
Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 949, in _run
    call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 94, in _call_setup_hook
    _call_lightning_module_hook(trainer, "setup", stage=fn)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 60, in setup
    data_splits: Tuple[Any] = dataset_cls.splits(self.hparams.dataset)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/cifar.py", line 80, in splits
    train_transform = transforms.get_transform(train=True)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/albumentations.py", line 57, in get_transform
    default_augment(),
    ^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/albumentations.py", line 13, in default_augment
    A.RandomBrightnessContrast(limit=M*.1, p=proba, brightness_by_max=False),
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/albumentations/core/validation.py", line 29, in custom_init
    config = dct["InitSchema"](**full_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pydantic/main.py", line 176, in __init__
    self.__pydantic_validator__.validate_python(data, self_instance=self)
pydantic_core._pydantic_core.ValidationError: 1 validation error for InitSchema
p
  Input should be less than or equal to 1 [type=less_than_equal, input_value=4.333333333333333, input_type=float]
    For further information visit https://errors.pydantic.dev/2.7/v/less_than_equal
[2024-05-22 14:44:43,649][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 14:44:43,754][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 14:44:43,754][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 14:44:43,758][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 14:44:43,758][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 14:44:43,758][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 14:44:43,758][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 14:44:43,758][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 14:44:43,758][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 14:44:43,759][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 14:44:43,760][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 14:44:43,760][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32
[2024-05-22 14:44:43,760][hannah.utils.utils][INFO] -   
[2024-05-22 14:44:43,761][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 14:44:43,762][root][INFO] - Configuration: 
[2024-05-22 14:44:43,766][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
  sensor:
    resolution:
    - 32
    - 32
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 14:44:43,766][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 14:44:44,515][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 14:44:44,515][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 14:44:44,571][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 14:44:44,595][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 14:44:44,601][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 14:44:44,601][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 14:44:44,602][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 14:44:44,602][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 14:44:44,602][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 14:44:44,602][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:44:44,602][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:44:44,602][root][INFO] - Starting training
[2024-05-22 14:44:55,664][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/albumentations/core/validation.py:34: UserWarning: Argument 'limit' is not valid and will be ignored.
  warn(

[2024-05-22 14:44:55,667][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 14:44:55,667][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 14:44:55,667][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 14:44:55,667][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 14:44:55,667][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 14:44:55,667][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 14:44:55,668][hannah.modules.vision.base][INFO] - Setting up model resnet18
[2024-05-22 14:44:55,835][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:803: UserWarning: Overwriting focalnet_tiny_srf in registry with hannah.models._vendor.focalnet.focalnet_tiny_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:44:55,835][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:824: UserWarning: Overwriting focalnet_small_srf in registry with hannah.models._vendor.focalnet.focalnet_small_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:44:55,835][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:843: UserWarning: Overwriting focalnet_base_srf in registry with hannah.models._vendor.focalnet.focalnet_base_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:44:55,835][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:862: UserWarning: Overwriting focalnet_tiny_lrf in registry with hannah.models._vendor.focalnet.focalnet_tiny_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:44:55,835][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:885: UserWarning: Overwriting focalnet_small_lrf in registry with hannah.models._vendor.focalnet.focalnet_small_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:44:55,835][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:906: UserWarning: Overwriting focalnet_base_lrf in registry with hannah.models._vendor.focalnet.focalnet_base_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:44:55,836][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1010: UserWarning: Overwriting focalnet_large_fl3 in registry with hannah.models._vendor.focalnet.focalnet_large_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:44:55,836][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1031: UserWarning: Overwriting focalnet_large_fl4 in registry with hannah.models._vendor.focalnet.focalnet_large_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:44:55,836][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1052: UserWarning: Overwriting focalnet_xlarge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:44:55,836][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1073: UserWarning: Overwriting focalnet_xlarge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:44:55,836][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1094: UserWarning: Overwriting focalnet_huge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:44:55,836][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1115: UserWarning: Overwriting focalnet_huge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:44:55,965][hannah.models.timm][INFO] - Using default logger for automatic stem creation
[2024-05-22 14:44:55,965][hannah.models.timm][INFO] - Small input size detected trying to adopt small input size
[2024-05-22 14:44:55,980][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '

[2024-05-22 14:44:56,402][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)
[2024-05-22 14:44:56,406][hannah.modules.vision.base][INFO] - Running dummy forward to initialize lazy modules
[2024-05-22 14:44:56,419][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 14:44:56,764][pytorch_lightning.utilities.rank_zero][INFO] - Loading `train_dataloader` to estimate number of stepping batches.
[2024-05-22 14:44:57,231][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

[2024-05-22 14:44:57,476][pytorch_lightning.callbacks.model_summary][INFO] - 
  | Name           | Type                           | Params | In sizes       | Out sizes                          
-------------------------------------------------------------------------------------------------------------------------
0 | val_metrics    | MetricCollection               | 0      | ?              | ?                                  
1 | test_metrics   | MetricCollection               | 0      | ?              | ?                                  
2 | train_metrics  | MetricCollection               | 0      | ?              | ?                                  
3 | model          | TimmModel                      | 11.2 M | [1, 3, 32, 32] | [[1, 512, 4, 4], [0], [0], [1, 10]]
4 | test_confusion | MulticlassConfusionMatrix      | 0      | ?              | ?                                  
5 | test_roc       | MulticlassROC                  | 0      | ?              | ?                                  
6 | test_pr_curve  | MulticlassPrecisionRecallCurve | 0      | ?              | ?                                  
7 | metrics        | ModuleDict                     | 0      | ?              | ?                                  
-------------------------------------------------------------------------------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.696    Total estimated model params size (MB)
[2024-05-22 14:44:57,671][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 14:44:57,672][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 14:44:57,677][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 14:44:59,260][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 14:44:59,260][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 14:44:59,260][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 14:44:59,260][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 14:44:59,260][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 14:45:12,704][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 0, global step 21: 'val_error' reached 0.78345 (best 0.78345), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=21.ckpt' as top 1
[2024-05-22 14:45:28,117][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 1, global step 42: 'val_error' reached 0.70923 (best 0.70923), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=1-step=42.ckpt' as top 1
[2024-05-22 14:45:44,188][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 2, global step 63: 'val_error' reached 0.69897 (best 0.69897), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=2-step=63.ckpt' as top 1
[2024-05-22 14:45:59,907][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 3, global step 84: 'val_error' reached 0.67285 (best 0.67285), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=3-step=84.ckpt' as top 1
[2024-05-22 14:46:16,216][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 4, global step 105: 'val_error' reached 0.66260 (best 0.66260), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=4-step=105.ckpt' as top 1
[2024-05-22 14:46:32,006][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 5, global step 126: 'val_error' reached 0.63721 (best 0.63721), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=5-step=126.ckpt' as top 1
[2024-05-22 14:46:47,723][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 6, global step 147: 'val_error' reached 0.63403 (best 0.63403), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=6-step=147.ckpt' as top 1
[2024-05-22 14:47:03,817][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 7, global step 168: 'val_error' was not in top 1
[2024-05-22 14:47:19,258][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 8, global step 189: 'val_error' was not in top 1
[2024-05-22 14:47:34,952][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 9, global step 210: 'val_error' was not in top 1
[2024-05-22 14:47:50,853][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 10, global step 231: 'val_error' reached 0.60767 (best 0.60767), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=10-step=231.ckpt' as top 1
[2024-05-22 14:48:06,517][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 11, global step 252: 'val_error' was not in top 1
[2024-05-22 14:48:21,933][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 12, global step 273: 'val_error' reached 0.59180 (best 0.59180), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=12-step=273.ckpt' as top 1
[2024-05-22 14:48:37,693][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 13, global step 294: 'val_error' reached 0.56274 (best 0.56274), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=13-step=294.ckpt' as top 1
[2024-05-22 14:48:53,198][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 14, global step 315: 'val_error' reached 0.53467 (best 0.53467), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=14-step=315.ckpt' as top 1
[2024-05-22 14:49:08,806][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 15, global step 336: 'val_error' reached 0.48218 (best 0.48218), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=15-step=336.ckpt' as top 1
[2024-05-22 14:49:25,099][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 16, global step 357: 'val_error' was not in top 1
[2024-05-22 14:49:40,602][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 17, global step 378: 'val_error' was not in top 1
[2024-05-22 14:49:56,400][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 18, global step 399: 'val_error' was not in top 1
[2024-05-22 14:50:12,104][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 19, global step 420: 'val_error' reached 0.45923 (best 0.45923), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=19-step=420.ckpt' as top 1
[2024-05-22 14:50:27,886][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 20, global step 441: 'val_error' reached 0.42017 (best 0.42017), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=20-step=441.ckpt' as top 1
[2024-05-22 14:50:43,685][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 21, global step 462: 'val_error' was not in top 1
[2024-05-22 14:50:59,020][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 22, global step 483: 'val_error' was not in top 1
[2024-05-22 14:51:15,200][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 23, global step 504: 'val_error' reached 0.37134 (best 0.37134), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=23-step=504.ckpt' as top 1
[2024-05-22 14:51:30,732][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 24, global step 525: 'val_error' was not in top 1
[2024-05-22 14:51:47,012][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 25, global step 546: 'val_error' reached 0.34033 (best 0.34033), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=25-step=546.ckpt' as top 1
[2024-05-22 14:52:02,876][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 26, global step 567: 'val_error' was not in top 1
[2024-05-22 14:52:18,189][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 27, global step 588: 'val_error' reached 0.31836 (best 0.31836), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=27-step=588.ckpt' as top 1
[2024-05-22 14:52:34,667][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 28, global step 609: 'val_error' reached 0.30835 (best 0.30835), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=28-step=609.ckpt' as top 1
[2024-05-22 14:52:49,965][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 29, global step 630: 'val_error' was not in top 1
[2024-05-22 14:53:05,685][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 30, global step 651: 'val_error' reached 0.26025 (best 0.26025), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=30-step=651.ckpt' as top 1
[2024-05-22 14:53:21,243][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 31, global step 672: 'val_error' was not in top 1
[2024-05-22 14:53:36,561][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 32, global step 693: 'val_error' was not in top 1
[2024-05-22 14:53:52,391][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 33, global step 714: 'val_error' was not in top 1
[2024-05-22 14:54:07,834][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 34, global step 735: 'val_error' was not in top 1
[2024-05-22 14:54:23,317][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 35, global step 756: 'val_error' was not in top 1
[2024-05-22 14:54:27,665][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...

[2024-05-22 14:54:27,673][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 14:54:27,674][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 14:54:27,676][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=30-step=651.ckpt
[2024-05-22 14:54:27,959][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 14:54:28,073][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 14:54:28,074][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 14:54:28,075][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 14:54:28,517][pytorch_lightning.utilities.rank_zero][INFO] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=30-step=651.ckpt
[2024-05-22 14:54:29,209][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 14:54:29,211][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 14:54:29,214][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=30-step=651.ckpt
[2024-05-22 14:54:29,256][hannah.train][INFO] - Averaged Result Metrics:
| Metric              |     Mean |   Std |   Count |
|---------------------|----------|-------|---------|
| val_classifier_loss | 0.900025 |     0 |       1 |
| val_accuracy        | 0.70166  |     0 |       1 |
| val_error           | 0.29834  |     0 |       1 |
| val_f1              | 0.694433 |     0 |       1 |
| val_precision       | 0.727157 |     0 |       1 |
| val_recall          | 0.702132 |     0 |       1 |
| val_loss            | 0.900025 |     0 |       1 |
[2024-05-22 14:54:34,291][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 14:54:34,398][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 14:54:34,398][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 14:54:34,402][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 14:54:34,402][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 14:54:34,402][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 14:54:34,402][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 14:54:34,402][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 14:54:34,403][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 14:54:34,403][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 14:54:34,404][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 14:54:34,404][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32
[2024-05-22 14:54:34,404][hannah.utils.utils][INFO] -   
[2024-05-22 14:54:34,405][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 14:54:34,439][root][INFO] - Configuration: 
[2024-05-22 14:54:34,442][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
  sensor:
    resolution:
    - 32
    - 32
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 14:54:34,442][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 14:54:35,178][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 14:54:35,178][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 14:54:35,246][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 14:54:35,270][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 14:54:35,277][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 14:54:35,277][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 14:54:35,277][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 14:54:35,277][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 14:54:35,277][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 14:54:35,277][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:54:35,277][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 14:54:35,278][root][INFO] - Starting training
[2024-05-22 14:54:36,724][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/albumentations/core/validation.py:34: UserWarning: Argument 'limit' is not valid and will be ignored.
  warn(

[2024-05-22 14:54:36,727][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 14:54:36,727][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 14:54:36,727][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 14:54:36,727][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 14:54:36,727][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 14:54:36,727][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 14:54:36,728][hannah.modules.vision.base][INFO] - Setting up model resnet18
[2024-05-22 14:54:36,890][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:803: UserWarning: Overwriting focalnet_tiny_srf in registry with hannah.models._vendor.focalnet.focalnet_tiny_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:54:36,890][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:824: UserWarning: Overwriting focalnet_small_srf in registry with hannah.models._vendor.focalnet.focalnet_small_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:54:36,891][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:843: UserWarning: Overwriting focalnet_base_srf in registry with hannah.models._vendor.focalnet.focalnet_base_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:54:36,891][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:862: UserWarning: Overwriting focalnet_tiny_lrf in registry with hannah.models._vendor.focalnet.focalnet_tiny_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:54:36,891][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:885: UserWarning: Overwriting focalnet_small_lrf in registry with hannah.models._vendor.focalnet.focalnet_small_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:54:36,891][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:906: UserWarning: Overwriting focalnet_base_lrf in registry with hannah.models._vendor.focalnet.focalnet_base_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:54:36,891][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1010: UserWarning: Overwriting focalnet_large_fl3 in registry with hannah.models._vendor.focalnet.focalnet_large_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:54:36,891][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1031: UserWarning: Overwriting focalnet_large_fl4 in registry with hannah.models._vendor.focalnet.focalnet_large_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:54:36,891][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1052: UserWarning: Overwriting focalnet_xlarge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:54:36,891][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1073: UserWarning: Overwriting focalnet_xlarge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:54:36,891][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1094: UserWarning: Overwriting focalnet_huge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:54:36,891][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1115: UserWarning: Overwriting focalnet_huge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 14:54:37,020][hannah.models.timm][INFO] - Using default logger for automatic stem creation
[2024-05-22 14:54:37,020][hannah.models.timm][INFO] - Small input size detected trying to adopt small input size
[2024-05-22 14:54:37,037][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '

[2024-05-22 14:54:37,519][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)
[2024-05-22 14:54:37,523][hannah.modules.vision.base][INFO] - Running dummy forward to initialize lazy modules
[2024-05-22 14:54:37,537][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 14:54:37,916][pytorch_lightning.utilities.rank_zero][INFO] - Loading `train_dataloader` to estimate number of stepping batches.
[2024-05-22 14:54:38,446][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

[2024-05-22 14:54:38,704][pytorch_lightning.callbacks.model_summary][INFO] - 
  | Name           | Type                           | Params | In sizes       | Out sizes                          
-------------------------------------------------------------------------------------------------------------------------
0 | val_metrics    | MetricCollection               | 0      | ?              | ?                                  
1 | test_metrics   | MetricCollection               | 0      | ?              | ?                                  
2 | train_metrics  | MetricCollection               | 0      | ?              | ?                                  
3 | model          | TimmModel                      | 11.2 M | [1, 3, 32, 32] | [[1, 512, 4, 4], [0], [0], [1, 10]]
4 | test_confusion | MulticlassConfusionMatrix      | 0      | ?              | ?                                  
5 | test_roc       | MulticlassROC                  | 0      | ?              | ?                                  
6 | test_pr_curve  | MulticlassPrecisionRecallCurve | 0      | ?              | ?                                  
7 | metrics        | ModuleDict                     | 0      | ?              | ?                                  
-------------------------------------------------------------------------------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.696    Total estimated model params size (MB)
[2024-05-22 14:54:38,854][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 14:54:38,854][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 14:54:38,862][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 14:54:40,511][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 14:54:40,512][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 14:54:40,512][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 14:54:40,512][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 14:54:40,512][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 14:54:48,625][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 0, global step 21: 'val_error' reached 0.77808 (best 0.77808), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=21.ckpt' as top 1
[2024-05-22 14:54:58,801][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 1, global step 42: 'val_error' reached 0.70386 (best 0.70386), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=1-step=42.ckpt' as top 1
[2024-05-22 14:55:09,110][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 2, global step 63: 'val_error' reached 0.67920 (best 0.67920), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=2-step=63.ckpt' as top 1
[2024-05-22 14:55:19,311][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 3, global step 84: 'val_error' reached 0.65918 (best 0.65918), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=3-step=84.ckpt' as top 1
[2024-05-22 14:55:29,475][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 4, global step 105: 'val_error' reached 0.64111 (best 0.64111), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=4-step=105.ckpt' as top 1
[2024-05-22 14:55:39,805][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 5, global step 126: 'val_error' reached 0.62622 (best 0.62622), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=5-step=126.ckpt' as top 1
[2024-05-22 14:55:49,908][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 6, global step 147: 'val_error' reached 0.60083 (best 0.60083), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=6-step=147.ckpt' as top 1
[2024-05-22 14:56:00,046][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 7, global step 168: 'val_error' was not in top 1
[2024-05-22 14:56:10,113][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 8, global step 189: 'val_error' reached 0.56641 (best 0.56641), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=8-step=189.ckpt' as top 1
[2024-05-22 14:56:20,292][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 9, global step 210: 'val_error' was not in top 1
[2024-05-22 14:56:30,267][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 10, global step 231: 'val_error' reached 0.55762 (best 0.55762), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=10-step=231.ckpt' as top 1
[2024-05-22 14:56:40,634][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 11, global step 252: 'val_error' was not in top 1
[2024-05-22 14:56:50,696][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 12, global step 273: 'val_error' was not in top 1
[2024-05-22 14:56:58,226][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 13, global step 294: 'val_error' reached 0.49585 (best 0.49585), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=13-step=294.ckpt' as top 1
[2024-05-22 14:57:07,150][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 14, global step 315: 'val_error' was not in top 1
[2024-05-22 14:57:15,968][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 15, global step 336: 'val_error' reached 0.41528 (best 0.41528), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=15-step=336.ckpt' as top 1
[2024-05-22 14:57:24,622][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 16, global step 357: 'val_error' was not in top 1
[2024-05-22 14:57:33,458][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 17, global step 378: 'val_error' reached 0.38574 (best 0.38574), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=17-step=378.ckpt' as top 1
[2024-05-22 14:57:42,177][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 18, global step 399: 'val_error' was not in top 1
[2024-05-22 14:57:50,855][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 19, global step 420: 'val_error' reached 0.37622 (best 0.37622), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=19-step=420.ckpt' as top 1
[2024-05-22 14:57:59,725][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 20, global step 441: 'val_error' reached 0.35815 (best 0.35815), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=20-step=441.ckpt' as top 1
[2024-05-22 14:58:08,499][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 21, global step 462: 'val_error' was not in top 1
[2024-05-22 14:58:17,377][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 22, global step 483: 'val_error' reached 0.32251 (best 0.32251), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=22-step=483.ckpt' as top 1
[2024-05-22 14:58:26,450][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 23, global step 504: 'val_error' was not in top 1
[2024-05-22 14:58:34,862][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 24, global step 525: 'val_error' was not in top 1
[2024-05-22 14:58:43,689][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 25, global step 546: 'val_error' reached 0.27417 (best 0.27417), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=25-step=546.ckpt' as top 1
[2024-05-22 14:58:52,376][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 26, global step 567: 'val_error' reached 0.26440 (best 0.26440), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=26-step=567.ckpt' as top 1
[2024-05-22 14:59:01,125][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 27, global step 588: 'val_error' was not in top 1
[2024-05-22 14:59:09,739][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 28, global step 609: 'val_error' was not in top 1
[2024-05-22 14:59:18,455][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 29, global step 630: 'val_error' reached 0.23169 (best 0.23169), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=29-step=630.ckpt' as top 1
[2024-05-22 14:59:28,029][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 30, global step 651: 'val_error' was not in top 1
[2024-05-22 14:59:37,418][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 31, global step 672: 'val_error' was not in top 1
[2024-05-22 14:59:46,581][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 32, global step 693: 'val_error' reached 0.21973 (best 0.21973), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=32-step=693.ckpt' as top 1
[2024-05-22 14:59:56,250][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 33, global step 714: 'val_error' reached 0.21753 (best 0.21753), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=33-step=714.ckpt' as top 1
[2024-05-22 15:00:05,800][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 34, global step 735: 'val_error' was not in top 1
[2024-05-22 15:00:15,460][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 35, global step 756: 'val_error' reached 0.20508 (best 0.20508), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=35-step=756.ckpt' as top 1
[2024-05-22 15:00:25,042][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 36, global step 777: 'val_error' was not in top 1
[2024-05-22 15:00:34,321][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 37, global step 798: 'val_error' was not in top 1
[2024-05-22 15:00:43,774][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 38, global step 819: 'val_error' reached 0.18677 (best 0.18677), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=38-step=819.ckpt' as top 1
[2024-05-22 15:00:53,328][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 39, global step 840: 'val_error' reached 0.17627 (best 0.17627), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=39-step=840.ckpt' as top 1
[2024-05-22 15:01:03,106][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 40, global step 861: 'val_error' reached 0.16797 (best 0.16797), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=40-step=861.ckpt' as top 1
[2024-05-22 15:01:12,769][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 41, global step 882: 'val_error' reached 0.15332 (best 0.15332), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=41-step=882.ckpt' as top 1
[2024-05-22 15:01:22,220][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 42, global step 903: 'val_error' was not in top 1
[2024-05-22 15:01:31,488][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 43, global step 924: 'val_error' was not in top 1
[2024-05-22 15:01:40,863][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 44, global step 945: 'val_error' was not in top 1
[2024-05-22 15:01:50,191][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 45, global step 966: 'val_error' reached 0.14453 (best 0.14453), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=45-step=966.ckpt' as top 1
[2024-05-22 15:01:59,989][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 46, global step 987: 'val_error' reached 0.13599 (best 0.13599), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=46-step=987.ckpt' as top 1
[2024-05-22 15:02:09,641][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 47, global step 1008: 'val_error' was not in top 1
[2024-05-22 15:02:19,436][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 48, global step 1029: 'val_error' was not in top 1
[2024-05-22 15:02:28,848][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 49, global step 1050: 'val_error' was not in top 1
[2024-05-22 15:02:29,063][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer.fit` stopped: `max_epochs=50` reached.
[2024-05-22 15:02:29,923][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:02:29,923][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 15:02:29,925][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=46-step=987.ckpt
[2024-05-22 15:02:29,975][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:02:30,176][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:02:30,176][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:02:30,178][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:02:30,401][pytorch_lightning.utilities.rank_zero][INFO] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=46-step=987.ckpt
[2024-05-22 15:02:31,667][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:02:31,667][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 15:02:31,669][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=46-step=987.ckpt
[2024-05-22 15:02:31,714][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:02:31,969][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:02:31,969][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:02:31,971][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:02:32,202][pytorch_lightning.utilities.rank_zero][INFO] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=46-step=987.ckpt
[2024-05-22 15:02:33,618][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 15:02:33,619][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 15:02:33,619][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 15:02:33,619][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 15:02:33,619][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 15:02:33,621][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:02:33,622][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:02:34,136][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:02:34,288][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:02:34,563][hannah.train][INFO] - Averaged Result Metrics:
| Metric               |     Mean |   Std |   Count |
|----------------------|----------|-------|---------|
| test_classifier_loss | 0.395788 |     0 |       1 |
| test_accuracy        | 0.865356 |     0 |       1 |
| test_error           | 0.134644 |     0 |       1 |
| test_f1              | 0.865083 |     0 |       1 |
| test_precision       | 0.86628  |     0 |       1 |
| test_recall          | 0.865796 |     0 |       1 |
| test_loss            | 0.395788 |     0 |       1 |
[2024-05-22 15:02:34,574][hannah.train][INFO] - Averaged Result Metrics:
| Metric              |     Mean |   Std |   Count |
|---------------------|----------|-------|---------|
| val_classifier_loss | 0.412536 |     0 |       1 |
| val_accuracy        | 0.864014 |     0 |       1 |
| val_error           | 0.135986 |     0 |       1 |
| val_f1              | 0.862627 |     0 |       1 |
| val_precision       | 0.864705 |     0 |       1 |
| val_recall          | 0.862893 |     0 |       1 |
| val_loss            | 0.412536 |     0 |       1 |
[2024-05-22 15:08:41,226][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 15:08:41,331][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 15:08:41,332][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 15:08:41,336][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 15:08:41,336][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 15:08:41,336][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 15:08:41,336][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 15:08:41,336][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 15:08:41,336][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 15:08:41,336][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 15:08:41,337][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 15:08:41,338][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train
[2024-05-22 15:08:41,338][hannah.utils.utils][INFO] -   
[2024-05-22 15:08:41,339][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:08:41,375][root][INFO] - Configuration: 
[2024-05-22 15:08:41,378][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
  sensor:
    resolution:
    - 32
    - 32
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 15:08:41,379][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 15:08:42,123][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 15:08:42,123][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 15:08:42,190][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 15:08:42,214][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 15:08:42,221][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 15:08:42,221][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 15:08:42,221][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 15:08:42,221][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 15:08:42,221][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 15:08:42,221][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:08:42,221][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:08:42,221][root][INFO] - Starting training
[2024-05-22 15:08:43,683][root][ERROR] - Exception Message: module 'albumentations' has no attribute 'RandomHorizontalFlip'
Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 949, in _run
    call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 94, in _call_setup_hook
    _call_lightning_module_hook(trainer, "setup", stage=fn)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 60, in setup
    data_splits: Tuple[Any] = dataset_cls.splits(self.hparams.dataset)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/cifar.py", line 80, in splits
    train_transform = transforms.get_transform(train=True)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/albumentations.py", line 63, in get_transform
    default_augment(M=1,N=3),
    ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/albumentations.py", line 34, in default_augment
    A.RandomHorizontalFlip(p=0.5),
    ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'albumentations' has no attribute 'RandomHorizontalFlip'
[2024-05-22 15:09:00,351][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 15:09:00,454][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 15:09:00,455][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 15:09:00,459][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 15:09:00,459][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 15:09:00,459][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 15:09:00,459][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 15:09:00,459][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 15:09:00,459][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 15:09:00,459][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 15:09:00,461][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 15:09:00,461][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train
[2024-05-22 15:09:00,461][hannah.utils.utils][INFO] -   
[2024-05-22 15:09:00,462][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:09:00,463][root][INFO] - Configuration: 
[2024-05-22 15:09:00,467][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
  sensor:
    resolution:
    - 32
    - 32
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 15:09:00,467][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 15:09:01,224][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 15:09:01,224][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 15:09:01,292][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 15:09:01,317][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 15:09:01,324][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 15:09:01,324][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 15:09:01,324][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 15:09:01,324][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 15:09:01,324][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 15:09:01,324][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:09:01,324][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:09:01,324][root][INFO] - Starting training
[2024-05-22 15:09:02,756][root][ERROR] - Exception Message: module 'albumentations' has no attribute 'RandomAffine'
Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 175, in train
    lit_trainer.fit(lit_module, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 949, in _run
    call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 94, in _call_setup_hook
    _call_lightning_module_hook(trainer, "setup", stage=fn)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 60, in setup
    data_splits: Tuple[Any] = dataset_cls.splits(self.hparams.dataset)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/cifar.py", line 80, in splits
    train_transform = transforms.get_transform(train=True)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/albumentations.py", line 62, in get_transform
    default_augment(M=1,N=3),
    ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/datasets/vision/albumentations.py", line 34, in default_augment
    A.RandomAffine(degrees=M*10, scale=(1-M*.1, 1+M*.1), shear=M*5, p=0.5),
    ^^^^^^^^^^^^^^
AttributeError: module 'albumentations' has no attribute 'RandomAffine'
[2024-05-22 15:09:59,812][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 15:09:59,912][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 15:09:59,912][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 15:09:59,916][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 15:09:59,916][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 15:09:59,916][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 15:09:59,916][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 15:09:59,916][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 15:09:59,916][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 15:09:59,916][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 15:09:59,917][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 15:09:59,918][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train
[2024-05-22 15:09:59,918][hannah.utils.utils][INFO] -   
[2024-05-22 15:09:59,919][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:09:59,920][root][INFO] - Configuration: 
[2024-05-22 15:09:59,923][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
  sensor:
    resolution:
    - 32
    - 32
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 15:09:59,924][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 15:10:00,657][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 15:10:00,657][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 15:10:00,725][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 15:10:00,749][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 15:10:00,755][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 15:10:00,756][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 15:10:00,756][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 15:10:00,756][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 15:10:00,756][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 15:10:00,756][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:10:00,756][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:10:00,756][root][INFO] - Starting training
[2024-05-22 15:10:02,211][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 15:10:02,211][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 15:10:02,211][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 15:10:02,211][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 15:10:02,211][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 15:10:02,211][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 15:10:02,212][hannah.modules.vision.base][INFO] - Setting up model resnet18
[2024-05-22 15:10:02,374][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:803: UserWarning: Overwriting focalnet_tiny_srf in registry with hannah.models._vendor.focalnet.focalnet_tiny_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:10:02,374][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:824: UserWarning: Overwriting focalnet_small_srf in registry with hannah.models._vendor.focalnet.focalnet_small_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:10:02,374][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:843: UserWarning: Overwriting focalnet_base_srf in registry with hannah.models._vendor.focalnet.focalnet_base_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:10:02,374][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:862: UserWarning: Overwriting focalnet_tiny_lrf in registry with hannah.models._vendor.focalnet.focalnet_tiny_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:10:02,374][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:885: UserWarning: Overwriting focalnet_small_lrf in registry with hannah.models._vendor.focalnet.focalnet_small_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:10:02,374][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:906: UserWarning: Overwriting focalnet_base_lrf in registry with hannah.models._vendor.focalnet.focalnet_base_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:10:02,374][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1010: UserWarning: Overwriting focalnet_large_fl3 in registry with hannah.models._vendor.focalnet.focalnet_large_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:10:02,374][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1031: UserWarning: Overwriting focalnet_large_fl4 in registry with hannah.models._vendor.focalnet.focalnet_large_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:10:02,375][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1052: UserWarning: Overwriting focalnet_xlarge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:10:02,375][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1073: UserWarning: Overwriting focalnet_xlarge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:10:02,375][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1094: UserWarning: Overwriting focalnet_huge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:10:02,375][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1115: UserWarning: Overwriting focalnet_huge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:10:02,533][hannah.models.timm][INFO] - Using default logger for automatic stem creation
[2024-05-22 15:10:02,533][hannah.models.timm][INFO] - Small input size detected trying to adopt small input size
[2024-05-22 15:10:02,549][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '

[2024-05-22 15:10:03,025][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)
[2024-05-22 15:10:03,029][hannah.modules.vision.base][INFO] - Running dummy forward to initialize lazy modules
[2024-05-22 15:10:03,048][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:10:03,428][pytorch_lightning.utilities.rank_zero][INFO] - Loading `train_dataloader` to estimate number of stepping batches.
[2024-05-22 15:10:03,429][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=191` in the `DataLoader` to improve performance.

[2024-05-22 15:10:03,450][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

[2024-05-22 15:10:03,664][pytorch_lightning.callbacks.model_summary][INFO] - 
  | Name           | Type                           | Params | In sizes       | Out sizes                          
-------------------------------------------------------------------------------------------------------------------------
0 | val_metrics    | MetricCollection               | 0      | ?              | ?                                  
1 | test_metrics   | MetricCollection               | 0      | ?              | ?                                  
2 | train_metrics  | MetricCollection               | 0      | ?              | ?                                  
3 | model          | TimmModel                      | 11.2 M | [1, 3, 32, 32] | [[1, 512, 4, 4], [0], [0], [1, 10]]
4 | test_confusion | MulticlassConfusionMatrix      | 0      | ?              | ?                                  
5 | test_roc       | MulticlassROC                  | 0      | ?              | ?                                  
6 | test_pr_curve  | MulticlassPrecisionRecallCurve | 0      | ?              | ?                                  
7 | metrics        | ModuleDict                     | 0      | ?              | ?                                  
-------------------------------------------------------------------------------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.696    Total estimated model params size (MB)
[2024-05-22 15:10:03,799][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:10:03,799][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:10:03,804][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:10:04,094][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=191` in the `DataLoader` to improve performance.

[2024-05-22 15:10:04,869][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 15:10:04,869][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 15:10:04,869][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 15:10:04,869][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 15:10:04,870][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 15:10:15,391][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 0, global step 21: 'val_error' reached 0.78662 (best 0.78662), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=21.ckpt' as top 1
[2024-05-22 15:10:25,971][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 1, global step 42: 'val_error' reached 0.75391 (best 0.75391), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=1-step=42.ckpt' as top 1
[2024-05-22 15:10:36,555][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 2, global step 63: 'val_error' reached 0.71021 (best 0.71021), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=2-step=63.ckpt' as top 1
[2024-05-22 15:10:47,399][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 3, global step 84: 'val_error' reached 0.70215 (best 0.70215), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=3-step=84.ckpt' as top 1
[2024-05-22 15:10:53,868][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...

[2024-05-22 15:10:53,875][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:10:53,875][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 15:10:53,877][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=3-step=84.ckpt
[2024-05-22 15:10:54,105][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:10:54,211][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:10:54,211][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:10:54,213][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:10:54,231][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:10:54,231][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 15:10:54,232][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=3-step=84.ckpt
[2024-05-22 15:10:54,458][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:12:36,464][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 15:12:36,566][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 15:12:36,567][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 15:12:36,571][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 15:12:36,571][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 15:12:36,571][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 15:12:36,571][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 15:12:36,571][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 15:12:36,571][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 15:12:36,571][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 15:12:36,573][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 15:12:36,573][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train
[2024-05-22 15:12:36,573][hannah.utils.utils][INFO] -   
[2024-05-22 15:12:36,574][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:12:36,603][root][INFO] - Configuration: 
[2024-05-22 15:12:36,606][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
  sensor:
    resolution:
    - 32
    - 32
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 15:12:36,606][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 15:12:37,346][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 15:12:37,346][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 15:12:37,415][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 15:12:37,439][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 15:12:37,446][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 15:12:37,446][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 15:12:37,446][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 15:12:37,446][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 15:12:37,446][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 15:12:37,446][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:12:37,446][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:12:37,446][root][INFO] - Starting training
[2024-05-22 15:12:38,879][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 15:12:38,879][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 15:12:38,879][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 15:12:38,879][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 15:12:38,879][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 15:12:38,879][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 15:12:38,880][hannah.modules.vision.base][INFO] - Setting up model resnet18
[2024-05-22 15:12:39,041][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:803: UserWarning: Overwriting focalnet_tiny_srf in registry with hannah.models._vendor.focalnet.focalnet_tiny_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:12:39,042][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:824: UserWarning: Overwriting focalnet_small_srf in registry with hannah.models._vendor.focalnet.focalnet_small_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:12:39,042][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:843: UserWarning: Overwriting focalnet_base_srf in registry with hannah.models._vendor.focalnet.focalnet_base_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:12:39,042][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:862: UserWarning: Overwriting focalnet_tiny_lrf in registry with hannah.models._vendor.focalnet.focalnet_tiny_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:12:39,042][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:885: UserWarning: Overwriting focalnet_small_lrf in registry with hannah.models._vendor.focalnet.focalnet_small_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:12:39,042][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:906: UserWarning: Overwriting focalnet_base_lrf in registry with hannah.models._vendor.focalnet.focalnet_base_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:12:39,042][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1010: UserWarning: Overwriting focalnet_large_fl3 in registry with hannah.models._vendor.focalnet.focalnet_large_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:12:39,042][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1031: UserWarning: Overwriting focalnet_large_fl4 in registry with hannah.models._vendor.focalnet.focalnet_large_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:12:39,042][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1052: UserWarning: Overwriting focalnet_xlarge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:12:39,042][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1073: UserWarning: Overwriting focalnet_xlarge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:12:39,042][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1094: UserWarning: Overwriting focalnet_huge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:12:39,042][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1115: UserWarning: Overwriting focalnet_huge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:12:39,186][hannah.models.timm][INFO] - Using default logger for automatic stem creation
[2024-05-22 15:12:39,187][hannah.models.timm][INFO] - Small input size detected trying to adopt small input size
[2024-05-22 15:12:39,203][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '

[2024-05-22 15:12:39,678][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)
[2024-05-22 15:12:39,683][hannah.modules.vision.base][INFO] - Running dummy forward to initialize lazy modules
[2024-05-22 15:12:39,697][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:12:40,098][pytorch_lightning.utilities.rank_zero][INFO] - Loading `train_dataloader` to estimate number of stepping batches.
[2024-05-22 15:12:40,098][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=191` in the `DataLoader` to improve performance.

[2024-05-22 15:12:40,120][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

[2024-05-22 15:12:40,345][pytorch_lightning.callbacks.model_summary][INFO] - 
  | Name           | Type                           | Params | In sizes       | Out sizes                          
-------------------------------------------------------------------------------------------------------------------------
0 | val_metrics    | MetricCollection               | 0      | ?              | ?                                  
1 | test_metrics   | MetricCollection               | 0      | ?              | ?                                  
2 | train_metrics  | MetricCollection               | 0      | ?              | ?                                  
3 | model          | TimmModel                      | 11.2 M | [1, 3, 32, 32] | [[1, 512, 4, 4], [0], [0], [1, 10]]
4 | test_confusion | MulticlassConfusionMatrix      | 0      | ?              | ?                                  
5 | test_roc       | MulticlassROC                  | 0      | ?              | ?                                  
6 | test_pr_curve  | MulticlassPrecisionRecallCurve | 0      | ?              | ?                                  
7 | metrics        | ModuleDict                     | 0      | ?              | ?                                  
-------------------------------------------------------------------------------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.696    Total estimated model params size (MB)
[2024-05-22 15:12:40,480][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:12:40,481][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:12:40,486][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:12:40,774][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=191` in the `DataLoader` to improve performance.

[2024-05-22 15:12:41,535][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 15:12:41,536][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 15:12:41,536][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 15:12:41,536][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 15:12:41,536][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 15:12:59,536][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 0, global step 21: 'val_error' reached 0.78784 (best 0.78784), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=21.ckpt' as top 1
[2024-05-22 15:13:17,514][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 1, global step 42: 'val_error' reached 0.74146 (best 0.74146), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=1-step=42.ckpt' as top 1
[2024-05-22 15:13:35,666][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 2, global step 63: 'val_error' reached 0.71143 (best 0.71143), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=2-step=63.ckpt' as top 1
[2024-05-22 15:13:54,228][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 3, global step 84: 'val_error' reached 0.70654 (best 0.70654), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=3-step=84.ckpt' as top 1
[2024-05-22 15:14:12,406][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 4, global step 105: 'val_error' reached 0.67017 (best 0.67017), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=4-step=105.ckpt' as top 1
[2024-05-22 15:14:30,720][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 5, global step 126: 'val_error' reached 0.66626 (best 0.66626), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=5-step=126.ckpt' as top 1
[2024-05-22 15:14:48,989][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 6, global step 147: 'val_error' reached 0.66040 (best 0.66040), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=6-step=147.ckpt' as top 1
[2024-05-22 15:15:07,097][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 7, global step 168: 'val_error' reached 0.58252 (best 0.58252), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=7-step=168.ckpt' as top 1
[2024-05-22 15:15:25,320][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 8, global step 189: 'val_error' reached 0.56543 (best 0.56543), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=8-step=189.ckpt' as top 1
[2024-05-22 15:15:35,852][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...

[2024-05-22 15:15:35,859][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:15:35,859][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 15:15:35,860][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=8-step=189.ckpt
[2024-05-22 15:15:36,095][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:15:36,202][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:15:36,203][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:15:36,204][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:15:36,366][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:15:36,366][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 15:15:36,367][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=8-step=189.ckpt
[2024-05-22 15:15:36,396][hannah.train][INFO] - Averaged Result Metrics:
| Metric              |     Mean |   Std |   Count |
|---------------------|----------|-------|---------|
| val_classifier_loss | 1.55599  |     0 |       1 |
| val_accuracy        | 0.43457  |     0 |       1 |
| val_error           | 0.56543  |     0 |       1 |
| val_f1              | 0.421084 |     0 |       1 |
| val_precision       | 0.483885 |     0 |       1 |
| val_recall          | 0.436065 |     0 |       1 |
| val_loss            | 1.55599  |     0 |       1 |
[2024-05-22 15:15:49,996][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 15:15:50,099][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 15:15:50,100][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 15:15:50,104][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 15:15:50,104][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 15:15:50,104][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 15:15:50,104][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 15:15:50,104][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 15:15:50,104][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 15:15:50,104][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 15:15:50,106][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 15:15:50,106][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32
[2024-05-22 15:15:50,106][hannah.utils.utils][INFO] -   
[2024-05-22 15:15:50,107][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:15:50,141][root][INFO] - Configuration: 
[2024-05-22 15:15:50,145][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
  sensor:
    resolution:
    - 32
    - 32
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 15:15:50,145][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 15:15:50,894][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 15:15:50,894][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 15:15:50,961][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 15:15:50,985][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 15:15:50,992][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 15:15:50,992][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 15:15:50,992][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 15:15:50,992][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 15:15:50,992][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 15:15:50,992][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:15:50,992][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:15:50,992][root][INFO] - Starting training
[2024-05-22 15:15:52,459][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 15:15:52,459][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 15:15:52,459][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 15:15:52,459][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 15:15:52,459][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 15:15:52,459][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 15:15:52,460][hannah.modules.vision.base][INFO] - Setting up model resnet18
[2024-05-22 15:15:52,624][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:803: UserWarning: Overwriting focalnet_tiny_srf in registry with hannah.models._vendor.focalnet.focalnet_tiny_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:15:52,624][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:824: UserWarning: Overwriting focalnet_small_srf in registry with hannah.models._vendor.focalnet.focalnet_small_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:15:52,624][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:843: UserWarning: Overwriting focalnet_base_srf in registry with hannah.models._vendor.focalnet.focalnet_base_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:15:52,624][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:862: UserWarning: Overwriting focalnet_tiny_lrf in registry with hannah.models._vendor.focalnet.focalnet_tiny_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:15:52,625][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:885: UserWarning: Overwriting focalnet_small_lrf in registry with hannah.models._vendor.focalnet.focalnet_small_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:15:52,625][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:906: UserWarning: Overwriting focalnet_base_lrf in registry with hannah.models._vendor.focalnet.focalnet_base_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:15:52,625][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1010: UserWarning: Overwriting focalnet_large_fl3 in registry with hannah.models._vendor.focalnet.focalnet_large_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:15:52,625][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1031: UserWarning: Overwriting focalnet_large_fl4 in registry with hannah.models._vendor.focalnet.focalnet_large_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:15:52,625][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1052: UserWarning: Overwriting focalnet_xlarge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:15:52,625][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1073: UserWarning: Overwriting focalnet_xlarge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:15:52,625][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1094: UserWarning: Overwriting focalnet_huge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:15:52,625][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1115: UserWarning: Overwriting focalnet_huge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:15:52,778][hannah.models.timm][INFO] - Using default logger for automatic stem creation
[2024-05-22 15:15:52,778][hannah.models.timm][INFO] - Small input size detected trying to adopt small input size
[2024-05-22 15:15:52,794][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '

[2024-05-22 15:15:53,251][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)
[2024-05-22 15:15:53,255][hannah.modules.vision.base][INFO] - Running dummy forward to initialize lazy modules
[2024-05-22 15:15:53,269][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:15:53,678][pytorch_lightning.utilities.rank_zero][INFO] - Loading `train_dataloader` to estimate number of stepping batches.
[2024-05-22 15:15:54,211][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

[2024-05-22 15:15:54,447][pytorch_lightning.callbacks.model_summary][INFO] - 
  | Name           | Type                           | Params | In sizes       | Out sizes                          
-------------------------------------------------------------------------------------------------------------------------
0 | val_metrics    | MetricCollection               | 0      | ?              | ?                                  
1 | test_metrics   | MetricCollection               | 0      | ?              | ?                                  
2 | train_metrics  | MetricCollection               | 0      | ?              | ?                                  
3 | model          | TimmModel                      | 11.2 M | [1, 3, 32, 32] | [[1, 512, 4, 4], [0], [0], [1, 10]]
4 | test_confusion | MulticlassConfusionMatrix      | 0      | ?              | ?                                  
5 | test_roc       | MulticlassROC                  | 0      | ?              | ?                                  
6 | test_pr_curve  | MulticlassPrecisionRecallCurve | 0      | ?              | ?                                  
7 | metrics        | ModuleDict                     | 0      | ?              | ?                                  
-------------------------------------------------------------------------------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.696    Total estimated model params size (MB)
[2024-05-22 15:15:54,592][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:15:54,593][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:15:54,600][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:15:56,460][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 15:15:56,460][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 15:15:56,460][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 15:15:56,460][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 15:15:56,460][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 15:16:02,816][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 0, global step 21: 'val_error' reached 0.78760 (best 0.78760), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=21.ckpt' as top 1
[2024-05-22 15:16:10,020][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 1, global step 42: 'val_error' reached 0.74536 (best 0.74536), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=1-step=42.ckpt' as top 1
[2024-05-22 15:16:17,218][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 2, global step 63: 'val_error' reached 0.70703 (best 0.70703), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=2-step=63.ckpt' as top 1
[2024-05-22 15:16:24,581][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 3, global step 84: 'val_error' reached 0.70386 (best 0.70386), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=3-step=84.ckpt' as top 1
[2024-05-22 15:16:31,933][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 4, global step 105: 'val_error' reached 0.68433 (best 0.68433), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=4-step=105.ckpt' as top 1
[2024-05-22 15:16:39,065][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 5, global step 126: 'val_error' was not in top 1
[2024-05-22 15:16:46,197][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 6, global step 147: 'val_error' reached 0.62915 (best 0.62915), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=6-step=147.ckpt' as top 1
[2024-05-22 15:16:53,450][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 7, global step 168: 'val_error' reached 0.61011 (best 0.61011), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=7-step=168.ckpt' as top 1
[2024-05-22 15:17:00,760][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 8, global step 189: 'val_error' reached 0.55615 (best 0.55615), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=8-step=189.ckpt' as top 1
[2024-05-22 15:17:08,022][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 9, global step 210: 'val_error' was not in top 1
[2024-05-22 15:17:15,096][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 10, global step 231: 'val_error' reached 0.51880 (best 0.51880), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=10-step=231.ckpt' as top 1
[2024-05-22 15:17:22,416][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 11, global step 252: 'val_error' reached 0.49268 (best 0.49268), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=11-step=252.ckpt' as top 1
[2024-05-22 15:17:29,648][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 12, global step 273: 'val_error' reached 0.48730 (best 0.48730), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=12-step=273.ckpt' as top 1
[2024-05-22 15:17:36,960][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 13, global step 294: 'val_error' reached 0.45972 (best 0.45972), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=13-step=294.ckpt' as top 1
[2024-05-22 15:17:44,325][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 14, global step 315: 'val_error' reached 0.44971 (best 0.44971), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=14-step=315.ckpt' as top 1
[2024-05-22 15:17:51,877][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 15, global step 336: 'val_error' was not in top 1
[2024-05-22 15:17:54,496][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...

[2024-05-22 15:17:54,503][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:17:54,504][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 15:17:54,506][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=14-step=315.ckpt
[2024-05-22 15:17:54,747][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:17:54,860][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:17:54,860][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:17:54,862][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:17:54,899][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:17:54,900][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 15:17:54,901][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=14-step=315.ckpt
[2024-05-22 15:17:54,926][hannah.train][INFO] - Averaged Result Metrics:
| Metric              |     Mean |   Std |   Count |
|---------------------|----------|-------|---------|
| val_classifier_loss | 1.68123  |     0 |       1 |
| val_accuracy        | 0.490967 |     0 |       1 |
| val_error           | 0.509033 |     0 |       1 |
| val_f1              | 0.489434 |     0 |       1 |
| val_precision       | 0.611718 |     0 |       1 |
| val_recall          | 0.491295 |     0 |       1 |
| val_loss            | 1.68123  |     0 |       1 |
[2024-05-22 15:18:09,654][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 15:18:09,766][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 15:18:09,767][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 15:18:09,770][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 15:18:09,770][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 15:18:09,770][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 15:18:09,770][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 15:18:09,770][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 15:18:09,770][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 15:18:09,770][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 15:18:09,772][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 15:18:09,772][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32 trainer.max_epochs=10
[2024-05-22 15:18:09,772][hannah.utils.utils][INFO] -   
[2024-05-22 15:18:09,773][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:18:09,808][root][INFO] - Configuration: 
[2024-05-22 15:18:09,811][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
  sensor:
    resolution:
    - 32
    - 32
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 10
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 15:18:09,812][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 15:18:10,564][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 15:18:10,564][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 15:18:10,621][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 15:18:10,646][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 15:18:10,653][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 15:18:10,653][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 15:18:10,653][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 15:18:10,653][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 15:18:10,653][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 15:18:10,653][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:18:10,653][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:18:10,653][root][INFO] - Starting training
[2024-05-22 15:18:12,125][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 15:18:12,125][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 15:18:12,125][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 15:18:12,125][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 15:18:12,125][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 15:18:12,125][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 15:18:12,126][hannah.modules.vision.base][INFO] - Setting up model resnet18
[2024-05-22 15:18:12,289][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:803: UserWarning: Overwriting focalnet_tiny_srf in registry with hannah.models._vendor.focalnet.focalnet_tiny_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:18:12,289][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:824: UserWarning: Overwriting focalnet_small_srf in registry with hannah.models._vendor.focalnet.focalnet_small_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:18:12,289][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:843: UserWarning: Overwriting focalnet_base_srf in registry with hannah.models._vendor.focalnet.focalnet_base_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:18:12,289][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:862: UserWarning: Overwriting focalnet_tiny_lrf in registry with hannah.models._vendor.focalnet.focalnet_tiny_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:18:12,289][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:885: UserWarning: Overwriting focalnet_small_lrf in registry with hannah.models._vendor.focalnet.focalnet_small_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:18:12,290][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:906: UserWarning: Overwriting focalnet_base_lrf in registry with hannah.models._vendor.focalnet.focalnet_base_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:18:12,290][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1010: UserWarning: Overwriting focalnet_large_fl3 in registry with hannah.models._vendor.focalnet.focalnet_large_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:18:12,290][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1031: UserWarning: Overwriting focalnet_large_fl4 in registry with hannah.models._vendor.focalnet.focalnet_large_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:18:12,290][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1052: UserWarning: Overwriting focalnet_xlarge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:18:12,290][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1073: UserWarning: Overwriting focalnet_xlarge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:18:12,290][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1094: UserWarning: Overwriting focalnet_huge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:18:12,290][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1115: UserWarning: Overwriting focalnet_huge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:18:12,420][hannah.models.timm][INFO] - Using default logger for automatic stem creation
[2024-05-22 15:18:12,420][hannah.models.timm][INFO] - Small input size detected trying to adopt small input size
[2024-05-22 15:18:12,437][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '

[2024-05-22 15:18:12,898][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)
[2024-05-22 15:18:12,902][hannah.modules.vision.base][INFO] - Running dummy forward to initialize lazy modules
[2024-05-22 15:18:12,916][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:18:13,295][pytorch_lightning.utilities.rank_zero][INFO] - Loading `train_dataloader` to estimate number of stepping batches.
[2024-05-22 15:18:13,735][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

[2024-05-22 15:18:13,960][pytorch_lightning.callbacks.model_summary][INFO] - 
  | Name           | Type                           | Params | In sizes       | Out sizes                          
-------------------------------------------------------------------------------------------------------------------------
0 | val_metrics    | MetricCollection               | 0      | ?              | ?                                  
1 | test_metrics   | MetricCollection               | 0      | ?              | ?                                  
2 | train_metrics  | MetricCollection               | 0      | ?              | ?                                  
3 | model          | TimmModel                      | 11.2 M | [1, 3, 32, 32] | [[1, 512, 4, 4], [0], [0], [1, 10]]
4 | test_confusion | MulticlassConfusionMatrix      | 0      | ?              | ?                                  
5 | test_roc       | MulticlassROC                  | 0      | ?              | ?                                  
6 | test_pr_curve  | MulticlassPrecisionRecallCurve | 0      | ?              | ?                                  
7 | metrics        | ModuleDict                     | 0      | ?              | ?                                  
-------------------------------------------------------------------------------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.696    Total estimated model params size (MB)
[2024-05-22 15:18:14,101][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:18:14,101][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:18:14,108][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:18:15,862][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 15:18:15,863][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 15:18:15,863][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 15:18:15,863][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 15:18:15,863][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 15:18:22,137][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 0, global step 21: 'val_error' reached 0.77515 (best 0.77515), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=21.ckpt' as top 1
[2024-05-22 15:18:29,462][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 1, global step 42: 'val_error' reached 0.69946 (best 0.69946), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=1-step=42.ckpt' as top 1
[2024-05-22 15:18:36,782][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 2, global step 63: 'val_error' reached 0.65771 (best 0.65771), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=2-step=63.ckpt' as top 1
[2024-05-22 15:18:44,062][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 3, global step 84: 'val_error' reached 0.65747 (best 0.65747), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=3-step=84.ckpt' as top 1
[2024-05-22 15:18:51,419][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 4, global step 105: 'val_error' reached 0.61133 (best 0.61133), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=4-step=105.ckpt' as top 1
[2024-05-22 15:18:58,696][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 5, global step 126: 'val_error' reached 0.56348 (best 0.56348), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=5-step=126.ckpt' as top 1
[2024-05-22 15:19:05,993][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 6, global step 147: 'val_error' reached 0.52197 (best 0.52197), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=6-step=147.ckpt' as top 1
[2024-05-22 15:19:13,251][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 7, global step 168: 'val_error' reached 0.50854 (best 0.50854), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=7-step=168.ckpt' as top 1
[2024-05-22 15:19:20,572][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 8, global step 189: 'val_error' reached 0.47363 (best 0.47363), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=8-step=189.ckpt' as top 1
[2024-05-22 15:19:27,934][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 9, global step 210: 'val_error' reached 0.44189 (best 0.44189), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=210.ckpt' as top 1
[2024-05-22 15:19:28,352][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer.fit` stopped: `max_epochs=10` reached.
[2024-05-22 15:19:28,585][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:19:28,586][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 15:19:28,588][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=210.ckpt
[2024-05-22 15:19:28,633][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:19:29,128][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:19:29,129][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:19:29,130][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:19:29,347][pytorch_lightning.utilities.rank_zero][INFO] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=210.ckpt
[2024-05-22 15:19:30,660][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:19:30,661][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 15:19:30,662][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=210.ckpt
[2024-05-22 15:19:30,703][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:19:31,204][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:19:31,204][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:19:31,206][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:19:31,425][pytorch_lightning.utilities.rank_zero][INFO] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=210.ckpt
[2024-05-22 15:19:32,874][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 15:19:32,875][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 15:19:32,875][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 15:19:32,875][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 15:19:32,875][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 15:19:32,877][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:19:32,877][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:19:33,396][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:19:33,544][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:19:33,841][hannah.train][INFO] - Averaged Result Metrics:
| Metric               |     Mean |   Std |   Count |
|----------------------|----------|-------|---------|
| test_classifier_loss | 1.25284  |     0 |       1 |
| test_accuracy        | 0.546509 |     0 |       1 |
| test_error           | 0.453491 |     0 |       1 |
| test_f1              | 0.541218 |     0 |       1 |
| test_precision       | 0.571802 |     0 |       1 |
| test_recall          | 0.547473 |     0 |       1 |
| test_loss            | 1.25284  |     0 |       1 |
[2024-05-22 15:19:33,852][hannah.train][INFO] - Averaged Result Metrics:
| Metric              |     Mean |   Std |   Count |
|---------------------|----------|-------|---------|
| val_classifier_loss | 1.24052  |     0 |       1 |
| val_accuracy        | 0.558105 |     0 |       1 |
| val_error           | 0.441895 |     0 |       1 |
| val_f1              | 0.550416 |     0 |       1 |
| val_precision       | 0.577176 |     0 |       1 |
| val_recall          | 0.558632 |     0 |       1 |
| val_loss            | 1.24052  |     0 |       1 |
[2024-05-22 15:20:34,568][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 15:20:34,673][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 15:20:34,674][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 15:20:34,677][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 15:20:34,677][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 15:20:34,677][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 15:20:34,677][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 15:20:34,677][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 15:20:34,677][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 15:20:34,677][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 15:20:34,679][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 15:20:34,679][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32 trainer.max_epochs=10
[2024-05-22 15:20:34,679][hannah.utils.utils][INFO] -   
[2024-05-22 15:20:34,680][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:20:34,710][root][INFO] - Configuration: 
[2024-05-22 15:20:34,713][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
  sensor:
    resolution:
    - 32
    - 32
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 10
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 15:20:34,713][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 15:20:35,479][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 15:20:35,479][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 15:20:35,550][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 15:20:35,576][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 15:20:35,583][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 15:20:35,583][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 15:20:35,583][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 15:20:35,583][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 15:20:35,584][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 15:20:35,584][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:20:35,584][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:20:35,584][root][INFO] - Starting training
[2024-05-22 15:20:37,053][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 15:20:37,053][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 15:20:37,053][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 15:20:37,053][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 15:20:37,053][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 15:20:37,053][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 15:20:37,054][hannah.modules.vision.base][INFO] - Setting up model resnet18
[2024-05-22 15:20:37,220][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:803: UserWarning: Overwriting focalnet_tiny_srf in registry with hannah.models._vendor.focalnet.focalnet_tiny_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:20:37,220][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:824: UserWarning: Overwriting focalnet_small_srf in registry with hannah.models._vendor.focalnet.focalnet_small_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:20:37,220][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:843: UserWarning: Overwriting focalnet_base_srf in registry with hannah.models._vendor.focalnet.focalnet_base_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:20:37,221][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:862: UserWarning: Overwriting focalnet_tiny_lrf in registry with hannah.models._vendor.focalnet.focalnet_tiny_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:20:37,221][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:885: UserWarning: Overwriting focalnet_small_lrf in registry with hannah.models._vendor.focalnet.focalnet_small_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:20:37,221][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:906: UserWarning: Overwriting focalnet_base_lrf in registry with hannah.models._vendor.focalnet.focalnet_base_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:20:37,221][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1010: UserWarning: Overwriting focalnet_large_fl3 in registry with hannah.models._vendor.focalnet.focalnet_large_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:20:37,221][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1031: UserWarning: Overwriting focalnet_large_fl4 in registry with hannah.models._vendor.focalnet.focalnet_large_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:20:37,221][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1052: UserWarning: Overwriting focalnet_xlarge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:20:37,222][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1073: UserWarning: Overwriting focalnet_xlarge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:20:37,222][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1094: UserWarning: Overwriting focalnet_huge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:20:37,222][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1115: UserWarning: Overwriting focalnet_huge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:20:37,348][hannah.models.timm][INFO] - Using default logger for automatic stem creation
[2024-05-22 15:20:37,348][hannah.models.timm][INFO] - Small input size detected trying to adopt small input size
[2024-05-22 15:20:37,364][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '

[2024-05-22 15:20:37,811][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)
[2024-05-22 15:20:37,815][hannah.modules.vision.base][INFO] - Running dummy forward to initialize lazy modules
[2024-05-22 15:20:37,829][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:20:38,242][pytorch_lightning.utilities.rank_zero][INFO] - Loading `train_dataloader` to estimate number of stepping batches.
[2024-05-22 15:20:38,665][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

[2024-05-22 15:20:38,905][pytorch_lightning.callbacks.model_summary][INFO] - 
  | Name           | Type                           | Params | In sizes       | Out sizes                          
-------------------------------------------------------------------------------------------------------------------------
0 | val_metrics    | MetricCollection               | 0      | ?              | ?                                  
1 | test_metrics   | MetricCollection               | 0      | ?              | ?                                  
2 | train_metrics  | MetricCollection               | 0      | ?              | ?                                  
3 | model          | TimmModel                      | 11.2 M | [1, 3, 32, 32] | [[1, 512, 4, 4], [0], [0], [1, 10]]
4 | test_confusion | MulticlassConfusionMatrix      | 0      | ?              | ?                                  
5 | test_roc       | MulticlassROC                  | 0      | ?              | ?                                  
6 | test_pr_curve  | MulticlassPrecisionRecallCurve | 0      | ?              | ?                                  
7 | metrics        | ModuleDict                     | 0      | ?              | ?                                  
-------------------------------------------------------------------------------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.696    Total estimated model params size (MB)
[2024-05-22 15:20:39,052][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:20:39,052][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:20:39,061][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:20:40,957][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 15:20:40,958][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 15:20:40,958][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 15:20:40,958][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 15:20:40,958][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 15:20:47,202][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 0, global step 21: 'val_error' reached 0.74805 (best 0.74805), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=21.ckpt' as top 1
[2024-05-22 15:20:54,470][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 1, global step 42: 'val_error' reached 0.66211 (best 0.66211), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=1-step=42.ckpt' as top 1
[2024-05-22 15:21:01,681][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 2, global step 63: 'val_error' reached 0.62842 (best 0.62842), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=2-step=63.ckpt' as top 1
[2024-05-22 15:21:08,759][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 3, global step 84: 'val_error' reached 0.57715 (best 0.57715), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=3-step=84.ckpt' as top 1
[2024-05-22 15:21:15,770][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 4, global step 105: 'val_error' reached 0.53149 (best 0.53149), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=4-step=105.ckpt' as top 1
[2024-05-22 15:21:22,765][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 5, global step 126: 'val_error' reached 0.52051 (best 0.52051), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=5-step=126.ckpt' as top 1
[2024-05-22 15:21:29,748][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 6, global step 147: 'val_error' reached 0.44751 (best 0.44751), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=6-step=147.ckpt' as top 1
[2024-05-22 15:21:36,758][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 7, global step 168: 'val_error' reached 0.41943 (best 0.41943), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=7-step=168.ckpt' as top 1
[2024-05-22 15:21:43,803][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 8, global step 189: 'val_error' reached 0.37207 (best 0.37207), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=8-step=189.ckpt' as top 1
[2024-05-22 15:21:50,884][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 9, global step 210: 'val_error' reached 0.35840 (best 0.35840), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=210.ckpt' as top 1
[2024-05-22 15:21:51,204][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer.fit` stopped: `max_epochs=10` reached.
[2024-05-22 15:21:51,429][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:21:51,429][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 15:21:51,431][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=210.ckpt
[2024-05-22 15:21:51,478][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:21:51,955][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:21:51,956][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:21:51,959][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:21:52,177][pytorch_lightning.utilities.rank_zero][INFO] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=210.ckpt
[2024-05-22 15:21:53,435][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:21:53,436][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 15:21:53,437][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=210.ckpt
[2024-05-22 15:21:53,486][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:21:54,019][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:21:54,019][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:21:54,021][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:21:54,249][pytorch_lightning.utilities.rank_zero][INFO] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=210.ckpt
[2024-05-22 15:21:55,750][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 15:21:55,750][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 15:21:55,750][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 15:21:55,750][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 15:21:55,750][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 15:21:55,752][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:21:55,752][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:21:56,302][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:21:56,449][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:21:56,753][hannah.train][INFO] - Averaged Result Metrics:
| Metric               |     Mean |   Std |   Count |
|----------------------|----------|-------|---------|
| test_classifier_loss | 0.980917 |     0 |       1 |
| test_accuracy        | 0.646851 |     0 |       1 |
| test_error           | 0.353149 |     0 |       1 |
| test_f1              | 0.643031 |     0 |       1 |
| test_precision       | 0.641631 |     0 |       1 |
| test_recall          | 0.647989 |     0 |       1 |
| test_loss            | 0.980917 |     0 |       1 |
[2024-05-22 15:21:56,764][hannah.train][INFO] - Averaged Result Metrics:
| Metric              |     Mean |   Std |   Count |
|---------------------|----------|-------|---------|
| val_classifier_loss | 0.986314 |     0 |       1 |
| val_accuracy        | 0.641602 |     0 |       1 |
| val_error           | 0.358398 |     0 |       1 |
| val_f1              | 0.635178 |     0 |       1 |
| val_precision       | 0.633903 |     0 |       1 |
| val_recall          | 0.64105  |     0 |       1 |
| val_loss            | 0.986314 |     0 |       1 |
[2024-05-22 15:22:21,004][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 15:22:21,105][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 15:22:21,106][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 15:22:21,109][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 15:22:21,109][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 15:22:21,109][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 15:22:21,109][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 15:22:21,109][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 15:22:21,109][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 15:22:21,110][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 15:22:21,111][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 15:22:21,111][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32 trainer.max_epochs=10
[2024-05-22 15:22:21,111][hannah.utils.utils][INFO] -   
[2024-05-22 15:22:21,112][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:22:21,146][root][INFO] - Configuration: 
[2024-05-22 15:22:21,150][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
  sensor:
    resolution:
    - 32
    - 32
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 10
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 15:22:21,150][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 15:22:21,891][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 15:22:21,891][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 15:22:21,946][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 15:22:21,970][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 15:22:21,977][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 15:22:21,977][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 15:22:21,977][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 15:22:21,977][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 15:22:21,977][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 15:22:21,977][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:22:21,977][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:22:21,977][root][INFO] - Starting training
[2024-05-22 15:22:23,417][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 15:22:23,417][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 15:22:23,417][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 15:22:23,417][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 15:22:23,417][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 15:22:23,417][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 15:22:23,418][hannah.modules.vision.base][INFO] - Setting up model resnet18
[2024-05-22 15:22:23,582][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:803: UserWarning: Overwriting focalnet_tiny_srf in registry with hannah.models._vendor.focalnet.focalnet_tiny_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:22:23,582][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:824: UserWarning: Overwriting focalnet_small_srf in registry with hannah.models._vendor.focalnet.focalnet_small_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:22:23,582][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:843: UserWarning: Overwriting focalnet_base_srf in registry with hannah.models._vendor.focalnet.focalnet_base_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:22:23,582][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:862: UserWarning: Overwriting focalnet_tiny_lrf in registry with hannah.models._vendor.focalnet.focalnet_tiny_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:22:23,582][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:885: UserWarning: Overwriting focalnet_small_lrf in registry with hannah.models._vendor.focalnet.focalnet_small_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:22:23,583][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:906: UserWarning: Overwriting focalnet_base_lrf in registry with hannah.models._vendor.focalnet.focalnet_base_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:22:23,583][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1010: UserWarning: Overwriting focalnet_large_fl3 in registry with hannah.models._vendor.focalnet.focalnet_large_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:22:23,583][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1031: UserWarning: Overwriting focalnet_large_fl4 in registry with hannah.models._vendor.focalnet.focalnet_large_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:22:23,583][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1052: UserWarning: Overwriting focalnet_xlarge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:22:23,583][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1073: UserWarning: Overwriting focalnet_xlarge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:22:23,583][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1094: UserWarning: Overwriting focalnet_huge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:22:23,583][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1115: UserWarning: Overwriting focalnet_huge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:22:23,715][hannah.models.timm][INFO] - Using default logger for automatic stem creation
[2024-05-22 15:22:23,715][hannah.models.timm][INFO] - Small input size detected trying to adopt small input size
[2024-05-22 15:22:23,732][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '

[2024-05-22 15:22:24,179][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)
[2024-05-22 15:22:24,183][hannah.modules.vision.base][INFO] - Running dummy forward to initialize lazy modules
[2024-05-22 15:22:24,198][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:22:24,572][pytorch_lightning.utilities.rank_zero][INFO] - Loading `train_dataloader` to estimate number of stepping batches.
[2024-05-22 15:22:25,034][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

[2024-05-22 15:22:25,431][pytorch_lightning.callbacks.model_summary][INFO] - 
  | Name           | Type                           | Params | In sizes       | Out sizes                          
-------------------------------------------------------------------------------------------------------------------------
0 | val_metrics    | MetricCollection               | 0      | ?              | ?                                  
1 | test_metrics   | MetricCollection               | 0      | ?              | ?                                  
2 | train_metrics  | MetricCollection               | 0      | ?              | ?                                  
3 | model          | TimmModel                      | 11.2 M | [1, 3, 32, 32] | [[1, 512, 4, 4], [0], [0], [1, 10]]
4 | test_confusion | MulticlassConfusionMatrix      | 0      | ?              | ?                                  
5 | test_roc       | MulticlassROC                  | 0      | ?              | ?                                  
6 | test_pr_curve  | MulticlassPrecisionRecallCurve | 0      | ?              | ?                                  
7 | metrics        | ModuleDict                     | 0      | ?              | ?                                  
-------------------------------------------------------------------------------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.696    Total estimated model params size (MB)
[2024-05-22 15:22:25,698][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:22:25,698][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:22:25,705][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:22:27,373][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 15:22:27,374][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 15:22:27,374][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 15:22:27,374][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 15:22:27,374][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 15:22:33,637][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 0, global step 21: 'val_error' reached 0.74561 (best 0.74561), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=21.ckpt' as top 1
[2024-05-22 15:22:40,497][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 1, global step 42: 'val_error' reached 0.66138 (best 0.66138), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=1-step=42.ckpt' as top 1
[2024-05-22 15:22:47,362][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 2, global step 63: 'val_error' reached 0.64429 (best 0.64429), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=2-step=63.ckpt' as top 1
[2024-05-22 15:22:51,498][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...

[2024-05-22 15:22:51,507][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:22:51,507][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 15:22:51,509][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=2-step=63.ckpt
[2024-05-22 15:22:51,768][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:22:51,878][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:22:51,879][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:22:51,880][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:22:51,983][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:22:51,984][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 15:22:51,985][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=2-step=63.ckpt
[2024-05-22 15:22:52,022][hannah.train][INFO] - Averaged Result Metrics:
| Metric              |     Mean |   Std |   Count |
|---------------------|----------|-------|---------|
| val_classifier_loss | 1.86025  |     0 |       1 |
| val_accuracy        | 0.355713 |     0 |       1 |
| val_error           | 0.644287 |     0 |       1 |
| val_f1              | 0.313752 |     0 |       1 |
| val_precision       | 0.399509 |     0 |       1 |
| val_recall          | 0.357381 |     0 |       1 |
| val_loss            | 1.86025  |     0 |       1 |
[2024-05-22 15:23:06,392][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 15:23:06,497][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 15:23:06,497][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 15:23:06,500][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 15:23:06,500][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 15:23:06,500][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 15:23:06,500][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 15:23:06,500][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 15:23:06,500][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 15:23:06,501][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 15:23:06,502][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 15:23:06,502][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32 trainer.max_epochs=10 scheduler.max_lr=10
[2024-05-22 15:23:06,502][hannah.utils.utils][INFO] -   
[2024-05-22 15:23:06,503][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:23:06,537][root][INFO] - Configuration: 
[2024-05-22 15:23:06,540][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
  sensor:
    resolution:
    - 32
    - 32
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: 10.0
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 10
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 15:23:06,540][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 15:23:07,332][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 15:23:07,333][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 15:23:07,405][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 15:23:07,429][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 15:23:07,436][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 15:23:07,436][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 15:23:07,436][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 15:23:07,436][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 15:23:07,436][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 15:23:07,436][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:23:07,436][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:23:07,436][root][INFO] - Starting training
[2024-05-22 15:23:08,867][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 15:23:08,867][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 15:23:08,867][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 15:23:08,867][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 15:23:08,868][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 15:23:08,868][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 15:23:08,868][hannah.modules.vision.base][INFO] - Setting up model resnet18
[2024-05-22 15:23:09,034][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:803: UserWarning: Overwriting focalnet_tiny_srf in registry with hannah.models._vendor.focalnet.focalnet_tiny_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:23:09,034][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:824: UserWarning: Overwriting focalnet_small_srf in registry with hannah.models._vendor.focalnet.focalnet_small_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:23:09,034][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:843: UserWarning: Overwriting focalnet_base_srf in registry with hannah.models._vendor.focalnet.focalnet_base_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:23:09,034][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:862: UserWarning: Overwriting focalnet_tiny_lrf in registry with hannah.models._vendor.focalnet.focalnet_tiny_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:23:09,034][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:885: UserWarning: Overwriting focalnet_small_lrf in registry with hannah.models._vendor.focalnet.focalnet_small_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:23:09,035][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:906: UserWarning: Overwriting focalnet_base_lrf in registry with hannah.models._vendor.focalnet.focalnet_base_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:23:09,035][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1010: UserWarning: Overwriting focalnet_large_fl3 in registry with hannah.models._vendor.focalnet.focalnet_large_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:23:09,035][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1031: UserWarning: Overwriting focalnet_large_fl4 in registry with hannah.models._vendor.focalnet.focalnet_large_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:23:09,035][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1052: UserWarning: Overwriting focalnet_xlarge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:23:09,035][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1073: UserWarning: Overwriting focalnet_xlarge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:23:09,035][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1094: UserWarning: Overwriting focalnet_huge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:23:09,035][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1115: UserWarning: Overwriting focalnet_huge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:23:09,164][hannah.models.timm][INFO] - Using default logger for automatic stem creation
[2024-05-22 15:23:09,164][hannah.models.timm][INFO] - Small input size detected trying to adopt small input size
[2024-05-22 15:23:09,180][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '

[2024-05-22 15:23:09,638][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)
[2024-05-22 15:23:09,642][hannah.modules.vision.base][INFO] - Running dummy forward to initialize lazy modules
[2024-05-22 15:23:09,657][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:23:10,067][pytorch_lightning.utilities.rank_zero][INFO] - Loading `train_dataloader` to estimate number of stepping batches.
[2024-05-22 15:23:10,534][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

[2024-05-22 15:23:10,950][pytorch_lightning.callbacks.model_summary][INFO] - 
  | Name           | Type                           | Params | In sizes       | Out sizes                          
-------------------------------------------------------------------------------------------------------------------------
0 | val_metrics    | MetricCollection               | 0      | ?              | ?                                  
1 | test_metrics   | MetricCollection               | 0      | ?              | ?                                  
2 | train_metrics  | MetricCollection               | 0      | ?              | ?                                  
3 | model          | TimmModel                      | 11.2 M | [1, 3, 32, 32] | [[1, 512, 4, 4], [0], [0], [1, 10]]
4 | test_confusion | MulticlassConfusionMatrix      | 0      | ?              | ?                                  
5 | test_roc       | MulticlassROC                  | 0      | ?              | ?                                  
6 | test_pr_curve  | MulticlassPrecisionRecallCurve | 0      | ?              | ?                                  
7 | metrics        | ModuleDict                     | 0      | ?              | ?                                  
-------------------------------------------------------------------------------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.696    Total estimated model params size (MB)
[2024-05-22 15:23:11,215][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:23:11,215][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:23:11,240][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:23:12,875][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 15:23:12,875][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 15:23:12,875][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 15:23:12,875][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 15:23:12,875][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 15:23:19,237][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 0, global step 21: 'val_error' reached 0.89355 (best 0.89355), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=21.ckpt' as top 1
[2024-05-22 15:23:26,137][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 1, global step 42: 'val_error' reached 0.87939 (best 0.87939), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=1-step=42.ckpt' as top 1
[2024-05-22 15:23:32,884][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 2, global step 63: 'val_error' was not in top 1
[2024-05-22 15:23:39,376][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 3, global step 84: 'val_error' was not in top 1
[2024-05-22 15:23:46,011][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 4, global step 105: 'val_error' was not in top 1
[2024-05-22 15:23:51,076][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...

[2024-05-22 15:23:51,085][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:23:51,085][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 15:23:51,087][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=1-step=42.ckpt
[2024-05-22 15:23:51,319][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:23:51,431][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:23:51,432][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:23:51,433][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:23:51,523][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:23:51,524][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 15:23:51,526][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=1-step=42.ckpt
[2024-05-22 15:23:51,769][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:23:52,036][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/pandas/core/dtypes/astype.py:170: RuntimeWarning: invalid value encountered in cast
  return arr.astype(dtype, copy=True)

[2024-05-22 15:23:52,044][hannah.train][INFO] - Averaged Result Metrics:
| Metric              |      Mean |   Std |   Count |
|---------------------|-----------|-------|---------|
| val_classifier_loss | 0         |     0 |       0 |
| val_accuracy        | 0.102539  |     0 |       1 |
| val_error           | 0.897461  |     0 |       1 |
| val_f1              | 0.0186005 |     0 |       1 |
| val_precision       | 0.0102539 |     0 |       1 |
| val_recall          | 0.1       |     0 |       1 |
| val_loss            | 0         |     0 |       0 |
[2024-05-22 15:23:58,921][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 15:23:59,025][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 15:23:59,026][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 15:23:59,028][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 15:23:59,028][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 15:23:59,028][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 15:23:59,029][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 15:23:59,029][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 15:23:59,029][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 15:23:59,029][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 15:23:59,030][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 15:23:59,030][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32 trainer.max_epochs=10 scheduler.max_lr=3
[2024-05-22 15:23:59,031][hannah.utils.utils][INFO] -   
[2024-05-22 15:23:59,032][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:23:59,065][root][INFO] - Configuration: 
[2024-05-22 15:23:59,069][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
  sensor:
    resolution:
    - 32
    - 32
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: 3.0
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 10
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 15:23:59,069][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 15:23:59,806][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 15:23:59,807][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 15:23:59,862][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 15:23:59,886][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 15:23:59,893][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 15:23:59,893][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 15:23:59,893][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 15:23:59,893][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 15:23:59,893][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 15:23:59,893][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:23:59,893][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:23:59,893][root][INFO] - Starting training
[2024-05-22 15:24:01,337][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 15:24:01,338][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 15:24:01,338][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 15:24:01,338][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 15:24:01,338][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 15:24:01,338][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 15:24:01,339][hannah.modules.vision.base][INFO] - Setting up model resnet18
[2024-05-22 15:24:01,500][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:803: UserWarning: Overwriting focalnet_tiny_srf in registry with hannah.models._vendor.focalnet.focalnet_tiny_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:24:01,501][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:824: UserWarning: Overwriting focalnet_small_srf in registry with hannah.models._vendor.focalnet.focalnet_small_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:24:01,501][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:843: UserWarning: Overwriting focalnet_base_srf in registry with hannah.models._vendor.focalnet.focalnet_base_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:24:01,501][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:862: UserWarning: Overwriting focalnet_tiny_lrf in registry with hannah.models._vendor.focalnet.focalnet_tiny_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:24:01,501][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:885: UserWarning: Overwriting focalnet_small_lrf in registry with hannah.models._vendor.focalnet.focalnet_small_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:24:01,501][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:906: UserWarning: Overwriting focalnet_base_lrf in registry with hannah.models._vendor.focalnet.focalnet_base_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:24:01,502][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1010: UserWarning: Overwriting focalnet_large_fl3 in registry with hannah.models._vendor.focalnet.focalnet_large_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:24:01,502][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1031: UserWarning: Overwriting focalnet_large_fl4 in registry with hannah.models._vendor.focalnet.focalnet_large_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:24:01,502][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1052: UserWarning: Overwriting focalnet_xlarge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:24:01,502][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1073: UserWarning: Overwriting focalnet_xlarge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:24:01,502][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1094: UserWarning: Overwriting focalnet_huge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:24:01,502][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1115: UserWarning: Overwriting focalnet_huge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:24:01,638][hannah.models.timm][INFO] - Using default logger for automatic stem creation
[2024-05-22 15:24:01,638][hannah.models.timm][INFO] - Small input size detected trying to adopt small input size
[2024-05-22 15:24:01,654][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '

[2024-05-22 15:24:02,108][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)
[2024-05-22 15:24:02,112][hannah.modules.vision.base][INFO] - Running dummy forward to initialize lazy modules
[2024-05-22 15:24:02,123][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:24:02,518][pytorch_lightning.utilities.rank_zero][INFO] - Loading `train_dataloader` to estimate number of stepping batches.
[2024-05-22 15:24:02,903][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

[2024-05-22 15:24:03,325][pytorch_lightning.callbacks.model_summary][INFO] - 
  | Name           | Type                           | Params | In sizes       | Out sizes                          
-------------------------------------------------------------------------------------------------------------------------
0 | val_metrics    | MetricCollection               | 0      | ?              | ?                                  
1 | test_metrics   | MetricCollection               | 0      | ?              | ?                                  
2 | train_metrics  | MetricCollection               | 0      | ?              | ?                                  
3 | model          | TimmModel                      | 11.2 M | [1, 3, 32, 32] | [[1, 512, 4, 4], [0], [0], [1, 10]]
4 | test_confusion | MulticlassConfusionMatrix      | 0      | ?              | ?                                  
5 | test_roc       | MulticlassROC                  | 0      | ?              | ?                                  
6 | test_pr_curve  | MulticlassPrecisionRecallCurve | 0      | ?              | ?                                  
7 | metrics        | ModuleDict                     | 0      | ?              | ?                                  
-------------------------------------------------------------------------------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.696    Total estimated model params size (MB)
[2024-05-22 15:24:03,591][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:24:03,591][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:24:03,613][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:24:05,197][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 15:24:05,198][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 15:24:05,198][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 15:24:05,198][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 15:24:05,198][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 15:24:11,445][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 0, global step 21: 'val_error' reached 0.89844 (best 0.89844), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=21.ckpt' as top 1
[2024-05-22 15:24:18,455][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 1, global step 42: 'val_error' reached 0.85645 (best 0.85645), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=1-step=42.ckpt' as top 1
[2024-05-22 15:24:25,267][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 2, global step 63: 'val_error' reached 0.82837 (best 0.82837), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=2-step=63.ckpt' as top 1
[2024-05-22 15:24:31,972][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 3, global step 84: 'val_error' reached 0.78516 (best 0.78516), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=3-step=84.ckpt' as top 1
[2024-05-22 15:24:38,753][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 4, global step 105: 'val_error' reached 0.70996 (best 0.70996), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=4-step=105.ckpt' as top 1
[2024-05-22 15:24:45,563][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 5, global step 126: 'val_error' reached 0.63623 (best 0.63623), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=5-step=126.ckpt' as top 1
[2024-05-22 15:24:52,328][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 6, global step 147: 'val_error' was not in top 1
[2024-05-22 15:24:58,870][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 7, global step 168: 'val_error' reached 0.60547 (best 0.60547), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=7-step=168.ckpt' as top 1
[2024-05-22 15:25:05,646][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 8, global step 189: 'val_error' reached 0.36230 (best 0.36230), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=8-step=189.ckpt' as top 1
[2024-05-22 15:25:12,497][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 9, global step 210: 'val_error' reached 0.27368 (best 0.27368), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=210.ckpt' as top 1
[2024-05-22 15:25:12,834][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer.fit` stopped: `max_epochs=10` reached.
[2024-05-22 15:25:13,099][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:25:13,100][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 15:25:13,101][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=210.ckpt
[2024-05-22 15:25:13,150][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:25:13,656][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:25:13,657][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:25:13,658][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:25:13,877][pytorch_lightning.utilities.rank_zero][INFO] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=210.ckpt
[2024-05-22 15:25:15,171][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:25:15,172][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 15:25:15,174][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=210.ckpt
[2024-05-22 15:25:15,216][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:25:15,728][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:25:15,729][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:25:15,730][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:25:15,951][pytorch_lightning.utilities.rank_zero][INFO] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=210.ckpt
[2024-05-22 15:25:17,453][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 15:25:17,454][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 15:25:17,454][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 15:25:17,454][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 15:25:17,454][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 15:25:17,456][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:25:17,456][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:25:18,023][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:25:18,170][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:25:18,472][hannah.train][INFO] - Averaged Result Metrics:
| Metric               |     Mean |   Std |   Count |
|----------------------|----------|-------|---------|
| test_classifier_loss | 0.787075 |     0 |       1 |
| test_accuracy        | 0.719849 |     0 |       1 |
| test_error           | 0.280151 |     0 |       1 |
| test_f1              | 0.71908  |     0 |       1 |
| test_precision       | 0.721803 |     0 |       1 |
| test_recall          | 0.720763 |     0 |       1 |
| test_loss            | 0.787075 |     0 |       1 |
[2024-05-22 15:25:18,483][hannah.train][INFO] - Averaged Result Metrics:
| Metric              |     Mean |   Std |   Count |
|---------------------|----------|-------|---------|
| val_classifier_loss | 0.764573 |     0 |       1 |
| val_accuracy        | 0.726318 |     0 |       1 |
| val_error           | 0.273682 |     0 |       1 |
| val_f1              | 0.722556 |     0 |       1 |
| val_precision       | 0.724788 |     0 |       1 |
| val_recall          | 0.724279 |     0 |       1 |
| val_loss            | 0.764573 |     0 |       1 |
[2024-05-22 15:25:33,510][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 15:25:33,620][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 15:25:33,620][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 15:25:33,623][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 15:25:33,623][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 15:25:33,623][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 15:25:33,624][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 15:25:33,624][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 15:25:33,624][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 15:25:33,624][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 15:25:33,625][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 15:25:33,625][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32 trainer.max_epochs=10
[2024-05-22 15:25:33,625][hannah.utils.utils][INFO] -   
[2024-05-22 15:25:33,626][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:25:33,661][root][INFO] - Configuration: 
[2024-05-22 15:25:33,665][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
  sensor:
    resolution:
    - 32
    - 32
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 10
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 15:25:33,665][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 15:25:34,414][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 15:25:34,414][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 15:25:34,482][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 15:25:34,506][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 15:25:34,513][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 15:25:34,513][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 15:25:34,513][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 15:25:34,513][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 15:25:34,514][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 15:25:34,514][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:25:34,514][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:25:34,514][root][INFO] - Starting training
[2024-05-22 15:25:35,947][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 15:25:35,948][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 15:25:35,948][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 15:25:35,948][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 15:25:35,948][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 15:25:35,948][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 15:25:35,949][hannah.modules.vision.base][INFO] - Setting up model resnet18
[2024-05-22 15:25:36,111][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:803: UserWarning: Overwriting focalnet_tiny_srf in registry with hannah.models._vendor.focalnet.focalnet_tiny_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:25:36,111][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:824: UserWarning: Overwriting focalnet_small_srf in registry with hannah.models._vendor.focalnet.focalnet_small_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:25:36,111][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:843: UserWarning: Overwriting focalnet_base_srf in registry with hannah.models._vendor.focalnet.focalnet_base_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:25:36,111][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:862: UserWarning: Overwriting focalnet_tiny_lrf in registry with hannah.models._vendor.focalnet.focalnet_tiny_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:25:36,111][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:885: UserWarning: Overwriting focalnet_small_lrf in registry with hannah.models._vendor.focalnet.focalnet_small_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:25:36,112][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:906: UserWarning: Overwriting focalnet_base_lrf in registry with hannah.models._vendor.focalnet.focalnet_base_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:25:36,112][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1010: UserWarning: Overwriting focalnet_large_fl3 in registry with hannah.models._vendor.focalnet.focalnet_large_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:25:36,112][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1031: UserWarning: Overwriting focalnet_large_fl4 in registry with hannah.models._vendor.focalnet.focalnet_large_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:25:36,112][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1052: UserWarning: Overwriting focalnet_xlarge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:25:36,112][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1073: UserWarning: Overwriting focalnet_xlarge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:25:36,112][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1094: UserWarning: Overwriting focalnet_huge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:25:36,112][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1115: UserWarning: Overwriting focalnet_huge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:25:36,256][hannah.models.timm][INFO] - Using default logger for automatic stem creation
[2024-05-22 15:25:36,256][hannah.models.timm][INFO] - Small input size detected trying to adopt small input size
[2024-05-22 15:25:36,279][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '

[2024-05-22 15:25:36,709][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)
[2024-05-22 15:25:36,713][hannah.modules.vision.base][INFO] - Running dummy forward to initialize lazy modules
[2024-05-22 15:25:36,727][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:25:37,075][pytorch_lightning.utilities.rank_zero][INFO] - Loading `train_dataloader` to estimate number of stepping batches.
[2024-05-22 15:25:37,536][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

[2024-05-22 15:25:37,939][pytorch_lightning.callbacks.model_summary][INFO] - 
  | Name           | Type                           | Params | In sizes       | Out sizes                          
-------------------------------------------------------------------------------------------------------------------------
0 | val_metrics    | MetricCollection               | 0      | ?              | ?                                  
1 | test_metrics   | MetricCollection               | 0      | ?              | ?                                  
2 | train_metrics  | MetricCollection               | 0      | ?              | ?                                  
3 | model          | TimmModel                      | 11.2 M | [1, 3, 32, 32] | [[1, 512, 4, 4], [0], [0], [1, 10]]
4 | test_confusion | MulticlassConfusionMatrix      | 0      | ?              | ?                                  
5 | test_roc       | MulticlassROC                  | 0      | ?              | ?                                  
6 | test_pr_curve  | MulticlassPrecisionRecallCurve | 0      | ?              | ?                                  
7 | metrics        | ModuleDict                     | 0      | ?              | ?                                  
-------------------------------------------------------------------------------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.696    Total estimated model params size (MB)
[2024-05-22 15:25:38,184][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:25:38,184][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:25:38,207][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:25:39,846][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 15:25:39,847][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 15:25:39,847][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 15:25:39,847][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 15:25:39,847][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 15:25:46,094][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 0, global step 21: 'val_error' reached 0.74561 (best 0.74561), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=21.ckpt' as top 1
[2024-05-22 15:25:53,068][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 1, global step 42: 'val_error' reached 0.66138 (best 0.66138), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=1-step=42.ckpt' as top 1
[2024-05-22 15:25:59,741][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 2, global step 63: 'val_error' reached 0.64429 (best 0.64429), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=2-step=63.ckpt' as top 1
[2024-05-22 15:26:06,542][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 3, global step 84: 'val_error' reached 0.58228 (best 0.58228), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=3-step=84.ckpt' as top 1
[2024-05-22 15:26:13,284][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 4, global step 105: 'val_error' reached 0.50391 (best 0.50391), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=4-step=105.ckpt' as top 1
[2024-05-22 15:26:20,010][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 5, global step 126: 'val_error' was not in top 1
[2024-05-22 15:26:26,602][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 6, global step 147: 'val_error' reached 0.44238 (best 0.44238), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=6-step=147.ckpt' as top 1
[2024-05-22 15:26:33,389][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 7, global step 168: 'val_error' reached 0.38501 (best 0.38501), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=7-step=168.ckpt' as top 1
[2024-05-22 15:26:40,142][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 8, global step 189: 'val_error' reached 0.34106 (best 0.34106), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=8-step=189.ckpt' as top 1
[2024-05-22 15:26:46,933][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 9, global step 210: 'val_error' reached 0.31836 (best 0.31836), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=210.ckpt' as top 1
[2024-05-22 15:26:47,286][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer.fit` stopped: `max_epochs=10` reached.
[2024-05-22 15:26:47,518][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:26:47,519][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 15:26:47,521][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=210.ckpt
[2024-05-22 15:26:47,571][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:26:48,043][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:26:48,044][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:26:48,046][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:26:48,264][pytorch_lightning.utilities.rank_zero][INFO] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=210.ckpt
[2024-05-22 15:26:49,653][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:26:49,654][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 15:26:49,655][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=210.ckpt
[2024-05-22 15:26:49,696][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:26:50,185][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:26:50,185][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:26:50,187][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:26:50,413][pytorch_lightning.utilities.rank_zero][INFO] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=210.ckpt
[2024-05-22 15:26:51,979][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 15:26:51,980][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 15:26:51,980][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 15:26:51,980][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 15:26:51,980][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 15:26:51,982][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:26:51,982][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:26:52,543][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:26:52,688][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:26:52,984][hannah.train][INFO] - Averaged Result Metrics:
| Metric               |     Mean |   Std |   Count |
|----------------------|----------|-------|---------|
| test_classifier_loss | 0.889264 |     0 |       1 |
| test_accuracy        | 0.674805 |     0 |       1 |
| test_error           | 0.325195 |     0 |       1 |
| test_f1              | 0.673928 |     0 |       1 |
| test_precision       | 0.673678 |     0 |       1 |
| test_recall          | 0.675866 |     0 |       1 |
| test_loss            | 0.889264 |     0 |       1 |
[2024-05-22 15:26:52,995][hannah.train][INFO] - Averaged Result Metrics:
| Metric              |     Mean |   Std |   Count |
|---------------------|----------|-------|---------|
| val_classifier_loss | 0.892605 |     0 |       1 |
| val_accuracy        | 0.681641 |     0 |       1 |
| val_error           | 0.318359 |     0 |       1 |
| val_f1              | 0.678616 |     0 |       1 |
| val_precision       | 0.678419 |     0 |       1 |
| val_recall          | 0.680669 |     0 |       1 |
| val_loss            | 0.892605 |     0 |       1 |
[2024-05-22 15:30:01,548][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 15:30:01,675][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 15:30:01,676][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 15:30:01,679][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 15:30:01,679][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 15:30:01,680][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 15:30:01,680][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 15:30:01,680][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 15:30:01,680][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 15:30:01,680][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 15:30:01,681][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 15:30:01,681][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32 trainer.max_epochs=10
[2024-05-22 15:30:01,682][hannah.utils.utils][INFO] -   
[2024-05-22 15:30:01,683][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:30:01,713][root][INFO] - Configuration: 
[2024-05-22 15:30:01,716][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 10
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 15:30:01,717][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 15:30:02,836][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 15:30:02,836][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 15:30:02,907][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 15:30:02,931][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 15:30:02,938][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 15:30:02,939][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 15:30:02,939][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 15:30:02,939][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 15:30:02,939][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 15:30:02,939][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:30:02,939][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:30:02,939][root][INFO] - Starting training
[2024-05-22 15:30:04,409][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:66: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 15:30:04,409][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 15:30:04,409][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 15:30:04,409][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 15:30:04,409][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 15:30:04,409][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 15:30:04,410][hannah.modules.vision.base][INFO] - Setting up model resnet18
[2024-05-22 15:30:04,573][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:803: UserWarning: Overwriting focalnet_tiny_srf in registry with hannah.models._vendor.focalnet.focalnet_tiny_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:30:04,573][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:824: UserWarning: Overwriting focalnet_small_srf in registry with hannah.models._vendor.focalnet.focalnet_small_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:30:04,573][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:843: UserWarning: Overwriting focalnet_base_srf in registry with hannah.models._vendor.focalnet.focalnet_base_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:30:04,573][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:862: UserWarning: Overwriting focalnet_tiny_lrf in registry with hannah.models._vendor.focalnet.focalnet_tiny_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:30:04,573][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:885: UserWarning: Overwriting focalnet_small_lrf in registry with hannah.models._vendor.focalnet.focalnet_small_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:30:04,573][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:906: UserWarning: Overwriting focalnet_base_lrf in registry with hannah.models._vendor.focalnet.focalnet_base_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:30:04,573][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1010: UserWarning: Overwriting focalnet_large_fl3 in registry with hannah.models._vendor.focalnet.focalnet_large_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:30:04,573][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1031: UserWarning: Overwriting focalnet_large_fl4 in registry with hannah.models._vendor.focalnet.focalnet_large_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:30:04,574][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1052: UserWarning: Overwriting focalnet_xlarge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:30:04,574][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1073: UserWarning: Overwriting focalnet_xlarge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:30:04,574][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1094: UserWarning: Overwriting focalnet_huge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:30:04,574][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1115: UserWarning: Overwriting focalnet_huge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:30:04,709][hannah.models.timm][INFO] - Using default logger for automatic stem creation
[2024-05-22 15:30:04,709][hannah.models.timm][INFO] - Small input size detected trying to adopt small input size
[2024-05-22 15:30:04,752][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '

[2024-05-22 15:30:05,219][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)
[2024-05-22 15:30:05,225][hannah.modules.vision.base][INFO] - Running dummy forward to initialize lazy modules
[2024-05-22 15:30:05,271][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:30:05,643][pytorch_lightning.utilities.rank_zero][INFO] - Loading `train_dataloader` to estimate number of stepping batches.
[2024-05-22 15:30:06,055][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

[2024-05-22 15:30:06,490][pytorch_lightning.callbacks.model_summary][INFO] - 
   | Name                 | Type                           | Params | In sizes       | Out sizes                          
--------------------------------------------------------------------------------------------------------------------------------
0  | val_metrics          | MetricCollection               | 0      | ?              | ?                                  
1  | test_metrics         | MetricCollection               | 0      | ?              | ?                                  
2  | train_metrics        | MetricCollection               | 0      | ?              | ?                                  
3  | model                | TimmModel                      | 11.2 M | [1, 3, 32, 32] | [[1, 512, 4, 4], [0], [0], [1, 10]]
4  | input_normalizer     | Normalize                      | 0      | ?              | ?                                  
5  | default_augmentation | Sequential                     | 0      | ?              | ?                                  
6  | augmentations        | ModuleDict                     | 0      | ?              | ?                                  
7  | test_confusion       | MulticlassConfusionMatrix      | 0      | ?              | ?                                  
8  | test_roc             | MulticlassROC                  | 0      | ?              | ?                                  
9  | test_pr_curve        | MulticlassPrecisionRecallCurve | 0      | ?              | ?                                  
10 | metrics              | ModuleDict                     | 0      | ?              | ?                                  
--------------------------------------------------------------------------------------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.696    Total estimated model params size (MB)
[2024-05-22 15:30:06,754][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:30:06,754][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:30:06,776][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:30:08,296][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 15:30:08,297][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 15:30:08,297][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 15:30:08,297][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 15:30:08,297][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 15:31:46,625][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 0, global step 21: 'val_error' reached 0.76074 (best 0.76074), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=21.ckpt' as top 1
[2024-05-22 15:33:25,114][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 1, global step 42: 'val_error' reached 0.69531 (best 0.69531), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=1-step=42.ckpt' as top 1
[2024-05-22 15:34:01,405][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 2, global step 63: 'val_error' reached 0.68091 (best 0.68091), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=2-step=63.ckpt' as top 1
[2024-05-22 15:34:18,350][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 3, global step 84: 'val_error' reached 0.63794 (best 0.63794), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=3-step=84.ckpt' as top 1
[2024-05-22 15:34:29,680][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 4, global step 105: 'val_error' reached 0.54102 (best 0.54102), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=4-step=105.ckpt' as top 1
[2024-05-22 15:34:41,210][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 5, global step 126: 'val_error' was not in top 1
[2024-05-22 15:34:52,377][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 6, global step 147: 'val_error' reached 0.49487 (best 0.49487), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=6-step=147.ckpt' as top 1
[2024-05-22 15:35:03,891][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 7, global step 168: 'val_error' reached 0.45264 (best 0.45264), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=7-step=168.ckpt' as top 1
[2024-05-22 15:35:15,145][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 8, global step 189: 'val_error' reached 0.42358 (best 0.42358), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=8-step=189.ckpt' as top 1
[2024-05-22 15:35:26,463][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 9, global step 210: 'val_error' reached 0.39600 (best 0.39600), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=210.ckpt' as top 1
[2024-05-22 15:35:26,781][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer.fit` stopped: `max_epochs=10` reached.
[2024-05-22 15:35:27,012][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:35:27,013][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 15:35:27,014][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=210.ckpt
[2024-05-22 15:35:27,062][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:35:27,181][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:35:27,181][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:35:27,183][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:35:27,401][pytorch_lightning.utilities.rank_zero][INFO] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=210.ckpt
[2024-05-22 15:35:28,496][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:35:28,497][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 15:35:28,498][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=210.ckpt
[2024-05-22 15:35:28,541][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:35:28,663][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:35:28,663][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:35:28,665][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:35:28,886][pytorch_lightning.utilities.rank_zero][INFO] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=210.ckpt
[2024-05-22 15:35:29,914][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 15:35:29,915][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 15:35:29,915][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 15:35:29,915][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 15:35:29,915][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 15:35:29,915][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:35:29,916][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:35:30,692][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:35:30,801][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:35:31,056][hannah.train][INFO] - Averaged Result Metrics:
| Metric               |     Mean |   Std |   Count |
|----------------------|----------|-------|---------|
| test_classifier_loss | 1.11319  |     0 |       1 |
| test_accuracy        | 0.604004 |     0 |       1 |
| test_error           | 0.395996 |     0 |       1 |
| test_f1              | 0.597301 |     0 |       1 |
| test_precision       | 0.594744 |     0 |       1 |
| test_recall          | 0.605067 |     0 |       1 |
| test_loss            | 1.11319  |     0 |       1 |
[2024-05-22 15:35:31,068][hannah.train][INFO] - Averaged Result Metrics:
| Metric              |     Mean |   Std |   Count |
|---------------------|----------|-------|---------|
| val_classifier_loss | 1.10556  |     0 |       1 |
| val_accuracy        | 0.604004 |     0 |       1 |
| val_error           | 0.395996 |     0 |       1 |
| val_f1              | 0.596197 |     0 |       1 |
| val_precision       | 0.595448 |     0 |       1 |
| val_recall          | 0.603168 |     0 |       1 |
| val_loss            | 1.10556  |     0 |       1 |
[2024-05-22 15:36:24,958][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 15:36:25,048][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 15:36:25,048][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 15:36:25,052][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 15:36:25,052][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 15:36:25,052][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 15:36:25,052][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 15:36:25,052][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 15:36:25,053][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 15:36:25,053][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 15:36:25,054][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 15:36:25,054][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32 module.batch_size=128 trainer.max_epochs=10
[2024-05-22 15:36:25,054][hannah.utils.utils][INFO] -   
[2024-05-22 15:36:25,055][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:36:25,085][root][INFO] - Configuration: 
[2024-05-22 15:36:25,089][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 128
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 10
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 15:36:25,089][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 15:36:25,893][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 15:36:25,893][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 15:36:25,960][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 15:36:25,984][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 15:36:25,991][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 15:36:25,991][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 15:36:25,991][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 15:36:25,991][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 15:36:25,991][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 15:36:25,991][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:36:25,991][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:36:25,991][root][INFO] - Starting training
[2024-05-22 15:36:27,364][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:66: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 15:36:27,364][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 15:36:27,364][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 15:36:27,364][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 15:36:27,364][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 15:36:27,364][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 15:36:27,365][hannah.modules.vision.base][INFO] - Setting up model resnet18
[2024-05-22 15:36:27,523][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:803: UserWarning: Overwriting focalnet_tiny_srf in registry with hannah.models._vendor.focalnet.focalnet_tiny_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:36:27,523][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:824: UserWarning: Overwriting focalnet_small_srf in registry with hannah.models._vendor.focalnet.focalnet_small_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:36:27,523][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:843: UserWarning: Overwriting focalnet_base_srf in registry with hannah.models._vendor.focalnet.focalnet_base_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:36:27,524][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:862: UserWarning: Overwriting focalnet_tiny_lrf in registry with hannah.models._vendor.focalnet.focalnet_tiny_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:36:27,524][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:885: UserWarning: Overwriting focalnet_small_lrf in registry with hannah.models._vendor.focalnet.focalnet_small_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:36:27,524][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:906: UserWarning: Overwriting focalnet_base_lrf in registry with hannah.models._vendor.focalnet.focalnet_base_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:36:27,524][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1010: UserWarning: Overwriting focalnet_large_fl3 in registry with hannah.models._vendor.focalnet.focalnet_large_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:36:27,524][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1031: UserWarning: Overwriting focalnet_large_fl4 in registry with hannah.models._vendor.focalnet.focalnet_large_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:36:27,524][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1052: UserWarning: Overwriting focalnet_xlarge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:36:27,524][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1073: UserWarning: Overwriting focalnet_xlarge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:36:27,524][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1094: UserWarning: Overwriting focalnet_huge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:36:27,524][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1115: UserWarning: Overwriting focalnet_huge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:36:27,663][hannah.models.timm][INFO] - Using default logger for automatic stem creation
[2024-05-22 15:36:27,663][hannah.models.timm][INFO] - Small input size detected trying to adopt small input size
[2024-05-22 15:36:27,680][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '

[2024-05-22 15:36:27,862][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)
[2024-05-22 15:36:27,869][hannah.modules.vision.base][INFO] - Running dummy forward to initialize lazy modules
[2024-05-22 15:36:27,883][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:36:27,897][pytorch_lightning.utilities.rank_zero][INFO] - Loading `train_dataloader` to estimate number of stepping batches.
[2024-05-22 15:36:28,583][pytorch_lightning.callbacks.model_summary][INFO] - 
   | Name                 | Type                           | Params | In sizes       | Out sizes                          
--------------------------------------------------------------------------------------------------------------------------------
0  | val_metrics          | MetricCollection               | 0      | ?              | ?                                  
1  | test_metrics         | MetricCollection               | 0      | ?              | ?                                  
2  | train_metrics        | MetricCollection               | 0      | ?              | ?                                  
3  | model                | TimmModel                      | 11.2 M | [1, 3, 32, 32] | [[1, 512, 4, 4], [0], [0], [1, 10]]
4  | input_normalizer     | Normalize                      | 0      | ?              | ?                                  
5  | default_augmentation | Sequential                     | 0      | ?              | ?                                  
6  | augmentations        | ModuleDict                     | 0      | ?              | ?                                  
7  | test_confusion       | MulticlassConfusionMatrix      | 0      | ?              | ?                                  
8  | test_roc             | MulticlassROC                  | 0      | ?              | ?                                  
9  | test_pr_curve        | MulticlassPrecisionRecallCurve | 0      | ?              | ?                                  
10 | metrics              | ModuleDict                     | 0      | ?              | ?                                  
--------------------------------------------------------------------------------------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.696    Total estimated model params size (MB)
[2024-05-22 15:36:28,733][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:36:28,733][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:36:28,737][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:36:29,844][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 15:36:29,844][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 15:36:29,844][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 15:36:29,844][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 15:36:29,844][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 15:36:48,042][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 0, global step 351: 'val_error' reached 0.62680 (best 0.62680), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=351.ckpt' as top 1
[2024-05-22 15:37:05,520][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 1, global step 702: 'val_error' reached 0.49179 (best 0.49179), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=1-step=702.ckpt' as top 1
[2024-05-22 15:37:23,591][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 2, global step 1053: 'val_error' reached 0.48558 (best 0.48558), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=2-step=1053.ckpt' as top 1
[2024-05-22 15:37:41,790][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 3, global step 1404: 'val_error' reached 0.32532 (best 0.32532), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=3-step=1404.ckpt' as top 1
[2024-05-22 15:37:59,890][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 4, global step 1755: 'val_error' was not in top 1
[2024-05-22 15:38:17,770][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 5, global step 2106: 'val_error' reached 0.25200 (best 0.25200), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=5-step=2106.ckpt' as top 1
[2024-05-22 15:38:35,789][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 6, global step 2457: 'val_error' was not in top 1
[2024-05-22 15:38:54,317][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 7, global step 2808: 'val_error' reached 0.19171 (best 0.19171), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=7-step=2808.ckpt' as top 1
[2024-05-22 15:39:11,963][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 8, global step 3159: 'val_error' reached 0.15485 (best 0.15485), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=8-step=3159.ckpt' as top 1
[2024-05-22 15:39:29,963][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 9, global step 3510: 'val_error' reached 0.12380 (best 0.12380), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=3510.ckpt' as top 1
[2024-05-22 15:39:30,279][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer.fit` stopped: `max_epochs=10` reached.
[2024-05-22 15:39:30,455][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:39:30,456][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 15:39:30,457][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=3510.ckpt
[2024-05-22 15:39:30,503][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:39:30,626][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:39:30,626][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:39:30,628][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:39:30,848][pytorch_lightning.utilities.rank_zero][INFO] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=3510.ckpt
[2024-05-22 15:39:32,024][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:39:32,025][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 15:39:32,027][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=3510.ckpt
[2024-05-22 15:39:32,066][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:39:32,188][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:39:32,189][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:39:32,191][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:39:32,417][pytorch_lightning.utilities.rank_zero][INFO] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=3510.ckpt
[2024-05-22 15:39:33,795][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 15:39:33,795][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 15:39:33,796][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 15:39:33,796][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 15:39:33,796][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 15:39:33,796][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:39:33,797][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:39:34,281][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:39:34,388][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:39:34,919][hannah.train][INFO] - Averaged Result Metrics:
| Metric               |     Mean |   Std |   Count |
|----------------------|----------|-------|---------|
| test_classifier_loss | 0.361935 |     0 |       1 |
| test_accuracy        | 0.874199 |     0 |       1 |
| test_error           | 0.125801 |     0 |       1 |
| test_f1              | 0.873778 |     0 |       1 |
| test_precision       | 0.873814 |     0 |       1 |
| test_recall          | 0.874166 |     0 |       1 |
| test_loss            | 0.361935 |     0 |       1 |
[2024-05-22 15:39:34,931][hannah.train][INFO] - Averaged Result Metrics:
| Metric              |     Mean |   Std |   Count |
|---------------------|----------|-------|---------|
| val_classifier_loss | 0.362503 |     0 |       1 |
| val_accuracy        | 0.876202 |     0 |       1 |
| val_error           | 0.123798 |     0 |       1 |
| val_f1              | 0.875088 |     0 |       1 |
| val_precision       | 0.875111 |     0 |       1 |
| val_recall          | 0.875193 |     0 |       1 |
| val_loss            | 0.362503 |     0 |       1 |
[2024-05-22 15:43:05,482][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 15:43:05,570][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 15:43:05,571][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 15:43:05,573][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 15:43:05,573][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 15:43:05,573][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 15:43:05,573][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 15:43:05,574][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 15:43:05,574][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 15:43:05,574][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 15:43:05,575][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 15:43:05,575][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32 module.batch_size=128 trainer.max_epochs=10
[2024-05-22 15:43:05,575][hannah.utils.utils][INFO] -   
[2024-05-22 15:43:05,576][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:43:05,606][root][INFO] - Configuration: 
[2024-05-22 15:43:05,609][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
  sensor:
    resolution:
    - 32
    - 32
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 128
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 10
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 15:43:05,609][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 15:43:06,347][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 15:43:06,347][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 15:43:06,414][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 15:43:06,438][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 15:43:06,445][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 15:43:06,445][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 15:43:06,445][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 15:43:06,445][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 15:43:06,445][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 15:43:06,445][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:43:06,445][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:43:06,445][root][INFO] - Starting training
[2024-05-22 15:43:07,818][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 15:43:07,818][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 15:43:07,818][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 15:43:07,818][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 15:43:07,818][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 15:43:07,818][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 15:43:07,819][hannah.modules.vision.base][INFO] - Setting up model resnet18
[2024-05-22 15:43:07,982][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:803: UserWarning: Overwriting focalnet_tiny_srf in registry with hannah.models._vendor.focalnet.focalnet_tiny_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:43:07,983][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:824: UserWarning: Overwriting focalnet_small_srf in registry with hannah.models._vendor.focalnet.focalnet_small_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:43:07,983][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:843: UserWarning: Overwriting focalnet_base_srf in registry with hannah.models._vendor.focalnet.focalnet_base_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:43:07,983][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:862: UserWarning: Overwriting focalnet_tiny_lrf in registry with hannah.models._vendor.focalnet.focalnet_tiny_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:43:07,983][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:885: UserWarning: Overwriting focalnet_small_lrf in registry with hannah.models._vendor.focalnet.focalnet_small_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:43:07,983][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:906: UserWarning: Overwriting focalnet_base_lrf in registry with hannah.models._vendor.focalnet.focalnet_base_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:43:07,983][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1010: UserWarning: Overwriting focalnet_large_fl3 in registry with hannah.models._vendor.focalnet.focalnet_large_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:43:07,983][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1031: UserWarning: Overwriting focalnet_large_fl4 in registry with hannah.models._vendor.focalnet.focalnet_large_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:43:07,983][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1052: UserWarning: Overwriting focalnet_xlarge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:43:07,983][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1073: UserWarning: Overwriting focalnet_xlarge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:43:07,983][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1094: UserWarning: Overwriting focalnet_huge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:43:07,983][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1115: UserWarning: Overwriting focalnet_huge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:43:08,120][hannah.models.timm][INFO] - Using default logger for automatic stem creation
[2024-05-22 15:43:08,121][hannah.models.timm][INFO] - Small input size detected trying to adopt small input size
[2024-05-22 15:43:08,137][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '

[2024-05-22 15:43:08,328][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)
[2024-05-22 15:43:08,332][hannah.modules.vision.base][INFO] - Running dummy forward to initialize lazy modules
[2024-05-22 15:43:08,344][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:43:08,359][pytorch_lightning.utilities.rank_zero][INFO] - Loading `train_dataloader` to estimate number of stepping batches.
[2024-05-22 15:43:09,023][pytorch_lightning.callbacks.model_summary][INFO] - 
  | Name           | Type                           | Params | In sizes       | Out sizes                          
-------------------------------------------------------------------------------------------------------------------------
0 | val_metrics    | MetricCollection               | 0      | ?              | ?                                  
1 | test_metrics   | MetricCollection               | 0      | ?              | ?                                  
2 | train_metrics  | MetricCollection               | 0      | ?              | ?                                  
3 | model          | TimmModel                      | 11.2 M | [1, 3, 32, 32] | [[1, 512, 4, 4], [0], [0], [1, 10]]
4 | test_confusion | MulticlassConfusionMatrix      | 0      | ?              | ?                                  
5 | test_roc       | MulticlassROC                  | 0      | ?              | ?                                  
6 | test_pr_curve  | MulticlassPrecisionRecallCurve | 0      | ?              | ?                                  
7 | metrics        | ModuleDict                     | 0      | ?              | ?                                  
-------------------------------------------------------------------------------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.696    Total estimated model params size (MB)
[2024-05-22 15:43:09,162][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:43:09,162][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:43:09,167][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:43:10,337][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 15:43:10,338][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 15:43:10,338][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 15:43:10,338][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 15:43:10,338][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 15:43:16,503][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 0, global step 351: 'val_error' reached 0.59235 (best 0.59235), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=351.ckpt' as top 1
[2024-05-22 15:43:22,707][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 1, global step 702: 'val_error' reached 0.39683 (best 0.39683), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=1-step=702.ckpt' as top 1
[2024-05-22 15:43:28,872][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 2, global step 1053: 'val_error' reached 0.33474 (best 0.33474), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=2-step=1053.ckpt' as top 1
[2024-05-22 15:43:35,052][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 3, global step 1404: 'val_error' reached 0.27925 (best 0.27925), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=3-step=1404.ckpt' as top 1
[2024-05-22 15:43:41,276][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 4, global step 1755: 'val_error' reached 0.27384 (best 0.27384), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=4-step=1755.ckpt' as top 1
[2024-05-22 15:43:47,472][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 5, global step 2106: 'val_error' reached 0.26482 (best 0.26482), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=5-step=2106.ckpt' as top 1
[2024-05-22 15:43:53,771][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 6, global step 2457: 'val_error' reached 0.20172 (best 0.20172), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=6-step=2457.ckpt' as top 1
[2024-05-22 15:44:00,063][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 7, global step 2808: 'val_error' reached 0.16346 (best 0.16346), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=7-step=2808.ckpt' as top 1
[2024-05-22 15:44:06,275][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 8, global step 3159: 'val_error' reached 0.12800 (best 0.12800), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=8-step=3159.ckpt' as top 1
[2024-05-22 15:44:12,548][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 9, global step 3510: 'val_error' reached 0.11398 (best 0.11398), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=3510.ckpt' as top 1
[2024-05-22 15:44:12,857][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer.fit` stopped: `max_epochs=10` reached.
[2024-05-22 15:44:13,057][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:44:13,060][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 15:44:13,062][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=3510.ckpt
[2024-05-22 15:44:13,106][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:44:13,218][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:44:13,218][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:44:13,220][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:44:13,432][pytorch_lightning.utilities.rank_zero][INFO] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=3510.ckpt
[2024-05-22 15:44:14,547][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:44:14,548][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 15:44:14,550][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=3510.ckpt
[2024-05-22 15:44:14,588][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:44:14,702][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:44:14,703][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:44:14,705][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:44:14,919][pytorch_lightning.utilities.rank_zero][INFO] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=3510.ckpt
[2024-05-22 15:44:16,271][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 15:44:16,272][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 15:44:16,272][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 15:44:16,272][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 15:44:16,272][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 15:44:16,273][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:44:16,273][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:44:16,809][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:44:16,917][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:44:17,144][hannah.train][INFO] - Averaged Result Metrics:
| Metric               |     Mean |   Std |   Count |
|----------------------|----------|-------|---------|
| test_classifier_loss | 0.324938 |     0 |       1 |
| test_accuracy        | 0.892127 |     0 |       1 |
| test_error           | 0.107873 |     0 |       1 |
| test_f1              | 0.891873 |     0 |       1 |
| test_precision       | 0.892138 |     0 |       1 |
| test_recall          | 0.892106 |     0 |       1 |
| test_loss            | 0.324938 |     0 |       1 |
[2024-05-22 15:44:17,156][hannah.train][INFO] - Averaged Result Metrics:
| Metric              |     Mean |   Std |   Count |
|---------------------|----------|-------|---------|
| val_classifier_loss | 0.332506 |     0 |       1 |
| val_accuracy        | 0.886018 |     0 |       1 |
| val_error           | 0.113982 |     0 |       1 |
| val_f1              | 0.885112 |     0 |       1 |
| val_precision       | 0.885528 |     0 |       1 |
| val_recall          | 0.885567 |     0 |       1 |
| val_loss            | 0.332506 |     0 |       1 |
[2024-05-22 15:44:45,990][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 15:44:46,090][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 15:44:46,090][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 15:44:46,093][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 15:44:46,093][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 15:44:46,093][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 15:44:46,093][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 15:44:46,094][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 15:44:46,094][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 15:44:46,094][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 15:44:46,095][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 15:44:46,095][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32 module.batch_size=128 trainer.max_epochs=10 +model.pretrained=True
[2024-05-22 15:44:46,095][hannah.utils.utils][INFO] -   
[2024-05-22 15:44:46,096][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:44:46,127][root][INFO] - Configuration: 
[2024-05-22 15:44:46,130][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
  sensor:
    resolution:
    - 32
    - 32
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
  pretrained: true
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 128
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 10
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 15:44:46,130][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 15:44:46,860][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 15:44:46,860][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 15:44:46,928][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 15:44:46,952][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 15:44:46,959][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 15:44:46,959][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 15:44:46,959][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 15:44:46,959][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 15:44:46,959][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 15:44:46,959][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:44:46,959][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:44:46,959][root][INFO] - Starting training
[2024-05-22 15:44:48,381][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 15:44:48,381][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 15:44:48,381][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 15:44:48,381][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 15:44:48,381][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 15:44:48,381][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 15:44:48,382][hannah.modules.vision.base][INFO] - Setting up model resnet18
[2024-05-22 15:44:48,544][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:803: UserWarning: Overwriting focalnet_tiny_srf in registry with hannah.models._vendor.focalnet.focalnet_tiny_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:44:48,544][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:824: UserWarning: Overwriting focalnet_small_srf in registry with hannah.models._vendor.focalnet.focalnet_small_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:44:48,544][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:843: UserWarning: Overwriting focalnet_base_srf in registry with hannah.models._vendor.focalnet.focalnet_base_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:44:48,544][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:862: UserWarning: Overwriting focalnet_tiny_lrf in registry with hannah.models._vendor.focalnet.focalnet_tiny_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:44:48,544][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:885: UserWarning: Overwriting focalnet_small_lrf in registry with hannah.models._vendor.focalnet.focalnet_small_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:44:48,545][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:906: UserWarning: Overwriting focalnet_base_lrf in registry with hannah.models._vendor.focalnet.focalnet_base_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:44:48,545][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1010: UserWarning: Overwriting focalnet_large_fl3 in registry with hannah.models._vendor.focalnet.focalnet_large_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:44:48,545][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1031: UserWarning: Overwriting focalnet_large_fl4 in registry with hannah.models._vendor.focalnet.focalnet_large_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:44:48,545][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1052: UserWarning: Overwriting focalnet_xlarge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:44:48,545][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1073: UserWarning: Overwriting focalnet_xlarge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:44:48,545][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1094: UserWarning: Overwriting focalnet_huge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:44:48,545][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1115: UserWarning: Overwriting focalnet_huge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:44:48,684][timm.models._builder][INFO] - Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
[2024-05-22 15:44:48,904][timm.models._hub][INFO] - [timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
[2024-05-22 15:44:48,981][hannah.models.timm][INFO] - Using default logger for automatic stem creation
[2024-05-22 15:44:48,981][hannah.models.timm][INFO] - Small input size detected trying to adopt small input size
[2024-05-22 15:44:48,997][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '

[2024-05-22 15:44:49,175][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)
[2024-05-22 15:44:49,179][hannah.modules.vision.base][INFO] - Running dummy forward to initialize lazy modules
[2024-05-22 15:44:49,223][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:44:49,237][pytorch_lightning.utilities.rank_zero][INFO] - Loading `train_dataloader` to estimate number of stepping batches.
[2024-05-22 15:44:49,902][pytorch_lightning.callbacks.model_summary][INFO] - 
  | Name           | Type                           | Params | In sizes       | Out sizes                          
-------------------------------------------------------------------------------------------------------------------------
0 | val_metrics    | MetricCollection               | 0      | ?              | ?                                  
1 | test_metrics   | MetricCollection               | 0      | ?              | ?                                  
2 | train_metrics  | MetricCollection               | 0      | ?              | ?                                  
3 | model          | TimmModel                      | 11.2 M | [1, 3, 32, 32] | [[1, 512, 4, 4], [0], [0], [1, 10]]
4 | test_confusion | MulticlassConfusionMatrix      | 0      | ?              | ?                                  
5 | test_roc       | MulticlassROC                  | 0      | ?              | ?                                  
6 | test_pr_curve  | MulticlassPrecisionRecallCurve | 0      | ?              | ?                                  
7 | metrics        | ModuleDict                     | 0      | ?              | ?                                  
-------------------------------------------------------------------------------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.696    Total estimated model params size (MB)
[2024-05-22 15:44:50,037][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:44:50,038][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:44:50,042][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:44:51,137][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 15:44:51,137][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 15:44:51,138][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 15:44:51,138][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 15:44:51,138][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 15:44:57,285][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 0, global step 351: 'val_error' reached 0.17768 (best 0.17768), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=351.ckpt' as top 1
[2024-05-22 15:45:03,378][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 1, global step 702: 'val_error' reached 0.14303 (best 0.14303), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=1-step=702.ckpt' as top 1
[2024-05-22 15:45:09,641][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 2, global step 1053: 'val_error' was not in top 1
[2024-05-22 15:45:15,810][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 3, global step 1404: 'val_error' was not in top 1
[2024-05-22 15:45:21,968][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 4, global step 1755: 'val_error' was not in top 1
[2024-05-22 15:45:28,102][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 5, global step 2106: 'val_error' was not in top 1
[2024-05-22 15:45:34,244][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 6, global step 2457: 'val_error' was not in top 1
[2024-05-22 15:45:40,438][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 7, global step 2808: 'val_error' reached 0.10817 (best 0.10817), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=7-step=2808.ckpt' as top 1
[2024-05-22 15:45:46,624][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 8, global step 3159: 'val_error' reached 0.07071 (best 0.07071), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=8-step=3159.ckpt' as top 1
[2024-05-22 15:45:52,798][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 9, global step 3510: 'val_error' reached 0.05589 (best 0.05589), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=3510.ckpt' as top 1
[2024-05-22 15:45:53,105][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer.fit` stopped: `max_epochs=10` reached.
[2024-05-22 15:45:53,450][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:45:53,450][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 15:45:53,452][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=3510.ckpt
[2024-05-22 15:45:53,496][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:45:53,608][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:45:53,608][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:45:53,610][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:45:53,827][pytorch_lightning.utilities.rank_zero][INFO] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=3510.ckpt
[2024-05-22 15:45:54,877][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:45:54,879][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 15:45:54,881][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=3510.ckpt
[2024-05-22 15:45:54,935][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:45:55,049][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:45:55,050][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:45:55,052][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:45:55,264][pytorch_lightning.utilities.rank_zero][INFO] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=3510.ckpt
[2024-05-22 15:45:56,632][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 15:45:56,633][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 15:45:56,633][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 15:45:56,633][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 15:45:56,633][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 15:45:56,633][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:45:56,634][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:45:57,102][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:45:57,209][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-22 15:45:57,425][hannah.train][INFO] - Averaged Result Metrics:
| Metric               |      Mean |   Std |   Count |
|----------------------|-----------|-------|---------|
| test_classifier_loss | 0.173745  |     0 |       1 |
| test_accuracy        | 0.940805  |     0 |       1 |
| test_error           | 0.0591947 |     0 |       1 |
| test_f1              | 0.940716  |     0 |       1 |
| test_precision       | 0.940812  |     0 |       1 |
| test_recall          | 0.940789  |     0 |       1 |
| test_loss            | 0.173745  |     0 |       1 |
[2024-05-22 15:45:57,436][hannah.train][INFO] - Averaged Result Metrics:
| Metric              |      Mean |   Std |   Count |
|---------------------|-----------|-------|---------|
| val_classifier_loss | 0.177934  |     0 |       1 |
| val_accuracy        | 0.944111  |     0 |       1 |
| val_error           | 0.0558894 |     0 |       1 |
| val_f1              | 0.94359   |     0 |       1 |
| val_precision       | 0.94353   |     0 |       1 |
| val_recall          | 0.943779  |     0 |       1 |
| val_loss            | 0.177934  |     0 |       1 |
[2024-05-22 15:48:28,430][hannah.utils.utils][INFO] - Environment info:
[2024-05-22 15:48:28,519][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-22 15:48:28,520][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-22 15:48:28,523][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-22 15:48:28,523][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-22 15:48:28,523][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-22 15:48:28,523][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-22 15:48:28,523][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-22 15:48:28,523][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-22 15:48:28,523][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-22 15:48:28,525][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-22 15:48:28,525][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32 module.batch_size=128 trainer.max_epochs=10 +model.pretrained=True
[2024-05-22 15:48:28,525][hannah.utils.utils][INFO] -   
[2024-05-22 15:48:28,526][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:48:28,556][root][INFO] - Configuration: 
[2024-05-22 15:48:28,559][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
  sensor:
    resolution:
    - 32
    - 32
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
  pretrained: true
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 128
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 10
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-22 15:48:28,559][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-22 15:48:29,297][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-22 15:48:29,297][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-22 15:48:29,365][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-22 15:48:29,390][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-22 15:48:29,396][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-22 15:48:29,396][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-22 15:48:29,396][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-22 15:48:29,397][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-22 15:48:29,397][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-22 15:48:29,397][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:48:29,397][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-22 15:48:29,397][root][INFO] - Starting training
[2024-05-22 15:48:30,784][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-22 15:48:30,784][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-22 15:48:30,784][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-22 15:48:30,784][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-22 15:48:30,784][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-22 15:48:30,784][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-22 15:48:30,785][hannah.modules.vision.base][INFO] - Setting up model resnet18
[2024-05-22 15:48:30,950][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:803: UserWarning: Overwriting focalnet_tiny_srf in registry with hannah.models._vendor.focalnet.focalnet_tiny_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:48:30,950][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:824: UserWarning: Overwriting focalnet_small_srf in registry with hannah.models._vendor.focalnet.focalnet_small_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:48:30,950][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:843: UserWarning: Overwriting focalnet_base_srf in registry with hannah.models._vendor.focalnet.focalnet_base_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:48:30,950][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:862: UserWarning: Overwriting focalnet_tiny_lrf in registry with hannah.models._vendor.focalnet.focalnet_tiny_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:48:30,951][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:885: UserWarning: Overwriting focalnet_small_lrf in registry with hannah.models._vendor.focalnet.focalnet_small_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:48:30,951][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:906: UserWarning: Overwriting focalnet_base_lrf in registry with hannah.models._vendor.focalnet.focalnet_base_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:48:30,951][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1010: UserWarning: Overwriting focalnet_large_fl3 in registry with hannah.models._vendor.focalnet.focalnet_large_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:48:30,951][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1031: UserWarning: Overwriting focalnet_large_fl4 in registry with hannah.models._vendor.focalnet.focalnet_large_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:48:30,951][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1052: UserWarning: Overwriting focalnet_xlarge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:48:30,951][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1073: UserWarning: Overwriting focalnet_xlarge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:48:30,952][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1094: UserWarning: Overwriting focalnet_huge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:48:30,952][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1115: UserWarning: Overwriting focalnet_huge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-22 15:48:31,075][timm.models._builder][INFO] - Loading pretrained weights from Hugging Face hub (timm/resnet18.a1_in1k)
[2024-05-22 15:48:31,228][timm.models._hub][INFO] - [timm/resnet18.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
[2024-05-22 15:48:31,247][hannah.models.timm][INFO] - Using default logger for automatic stem creation
[2024-05-22 15:48:31,247][hannah.models.timm][INFO] - Small input size detected trying to adopt small input size
[2024-05-22 15:48:31,261][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '

[2024-05-22 15:48:31,452][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)
[2024-05-22 15:48:31,456][hannah.modules.vision.base][INFO] - Running dummy forward to initialize lazy modules
[2024-05-22 15:48:31,467][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:48:31,480][pytorch_lightning.utilities.rank_zero][INFO] - Loading `train_dataloader` to estimate number of stepping batches.
[2024-05-22 15:48:32,169][pytorch_lightning.callbacks.model_summary][INFO] - 
  | Name           | Type                           | Params | In sizes       | Out sizes                          
-------------------------------------------------------------------------------------------------------------------------
0 | val_metrics    | MetricCollection               | 0      | ?              | ?                                  
1 | test_metrics   | MetricCollection               | 0      | ?              | ?                                  
2 | train_metrics  | MetricCollection               | 0      | ?              | ?                                  
3 | model          | TimmModel                      | 11.2 M | [1, 3, 32, 32] | [[1, 512, 4, 4], [0], [0], [1, 10]]
4 | test_confusion | MulticlassConfusionMatrix      | 0      | ?              | ?                                  
5 | test_roc       | MulticlassROC                  | 0      | ?              | ?                                  
6 | test_pr_curve  | MulticlassPrecisionRecallCurve | 0      | ?              | ?                                  
7 | metrics        | ModuleDict                     | 0      | ?              | ?                                  
-------------------------------------------------------------------------------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.696    Total estimated model params size (MB)
[2024-05-22 15:48:32,303][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:48:32,304][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:48:32,308][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:48:33,434][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-22 15:48:33,435][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-22 15:48:33,435][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-22 15:48:33,435][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-22 15:48:33,435][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-22 15:48:39,678][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 0, global step 351: 'val_error' reached 0.17768 (best 0.17768), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=351.ckpt' as top 1
[2024-05-22 15:48:42,721][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...

[2024-05-22 15:48:42,730][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:48:42,731][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 15:48:42,732][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=351.ckpt
[2024-05-22 15:48:42,811][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-22 15:48:42,925][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-22 15:48:42,925][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-22 15:48:42,927][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-22 15:48:43,145][pytorch_lightning.utilities.rank_zero][INFO] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=351.ckpt
[2024-05-22 15:48:43,327][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-22 15:48:43,329][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-22 15:48:43,331][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=351.ckpt
[2024-05-22 15:48:43,361][hannah.train][INFO] - Averaged Result Metrics:
| Metric              |     Mean |   Std |   Count |
|---------------------|----------|-------|---------|
| val_classifier_loss | 0.522127 |     0 |       1 |
| val_accuracy        | 0.822316 |     0 |       1 |
| val_error           | 0.177684 |     0 |       1 |
| val_f1              | 0.820167 |     0 |       1 |
| val_precision       | 0.826421 |     0 |       1 |
| val_recall          | 0.822147 |     0 |       1 |
| val_loss            | 0.522127 |     0 |       1 |
[2024-05-23 17:41:36,800][hannah.utils.utils][INFO] - Environment info:
[2024-05-23 17:41:36,896][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-23 17:41:36,897][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-23 17:41:36,901][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-23 17:41:36,901][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-23 17:41:36,901][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-23 17:41:36,901][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-23 17:41:36,902][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-23 17:41:36,902][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-23 17:41:36,902][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-23 17:41:36,903][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-23 17:41:36,903][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train
[2024-05-23 17:41:36,903][hannah.utils.utils][INFO] -   
[2024-05-23 17:41:36,904][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-23 17:41:36,907][root][INFO] - Configuration: 
[2024-05-23 17:41:36,910][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
  sensor:
    resolution:
    - 32
    - 32
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 128
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-23 17:41:36,910][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-23 17:41:37,713][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-23 17:41:37,713][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-23 17:41:37,781][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-23 17:41:37,805][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-23 17:41:37,811][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-23 17:41:37,812][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-23 17:41:37,812][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-23 17:41:37,812][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-23 17:41:37,812][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-23 17:41:37,812][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-23 17:41:37,812][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-23 17:41:37,812][root][INFO] - Starting training
[2024-05-23 17:41:39,317][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/albumentations/core/validation.py:34: UserWarning: Argument 'limit' is not valid and will be ignored.
  warn(

[2024-05-23 17:41:39,320][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-23 17:41:39,320][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-23 17:41:39,320][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-23 17:41:39,320][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-23 17:41:39,320][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-23 17:41:39,320][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-23 17:41:39,321][hannah.modules.vision.base][INFO] - Setting up model resnet18
[2024-05-23 17:41:39,490][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:803: UserWarning: Overwriting focalnet_tiny_srf in registry with hannah.models._vendor.focalnet.focalnet_tiny_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-23 17:41:39,490][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:824: UserWarning: Overwriting focalnet_small_srf in registry with hannah.models._vendor.focalnet.focalnet_small_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-23 17:41:39,490][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:843: UserWarning: Overwriting focalnet_base_srf in registry with hannah.models._vendor.focalnet.focalnet_base_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-23 17:41:39,490][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:862: UserWarning: Overwriting focalnet_tiny_lrf in registry with hannah.models._vendor.focalnet.focalnet_tiny_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-23 17:41:39,490][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:885: UserWarning: Overwriting focalnet_small_lrf in registry with hannah.models._vendor.focalnet.focalnet_small_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-23 17:41:39,490][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:906: UserWarning: Overwriting focalnet_base_lrf in registry with hannah.models._vendor.focalnet.focalnet_base_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-23 17:41:39,490][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1010: UserWarning: Overwriting focalnet_large_fl3 in registry with hannah.models._vendor.focalnet.focalnet_large_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-23 17:41:39,490][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1031: UserWarning: Overwriting focalnet_large_fl4 in registry with hannah.models._vendor.focalnet.focalnet_large_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-23 17:41:39,490][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1052: UserWarning: Overwriting focalnet_xlarge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-23 17:41:39,491][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1073: UserWarning: Overwriting focalnet_xlarge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-23 17:41:39,491][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1094: UserWarning: Overwriting focalnet_huge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-23 17:41:39,491][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1115: UserWarning: Overwriting focalnet_huge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-23 17:41:39,620][hannah.models.timm][INFO] - Using default logger for automatic stem creation
[2024-05-23 17:41:39,620][hannah.models.timm][INFO] - Small input size detected trying to adopt small input size
[2024-05-23 17:41:39,637][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '

[2024-05-23 17:41:39,867][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)
[2024-05-23 17:41:39,871][hannah.modules.vision.base][INFO] - Running dummy forward to initialize lazy modules
[2024-05-23 17:41:39,884][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-23 17:41:39,918][pytorch_lightning.utilities.rank_zero][INFO] - Loading `train_dataloader` to estimate number of stepping batches.
[2024-05-23 17:41:39,918][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=191` in the `DataLoader` to improve performance.

[2024-05-23 17:41:40,190][pytorch_lightning.callbacks.model_summary][INFO] - 
  | Name           | Type                           | Params | In sizes       | Out sizes                          
-------------------------------------------------------------------------------------------------------------------------
0 | val_metrics    | MetricCollection               | 0      | ?              | ?                                  
1 | test_metrics   | MetricCollection               | 0      | ?              | ?                                  
2 | train_metrics  | MetricCollection               | 0      | ?              | ?                                  
3 | model          | TimmModel                      | 11.2 M | [1, 3, 32, 32] | [[1, 512, 4, 4], [0], [0], [1, 10]]
4 | test_confusion | MulticlassConfusionMatrix      | 0      | ?              | ?                                  
5 | test_roc       | MulticlassROC                  | 0      | ?              | ?                                  
6 | test_pr_curve  | MulticlassPrecisionRecallCurve | 0      | ?              | ?                                  
7 | metrics        | ModuleDict                     | 0      | ?              | ?                                  
-------------------------------------------------------------------------------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.696    Total estimated model params size (MB)
[2024-05-23 17:41:40,331][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-23 17:41:40,331][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-23 17:41:40,336][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-23 17:41:40,625][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=191` in the `DataLoader` to improve performance.

[2024-05-23 17:41:40,965][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-23 17:41:40,965][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-23 17:41:40,965][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-23 17:41:40,965][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-23 17:41:40,965][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-23 17:42:31,575][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...

[2024-05-23 17:42:31,583][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-23 17:42:31,583][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-23 17:42:31,620][root][ERROR] - Exception Message: `.validate(ckpt_path="best")` is set but `ModelCheckpoint` is not configured to save the best model.
Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 183, in train
    lit_trainer.validate(ckpt_path=ckpt_path, verbose=validate_output)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 645, in validate
    return call._call_and_handle_interrupt(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 682, in _validate_impl
    ckpt_path = self._checkpoint_connector._select_ckpt_path(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py", line 104, in _select_ckpt_path
    ckpt_path = self._parse_ckpt_path(
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py", line 171, in _parse_ckpt_path
    raise ValueError(
ValueError: `.validate(ckpt_path="best")` is set but `ModelCheckpoint` is not configured to save the best model.
[2024-05-23 17:42:42,923][hannah.utils.utils][INFO] - Environment info:
[2024-05-23 17:42:43,017][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-23 17:42:43,018][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-23 17:42:43,022][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-23 17:42:43,023][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-23 17:42:43,023][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-23 17:42:43,023][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-23 17:42:43,023][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-23 17:42:43,023][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-23 17:42:43,023][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-23 17:42:43,024][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-23 17:42:43,024][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=8
[2024-05-23 17:42:43,024][hannah.utils.utils][INFO] -   
[2024-05-23 17:42:43,025][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-23 17:42:43,027][root][INFO] - Configuration: 
[2024-05-23 17:42:43,030][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
  sensor:
    resolution:
    - 32
    - 32
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 8
  batch_size: 128
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-23 17:42:43,030][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-23 17:42:43,830][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-23 17:42:43,831][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-23 17:42:43,899][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-23 17:42:43,923][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-23 17:42:43,930][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-23 17:42:43,930][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-23 17:42:43,930][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-23 17:42:43,930][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-23 17:42:43,931][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-23 17:42:43,931][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-23 17:42:43,931][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-23 17:42:43,931][root][INFO] - Starting training
[2024-05-23 17:42:45,434][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/albumentations/core/validation.py:34: UserWarning: Argument 'limit' is not valid and will be ignored.
  warn(

[2024-05-23 17:42:45,437][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-23 17:42:45,437][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-23 17:42:45,437][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-23 17:42:45,437][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-23 17:42:45,437][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-23 17:42:45,437][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-23 17:42:45,438][hannah.modules.vision.base][INFO] - Setting up model resnet18
[2024-05-23 17:42:45,603][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:803: UserWarning: Overwriting focalnet_tiny_srf in registry with hannah.models._vendor.focalnet.focalnet_tiny_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-23 17:42:45,604][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:824: UserWarning: Overwriting focalnet_small_srf in registry with hannah.models._vendor.focalnet.focalnet_small_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-23 17:42:45,604][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:843: UserWarning: Overwriting focalnet_base_srf in registry with hannah.models._vendor.focalnet.focalnet_base_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-23 17:42:45,604][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:862: UserWarning: Overwriting focalnet_tiny_lrf in registry with hannah.models._vendor.focalnet.focalnet_tiny_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-23 17:42:45,604][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:885: UserWarning: Overwriting focalnet_small_lrf in registry with hannah.models._vendor.focalnet.focalnet_small_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-23 17:42:45,604][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:906: UserWarning: Overwriting focalnet_base_lrf in registry with hannah.models._vendor.focalnet.focalnet_base_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-23 17:42:45,604][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1010: UserWarning: Overwriting focalnet_large_fl3 in registry with hannah.models._vendor.focalnet.focalnet_large_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-23 17:42:45,604][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1031: UserWarning: Overwriting focalnet_large_fl4 in registry with hannah.models._vendor.focalnet.focalnet_large_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-23 17:42:45,604][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1052: UserWarning: Overwriting focalnet_xlarge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-23 17:42:45,604][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1073: UserWarning: Overwriting focalnet_xlarge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-23 17:42:45,604][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1094: UserWarning: Overwriting focalnet_huge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-23 17:42:45,604][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1115: UserWarning: Overwriting focalnet_huge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-23 17:42:45,731][hannah.models.timm][INFO] - Using default logger for automatic stem creation
[2024-05-23 17:42:45,731][hannah.models.timm][INFO] - Small input size detected trying to adopt small input size
[2024-05-23 17:42:45,749][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '

[2024-05-23 17:42:45,974][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)
[2024-05-23 17:42:45,978][hannah.modules.vision.base][INFO] - Running dummy forward to initialize lazy modules
[2024-05-23 17:42:45,993][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-23 17:42:46,007][pytorch_lightning.utilities.rank_zero][INFO] - Loading `train_dataloader` to estimate number of stepping batches.
[2024-05-23 17:42:46,392][pytorch_lightning.callbacks.model_summary][INFO] - 
  | Name           | Type                           | Params | In sizes       | Out sizes                          
-------------------------------------------------------------------------------------------------------------------------
0 | val_metrics    | MetricCollection               | 0      | ?              | ?                                  
1 | test_metrics   | MetricCollection               | 0      | ?              | ?                                  
2 | train_metrics  | MetricCollection               | 0      | ?              | ?                                  
3 | model          | TimmModel                      | 11.2 M | [1, 3, 32, 32] | [[1, 512, 4, 4], [0], [0], [1, 10]]
4 | test_confusion | MulticlassConfusionMatrix      | 0      | ?              | ?                                  
5 | test_roc       | MulticlassROC                  | 0      | ?              | ?                                  
6 | test_pr_curve  | MulticlassPrecisionRecallCurve | 0      | ?              | ?                                  
7 | metrics        | ModuleDict                     | 0      | ?              | ?                                  
-------------------------------------------------------------------------------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.696    Total estimated model params size (MB)
[2024-05-23 17:42:46,533][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-23 17:42:46,533][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-23 17:42:46,538][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-23 17:42:47,359][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-23 17:42:47,360][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-23 17:42:47,360][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-23 17:42:47,360][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-23 17:42:47,360][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-23 17:43:12,600][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 0, global step 351: 'val_error' reached 0.71975 (best 0.71975), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=351.ckpt' as top 1
[2024-05-23 17:43:39,329][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 1, global step 702: 'val_error' reached 0.65284 (best 0.65284), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=1-step=702.ckpt' as top 1
[2024-05-23 17:44:05,724][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 2, global step 1053: 'val_error' reached 0.63622 (best 0.63622), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=2-step=1053.ckpt' as top 1
[2024-05-23 17:44:32,302][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 3, global step 1404: 'val_error' reached 0.54067 (best 0.54067), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=3-step=1404.ckpt' as top 1
[2024-05-23 17:45:02,247][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 4, global step 1755: 'val_error' reached 0.51883 (best 0.51883), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=4-step=1755.ckpt' as top 1
[2024-05-23 17:45:32,209][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 5, global step 2106: 'val_error' reached 0.43590 (best 0.43590), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=5-step=2106.ckpt' as top 1
[2024-05-23 17:46:01,017][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 6, global step 2457: 'val_error' was not in top 1
[2024-05-23 17:46:29,672][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 7, global step 2808: 'val_error' reached 0.42248 (best 0.42248), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=7-step=2808.ckpt' as top 1
[2024-05-23 17:46:59,239][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 8, global step 3159: 'val_error' was not in top 1
[2024-05-23 17:47:28,360][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 9, global step 3510: 'val_error' was not in top 1
[2024-05-23 17:47:57,019][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 10, global step 3861: 'val_error' reached 0.33373 (best 0.33373), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=10-step=3861.ckpt' as top 1
[2024-05-23 17:48:27,079][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 11, global step 4212: 'val_error' was not in top 1
[2024-05-23 17:48:55,738][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 12, global step 4563: 'val_error' was not in top 1
[2024-05-23 17:49:24,865][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 13, global step 4914: 'val_error' was not in top 1
[2024-05-23 17:49:53,286][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 14, global step 5265: 'val_error' was not in top 1
[2024-05-23 17:50:22,560][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 15, global step 5616: 'val_error' reached 0.32312 (best 0.32312), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=15-step=5616.ckpt' as top 1
[2024-05-23 17:50:51,388][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 16, global step 5967: 'val_error' was not in top 1
[2024-05-23 17:51:20,385][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 17, global step 6318: 'val_error' was not in top 1
[2024-05-23 17:51:49,423][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 18, global step 6669: 'val_error' was not in top 1
[2024-05-23 17:52:17,904][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 19, global step 7020: 'val_error' was not in top 1
[2024-05-23 17:52:46,881][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 20, global step 7371: 'val_error' reached 0.31631 (best 0.31631), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=20-step=7371.ckpt' as top 1
[2024-05-23 17:53:16,930][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 21, global step 7722: 'val_error' was not in top 1
[2024-05-23 17:53:45,759][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 22, global step 8073: 'val_error' reached 0.31370 (best 0.31370), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=22-step=8073.ckpt' as top 1
[2024-05-23 17:54:16,598][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 23, global step 8424: 'val_error' reached 0.30809 (best 0.30809), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=23-step=8424.ckpt' as top 1
[2024-05-23 17:54:45,397][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 24, global step 8775: 'val_error' was not in top 1
[2024-05-23 17:55:14,844][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 25, global step 9126: 'val_error' reached 0.28566 (best 0.28566), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=25-step=9126.ckpt' as top 1
[2024-05-23 17:55:43,686][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 26, global step 9477: 'val_error' was not in top 1
[2024-05-23 17:56:12,271][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 27, global step 9828: 'val_error' was not in top 1
[2024-05-23 17:56:43,675][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 28, global step 10179: 'val_error' reached 0.27123 (best 0.27123), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=28-step=10179.ckpt' as top 1
[2024-05-23 17:57:15,286][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 29, global step 10530: 'val_error' was not in top 1
[2024-05-23 17:57:43,585][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 30, global step 10881: 'val_error' reached 0.24099 (best 0.24099), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=30-step=10881.ckpt' as top 1
[2024-05-23 17:58:12,396][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 31, global step 11232: 'val_error' was not in top 1
[2024-05-23 17:58:40,883][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 32, global step 11583: 'val_error' was not in top 1
[2024-05-23 17:59:08,709][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 33, global step 11934: 'val_error' was not in top 1
[2024-05-23 17:59:37,467][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 34, global step 12285: 'val_error' was not in top 1
[2024-05-23 18:00:05,313][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 35, global step 12636: 'val_error' reached 0.22977 (best 0.22977), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=35-step=12636.ckpt' as top 1
[2024-05-23 18:00:33,473][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 36, global step 12987: 'val_error' reached 0.20933 (best 0.20933), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=36-step=12987.ckpt' as top 1
[2024-05-23 18:01:03,715][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 37, global step 13338: 'val_error' was not in top 1
[2024-05-23 18:01:32,725][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 38, global step 13689: 'val_error' was not in top 1
[2024-05-23 18:02:01,471][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 39, global step 14040: 'val_error' was not in top 1
[2024-05-23 18:02:30,294][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 40, global step 14391: 'val_error' reached 0.17768 (best 0.17768), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=40-step=14391.ckpt' as top 1
[2024-05-23 18:02:59,396][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 41, global step 14742: 'val_error' was not in top 1
[2024-05-23 18:03:27,723][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 42, global step 15093: 'val_error' reached 0.16967 (best 0.16967), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=42-step=15093.ckpt' as top 1
[2024-05-23 18:03:56,790][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 43, global step 15444: 'val_error' reached 0.16747 (best 0.16747), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=43-step=15444.ckpt' as top 1
[2024-05-23 18:04:25,837][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 44, global step 15795: 'val_error' reached 0.14643 (best 0.14643), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=44-step=15795.ckpt' as top 1
[2024-05-23 18:04:55,676][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 45, global step 16146: 'val_error' reached 0.12981 (best 0.12981), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=45-step=16146.ckpt' as top 1
[2024-05-23 18:05:25,682][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 46, global step 16497: 'val_error' reached 0.12440 (best 0.12440), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=46-step=16497.ckpt' as top 1
[2024-05-23 18:05:54,826][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 47, global step 16848: 'val_error' reached 0.11599 (best 0.11599), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=47-step=16848.ckpt' as top 1
[2024-05-23 18:06:24,205][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 48, global step 17199: 'val_error' reached 0.11018 (best 0.11018), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=48-step=17199.ckpt' as top 1
[2024-05-23 18:06:53,859][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 49, global step 17550: 'val_error' reached 0.10857 (best 0.10857), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=49-step=17550.ckpt' as top 1
[2024-05-23 18:06:54,284][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer.fit` stopped: `max_epochs=50` reached.
[2024-05-23 18:06:54,554][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-23 18:06:54,559][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-23 18:06:54,561][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=49-step=17550.ckpt
[2024-05-23 18:06:54,649][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-23 18:06:54,820][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-23 18:06:54,820][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-23 18:06:54,822][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-23 18:06:55,056][pytorch_lightning.utilities.rank_zero][INFO] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=49-step=17550.ckpt
[2024-05-23 18:06:56,771][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-23 18:06:56,772][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-23 18:06:56,773][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=49-step=17550.ckpt
[2024-05-23 18:06:56,832][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-23 18:06:57,056][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-23 18:06:57,056][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-23 18:06:57,058][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-23 18:06:57,292][pytorch_lightning.utilities.rank_zero][INFO] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=49-step=17550.ckpt
[2024-05-23 18:07:00,688][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-23 18:07:00,689][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-23 18:07:00,689][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-23 18:07:00,689][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-23 18:07:00,689][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-23 18:07:00,690][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-23 18:07:00,691][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-23 18:07:01,282][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-23 18:07:01,413][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-23 18:07:01,705][hannah.train][INFO] - Averaged Result Metrics:
| Metric               |     Mean |   Std |   Count |
|----------------------|----------|-------|---------|
| test_classifier_loss | 0.31712  |     0 |       1 |
| test_accuracy        | 0.893029 |     0 |       1 |
| test_error           | 0.106971 |     0 |       1 |
| test_f1              | 0.892755 |     0 |       1 |
| test_precision       | 0.892756 |     0 |       1 |
| test_recall          | 0.892993 |     0 |       1 |
| test_loss            | 0.31712  |     0 |       1 |
[2024-05-23 18:07:01,718][hannah.train][INFO] - Averaged Result Metrics:
| Metric              |     Mean |   Std |   Count |
|---------------------|----------|-------|---------|
| val_classifier_loss | 0.316657 |     0 |       1 |
| val_accuracy        | 0.891426 |     0 |       1 |
| val_error           | 0.108574 |     0 |       1 |
| val_f1              | 0.890211 |     0 |       1 |
| val_precision       | 0.890122 |     0 |       1 |
| val_recall          | 0.890518 |     0 |       1 |
| val_loss            | 0.316657 |     0 |       1 |
[2024-05-24 10:59:58,001][hannah.utils.utils][INFO] - Environment info:
[2024-05-24 10:59:58,101][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-24 10:59:58,102][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-24 10:59:58,105][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-24 10:59:58,105][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-24 10:59:58,105][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-24 10:59:58,106][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-24 10:59:58,106][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-24 10:59:58,106][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-24 10:59:58,106][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-24 10:59:58,107][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-24 10:59:58,108][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train
[2024-05-24 10:59:58,108][hannah.utils.utils][INFO] -   
[2024-05-24 10:59:58,109][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-24 10:59:58,155][root][INFO] - Configuration: 
[2024-05-24 10:59:58,158][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
  sensor:
    resolution:
    - 32
    - 32
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 128
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-24 10:59:58,158][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-24 10:59:59,023][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-24 10:59:59,023][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-24 10:59:59,097][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-24 10:59:59,123][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-24 10:59:59,131][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-24 10:59:59,131][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-24 10:59:59,131][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-24 10:59:59,131][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-24 10:59:59,131][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-24 10:59:59,131][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-24 10:59:59,131][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-24 10:59:59,131][root][INFO] - Starting training
[2024-05-24 11:00:01,692][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/albumentations/core/validation.py:34: UserWarning: Argument 'limit' is not valid and will be ignored.
  warn(

[2024-05-24 11:00:01,695][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-24 11:00:01,695][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-24 11:00:01,696][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-24 11:00:01,696][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-24 11:00:01,696][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-24 11:00:01,696][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-24 11:00:01,698][hannah.modules.vision.base][INFO] - Setting up model resnet18
[2024-05-24 11:00:01,878][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:803: UserWarning: Overwriting focalnet_tiny_srf in registry with hannah.models._vendor.focalnet.focalnet_tiny_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-24 11:00:01,878][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:824: UserWarning: Overwriting focalnet_small_srf in registry with hannah.models._vendor.focalnet.focalnet_small_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-24 11:00:01,878][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:843: UserWarning: Overwriting focalnet_base_srf in registry with hannah.models._vendor.focalnet.focalnet_base_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-24 11:00:01,878][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:862: UserWarning: Overwriting focalnet_tiny_lrf in registry with hannah.models._vendor.focalnet.focalnet_tiny_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-24 11:00:01,878][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:885: UserWarning: Overwriting focalnet_small_lrf in registry with hannah.models._vendor.focalnet.focalnet_small_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-24 11:00:01,878][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:906: UserWarning: Overwriting focalnet_base_lrf in registry with hannah.models._vendor.focalnet.focalnet_base_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-24 11:00:01,878][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1010: UserWarning: Overwriting focalnet_large_fl3 in registry with hannah.models._vendor.focalnet.focalnet_large_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-24 11:00:01,878][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1031: UserWarning: Overwriting focalnet_large_fl4 in registry with hannah.models._vendor.focalnet.focalnet_large_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-24 11:00:01,878][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1052: UserWarning: Overwriting focalnet_xlarge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-24 11:00:01,878][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1073: UserWarning: Overwriting focalnet_xlarge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-24 11:00:01,879][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1094: UserWarning: Overwriting focalnet_huge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-24 11:00:01,879][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1115: UserWarning: Overwriting focalnet_huge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-24 11:00:02,018][hannah.models.timm][INFO] - Using default logger for automatic stem creation
[2024-05-24 11:00:02,018][hannah.models.timm][INFO] - Small input size detected trying to adopt small input size
[2024-05-24 11:00:02,073][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '

[2024-05-24 11:00:02,406][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)
[2024-05-24 11:00:02,411][hannah.modules.vision.base][INFO] - Running dummy forward to initialize lazy modules
[2024-05-24 11:00:02,430][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-24 11:00:02,585][pytorch_lightning.utilities.rank_zero][INFO] - Loading `train_dataloader` to estimate number of stepping batches.
[2024-05-24 11:00:02,585][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=191` in the `DataLoader` to improve performance.

[2024-05-24 11:00:02,848][pytorch_lightning.callbacks.model_summary][INFO] - 
  | Name           | Type                           | Params | In sizes       | Out sizes                          
-------------------------------------------------------------------------------------------------------------------------
0 | val_metrics    | MetricCollection               | 0      | ?              | ?                                  
1 | test_metrics   | MetricCollection               | 0      | ?              | ?                                  
2 | train_metrics  | MetricCollection               | 0      | ?              | ?                                  
3 | model          | TimmModel                      | 11.2 M | [1, 3, 32, 32] | [[1, 512, 4, 4], [0], [0], [1, 10]]
4 | test_confusion | MulticlassConfusionMatrix      | 0      | ?              | ?                                  
5 | test_roc       | MulticlassROC                  | 0      | ?              | ?                                  
6 | test_pr_curve  | MulticlassPrecisionRecallCurve | 0      | ?              | ?                                  
7 | metrics        | ModuleDict                     | 0      | ?              | ?                                  
-------------------------------------------------------------------------------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.696    Total estimated model params size (MB)
[2024-05-24 11:00:03,007][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-24 11:00:03,008][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-24 11:00:03,014][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-24 11:00:03,309][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=191` in the `DataLoader` to improve performance.

[2024-05-24 11:00:03,702][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-24 11:00:03,703][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-24 11:00:03,703][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-24 11:00:03,703][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-24 11:00:03,703][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-24 11:00:10,986][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...

[2024-05-24 11:00:10,990][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-24 11:00:10,991][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-24 11:00:11,038][root][ERROR] - Exception Message: `.validate(ckpt_path="best")` is set but `ModelCheckpoint` is not configured to save the best model.
Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 183, in train
    lit_trainer.validate(ckpt_path=ckpt_path, verbose=validate_output)
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 645, in validate
    return call._call_and_handle_interrupt(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 682, in _validate_impl
    ckpt_path = self._checkpoint_connector._select_ckpt_path(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py", line 104, in _select_ckpt_path
    ckpt_path = self._parse_ckpt_path(
                ^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py", line 171, in _parse_ckpt_path
    raise ValueError(
ValueError: `.validate(ckpt_path="best")` is set but `ModelCheckpoint` is not configured to save the best model.
[2024-05-24 11:00:24,012][hannah.utils.utils][INFO] - Environment info:
[2024-05-24 11:00:24,120][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-05-24 11:00:24,121][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-05-24 11:00:24,123][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-05-24 11:00:24,123][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.24.1.el8_9.x86_64
[2024-05-24 11:00:24,124][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-05-24 11:00:24,124][hannah.utils.utils][INFO] -   PyTorch: 2.2.2+cu121
[2024-05-24 11:00:24,124][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.2.4
[2024-05-24 11:00:24,124][hannah.utils.utils][INFO] -   Numpy: 1.26.4
[2024-05-24 11:00:24,124][hannah.utils.utils][INFO] -   Hannah version info:
[2024-05-24 11:00:24,125][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-05-24 11:00:24,126][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train module.num_workers=32
[2024-05-24 11:00:24,126][hannah.utils.utils][INFO] -   
[2024-05-24 11:00:24,127][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-24 11:00:24,128][root][INFO] - Configuration: 
[2024-05-24 11:00:24,131][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
  sensor:
    resolution:
    - 32
    - 32
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.timm.TimmModel
  name: resnet18
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 32
  batch_size: 128
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
experiment_id: test
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-05-24 11:00:24,131][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18
[2024-05-24 11:00:24,981][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-05-24 11:00:24,981][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-05-24 11:00:25,052][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:563: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-05-24 11:00:25,078][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-05-24 11:00:25,085][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-05-24 11:00:25,085][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-05-24 11:00:25,085][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-05-24 11:00:25,085][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-05-24 11:00:25,085][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-05-24 11:00:25,085][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-24 11:00:25,085][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-05-24 11:00:25,085][root][INFO] - Starting training
[2024-05-24 11:00:27,801][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/albumentations/core/validation.py:34: UserWarning: Argument 'limit' is not valid and will be ignored.
  warn(

[2024-05-24 11:00:27,804][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:63: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-05-24 11:00:27,804][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-05-24 11:00:27,804][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-05-24 11:00:27,804][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-05-24 11:00:27,804][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-05-24 11:00:27,804][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-05-24 11:00:27,805][hannah.modules.vision.base][INFO] - Setting up model resnet18
[2024-05-24 11:00:27,976][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:803: UserWarning: Overwriting focalnet_tiny_srf in registry with hannah.models._vendor.focalnet.focalnet_tiny_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-24 11:00:27,976][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:824: UserWarning: Overwriting focalnet_small_srf in registry with hannah.models._vendor.focalnet.focalnet_small_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-24 11:00:27,976][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:843: UserWarning: Overwriting focalnet_base_srf in registry with hannah.models._vendor.focalnet.focalnet_base_srf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-24 11:00:27,976][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:862: UserWarning: Overwriting focalnet_tiny_lrf in registry with hannah.models._vendor.focalnet.focalnet_tiny_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-24 11:00:27,976][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:885: UserWarning: Overwriting focalnet_small_lrf in registry with hannah.models._vendor.focalnet.focalnet_small_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-24 11:00:27,976][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:906: UserWarning: Overwriting focalnet_base_lrf in registry with hannah.models._vendor.focalnet.focalnet_base_lrf. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-24 11:00:27,976][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1010: UserWarning: Overwriting focalnet_large_fl3 in registry with hannah.models._vendor.focalnet.focalnet_large_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-24 11:00:27,976][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1031: UserWarning: Overwriting focalnet_large_fl4 in registry with hannah.models._vendor.focalnet.focalnet_large_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-24 11:00:27,976][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1052: UserWarning: Overwriting focalnet_xlarge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-24 11:00:27,976][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1073: UserWarning: Overwriting focalnet_xlarge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_xlarge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-24 11:00:27,976][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1094: UserWarning: Overwriting focalnet_huge_fl3 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-24 11:00:27,977][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/_vendor/focalnet.py:1115: UserWarning: Overwriting focalnet_huge_fl4 in registry with hannah.models._vendor.focalnet.focalnet_huge_fl4. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  @register_model

[2024-05-24 11:00:28,124][hannah.models.timm][INFO] - Using default logger for automatic stem creation
[2024-05-24 11:00:28,124][hannah.models.timm][INFO] - Small input size detected trying to adopt small input size
[2024-05-24 11:00:28,143][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '

[2024-05-24 11:00:28,432][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)
[2024-05-24 11:00:28,436][hannah.modules.vision.base][INFO] - Running dummy forward to initialize lazy modules
[2024-05-24 11:00:28,451][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-24 11:00:28,466][pytorch_lightning.utilities.rank_zero][INFO] - Loading `train_dataloader` to estimate number of stepping batches.
[2024-05-24 11:00:29,547][pytorch_lightning.callbacks.model_summary][INFO] - 
  | Name           | Type                           | Params | In sizes       | Out sizes                          
-------------------------------------------------------------------------------------------------------------------------
0 | val_metrics    | MetricCollection               | 0      | ?              | ?                                  
1 | test_metrics   | MetricCollection               | 0      | ?              | ?                                  
2 | train_metrics  | MetricCollection               | 0      | ?              | ?                                  
3 | model          | TimmModel                      | 11.2 M | [1, 3, 32, 32] | [[1, 512, 4, 4], [0], [0], [1, 10]]
4 | test_confusion | MulticlassConfusionMatrix      | 0      | ?              | ?                                  
5 | test_roc       | MulticlassROC                  | 0      | ?              | ?                                  
6 | test_pr_curve  | MulticlassPrecisionRecallCurve | 0      | ?              | ?                                  
7 | metrics        | ModuleDict                     | 0      | ?              | ?                                  
-------------------------------------------------------------------------------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.696    Total estimated model params size (MB)
[2024-05-24 11:00:29,811][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-24 11:00:29,812][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-24 11:00:29,822][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-24 11:00:31,843][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-24 11:00:31,843][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-24 11:00:31,843][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-24 11:00:31,843][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-24 11:00:31,843][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-24 11:00:50,738][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 0, global step 351: 'val_error' reached 0.70813 (best 0.70813), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=0-step=351.ckpt' as top 1
[2024-05-24 11:01:10,365][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 1, global step 702: 'val_error' reached 0.66306 (best 0.66306), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=1-step=702.ckpt' as top 1
[2024-05-24 11:01:29,560][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 2, global step 1053: 'val_error' reached 0.59555 (best 0.59555), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=2-step=1053.ckpt' as top 1
[2024-05-24 11:01:49,050][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 3, global step 1404: 'val_error' reached 0.53045 (best 0.53045), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=3-step=1404.ckpt' as top 1
[2024-05-24 11:02:08,533][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 4, global step 1755: 'val_error' was not in top 1
[2024-05-24 11:02:27,883][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 5, global step 2106: 'val_error' reached 0.50361 (best 0.50361), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=5-step=2106.ckpt' as top 1
[2024-05-24 11:02:47,242][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 6, global step 2457: 'val_error' reached 0.44591 (best 0.44591), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=6-step=2457.ckpt' as top 1
[2024-05-24 11:03:06,821][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 7, global step 2808: 'val_error' was not in top 1
[2024-05-24 11:03:26,144][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 8, global step 3159: 'val_error' reached 0.38201 (best 0.38201), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=8-step=3159.ckpt' as top 1
[2024-05-24 11:03:45,646][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 9, global step 3510: 'val_error' reached 0.37540 (best 0.37540), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=9-step=3510.ckpt' as top 1
[2024-05-24 11:04:04,947][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 10, global step 3861: 'val_error' reached 0.35577 (best 0.35577), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=10-step=3861.ckpt' as top 1
[2024-05-24 11:04:24,532][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 11, global step 4212: 'val_error' was not in top 1
[2024-05-24 11:04:44,018][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 12, global step 4563: 'val_error' was not in top 1
[2024-05-24 11:05:03,240][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 13, global step 4914: 'val_error' was not in top 1
[2024-05-24 11:05:22,705][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 14, global step 5265: 'val_error' reached 0.35156 (best 0.35156), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=14-step=5265.ckpt' as top 1
[2024-05-24 11:05:42,378][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 15, global step 5616: 'val_error' reached 0.29567 (best 0.29567), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=15-step=5616.ckpt' as top 1
[2024-05-24 11:06:01,765][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 16, global step 5967: 'val_error' was not in top 1
[2024-05-24 11:06:20,952][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 17, global step 6318: 'val_error' was not in top 1
[2024-05-24 11:06:40,022][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 18, global step 6669: 'val_error' was not in top 1
[2024-05-24 11:06:58,918][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 19, global step 7020: 'val_error' was not in top 1
[2024-05-24 11:07:18,171][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 20, global step 7371: 'val_error' was not in top 1
[2024-05-24 11:07:37,286][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 21, global step 7722: 'val_error' was not in top 1
[2024-05-24 11:07:56,140][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 22, global step 8073: 'val_error' was not in top 1
[2024-05-24 11:08:15,354][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 23, global step 8424: 'val_error' was not in top 1
[2024-05-24 11:08:34,520][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 24, global step 8775: 'val_error' was not in top 1
[2024-05-24 11:08:53,888][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 25, global step 9126: 'val_error' was not in top 1
[2024-05-24 11:09:12,679][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 26, global step 9477: 'val_error' was not in top 1
[2024-05-24 11:09:31,829][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 27, global step 9828: 'val_error' was not in top 1
[2024-05-24 11:09:50,799][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 28, global step 10179: 'val_error' reached 0.25861 (best 0.25861), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=28-step=10179.ckpt' as top 1
[2024-05-24 11:10:10,251][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 29, global step 10530: 'val_error' was not in top 1
[2024-05-24 11:10:29,215][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 30, global step 10881: 'val_error' was not in top 1
[2024-05-24 11:10:48,296][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 31, global step 11232: 'val_error' was not in top 1
[2024-05-24 11:11:07,210][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 32, global step 11583: 'val_error' was not in top 1
[2024-05-24 11:11:26,653][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 33, global step 11934: 'val_error' reached 0.24119 (best 0.24119), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=33-step=11934.ckpt' as top 1
[2024-05-24 11:11:45,799][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 34, global step 12285: 'val_error' was not in top 1
[2024-05-24 11:12:05,574][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 35, global step 12636: 'val_error' reached 0.22536 (best 0.22536), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=35-step=12636.ckpt' as top 1
[2024-05-24 11:12:24,658][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 36, global step 12987: 'val_error' was not in top 1
[2024-05-24 11:12:43,854][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 37, global step 13338: 'val_error' was not in top 1
[2024-05-24 11:13:03,337][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 38, global step 13689: 'val_error' reached 0.22276 (best 0.22276), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=38-step=13689.ckpt' as top 1
[2024-05-24 11:13:22,640][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 39, global step 14040: 'val_error' reached 0.19371 (best 0.19371), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=39-step=14040.ckpt' as top 1
[2024-05-24 11:13:41,859][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 40, global step 14391: 'val_error' was not in top 1
[2024-05-24 11:14:01,062][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 41, global step 14742: 'val_error' reached 0.17788 (best 0.17788), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=41-step=14742.ckpt' as top 1
[2024-05-24 11:14:20,428][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 42, global step 15093: 'val_error' reached 0.16246 (best 0.16246), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=42-step=15093.ckpt' as top 1
[2024-05-24 11:14:36,138][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 43, global step 15444: 'val_error' reached 0.16206 (best 0.16206), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=43-step=15444.ckpt' as top 1
[2024-05-24 11:14:48,066][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 44, global step 15795: 'val_error' reached 0.15645 (best 0.15645), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=44-step=15795.ckpt' as top 1
[2024-05-24 11:14:58,399][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 45, global step 16146: 'val_error' reached 0.12700 (best 0.12700), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=45-step=16146.ckpt' as top 1
[2024-05-24 11:15:09,086][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 46, global step 16497: 'val_error' reached 0.11839 (best 0.11839), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=46-step=16497.ckpt' as top 1
[2024-05-24 11:15:19,226][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 47, global step 16848: 'val_error' reached 0.10978 (best 0.10978), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=47-step=16848.ckpt' as top 1
[2024-05-24 11:15:28,406][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 48, global step 17199: 'val_error' reached 0.10357 (best 0.10357), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=48-step=17199.ckpt' as top 1
[2024-05-24 11:15:37,712][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 49, global step 17550: 'val_error' was not in top 1
[2024-05-24 11:15:37,964][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer.fit` stopped: `max_epochs=50` reached.
[2024-05-24 11:15:38,374][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-24 11:15:38,377][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-24 11:15:38,378][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=48-step=17199.ckpt
[2024-05-24 11:15:38,444][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-24 11:15:38,557][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-24 11:15:38,558][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-24 11:15:38,559][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-24 11:15:38,771][pytorch_lightning.utilities.rank_zero][INFO] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=48-step=17199.ckpt
[2024-05-24 11:15:40,170][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-05-24 11:15:40,171][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-05-24 11:15:40,173][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=48-step=17199.ckpt
[2024-05-24 11:15:40,221][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-05-24 11:15:40,334][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:312: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  decoded = torch.tensor([])

[2024-05-24 11:15:40,335][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:316: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  logits = torch.tensor([])

[2024-05-24 11:15:40,336][py.warnings][WARNING] - /local/gerum/hannah/hannah/models/timm.py:320: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  projection = torch.tensor([])

[2024-05-24 11:15:40,548][pytorch_lightning.utilities.rank_zero][INFO] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/test/resnet18/checkpoints/epoch=48-step=17199.ckpt
[2024-05-24 11:15:42,416][hannah.callbacks.summaries][INFO] - 
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name                          | Type                  | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | encoder.conv1                 | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | encoder.bn1                   | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | encoder.act1                  | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | encoder.maxpool               | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | encoder.layer1.0.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
|  5 | encoder.layer1.0.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  6 | encoder.layer1.0.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  7 | encoder.layer1.0.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  8 | encoder.layer1.0.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  9 | encoder.layer1.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 10 | encoder.layer1.0.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 11 | encoder.layer1.0.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 12 | encoder.layer1.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 13 | encoder.layer1.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 14 | encoder.layer1.1.bn1          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 15 | encoder.layer1.1.drop_block   | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 16 | encoder.layer1.1.act1         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 17 | encoder.layer1.1.aa           | Identity              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 18 | encoder.layer1.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |            36864 | 37748736 |
| 19 | encoder.layer1.1.bn2          | BatchNorm2d           |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 20 | encoder.layer1.1.act2         | ReLU                  |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 21 | encoder.layer1.1              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 22 | encoder.layer1                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
| 23 | encoder.layer2.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |            73728 | 18874368 |
| 24 | encoder.layer2.0.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 25 | encoder.layer2.0.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 26 | encoder.layer2.0.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 27 | encoder.layer2.0.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 28 | encoder.layer2.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 29 | encoder.layer2.0.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 30 | encoder.layer2.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |             8192 |  2097152 |
| 31 | encoder.layer2.0.downsample.1 | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 32 | encoder.layer2.0.downsample   | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 33 | encoder.layer2.0.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 34 | encoder.layer2.0              | BasicBlock            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 35 | encoder.layer2.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 36 | encoder.layer2.1.bn1          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 37 | encoder.layer2.1.drop_block   | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 38 | encoder.layer2.1.act1         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 39 | encoder.layer2.1.aa           | Identity              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 40 | encoder.layer2.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 41 | encoder.layer2.1.bn2          | BatchNorm2d           |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 42 | encoder.layer2.1.act2         | ReLU                  |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 43 | encoder.layer2.1              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 44 | encoder.layer2                | Sequential            |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 45 | encoder.layer3.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |           294912 | 18874368 |
| 46 | encoder.layer3.0.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 47 | encoder.layer3.0.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 48 | encoder.layer3.0.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 49 | encoder.layer3.0.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 50 | encoder.layer3.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 51 | encoder.layer3.0.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 52 | encoder.layer3.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |            32768 |  2097152 |
| 53 | encoder.layer3.0.downsample.1 | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 54 | encoder.layer3.0.downsample   | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 55 | encoder.layer3.0.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 56 | encoder.layer3.0              | BasicBlock            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 57 | encoder.layer3.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 58 | encoder.layer3.1.bn1          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 59 | encoder.layer3.1.drop_block   | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 60 | encoder.layer3.1.act1         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 61 | encoder.layer3.1.aa           | Identity              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 62 | encoder.layer3.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 63 | encoder.layer3.1.bn2          | BatchNorm2d           |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 64 | encoder.layer3.1.act2         | ReLU                  |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 65 | encoder.layer3.1              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 66 | encoder.layer3                | Sequential            |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 67 | encoder.layer4.0.conv1        | Conv2d                | k=(3, 3), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |          1179648 | 18874368 |
| 68 | encoder.layer4.0.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 69 | encoder.layer4.0.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 70 | encoder.layer4.0.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 71 | encoder.layer4.0.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 72 | encoder.layer4.0.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 73 | encoder.layer4.0.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 74 | encoder.layer4.0.downsample.0 | Conv2d                | k=(1, 1), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |           131072 |  2097152 |
| 75 | encoder.layer4.0.downsample.1 | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 76 | encoder.layer4.0.downsample   | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 77 | encoder.layer4.0.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 78 | encoder.layer4.0              | BasicBlock            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 79 | encoder.layer4.1.conv1        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 80 | encoder.layer4.1.bn1          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 81 | encoder.layer4.1.drop_block   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 82 | encoder.layer4.1.act1         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 83 | encoder.layer4.1.aa           | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 84 | encoder.layer4.1.conv2        | Conv2d                | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |          2359296 | 37748736 |
| 85 | encoder.layer4.1.bn2          | BatchNorm2d           |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 86 | encoder.layer4.1.act2         | ReLU                  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 87 | encoder.layer4.1              | BasicBlock            |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 88 | encoder.layer4                | Sequential            |                                                  | (1, 256, 8, 8)   |        16384 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 89 | encoder.global_pool.pool      | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 90 | encoder.global_pool.flatten   | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 91 | encoder.global_pool           | SelectAdaptivePool2d  |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 92 | encoder.fc                    | Identity              |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 93 | encoder                       | ResNet                |                                                  | (1, 3, 32, 32)   |         3072 | (1, 512, 4, 4)   |         8192 |                0 |        0 |
| 94 | classifier.pooling            | AdaptiveAvgPool2d     |                                                  | (1, 512, 4, 4)   |         8192 | (1, 512, 1, 1)   |          512 |                0 |        0 |
| 95 | classifier.flatten            | Flatten               |                                                  | (1, 512, 1, 1)   |          512 | (1, 512)         |          512 |                0 |        0 |
| 96 | classifier.linear             | Linear                |                                                  | (1, 512)         |          512 | (1, 10)          |           10 |             5120 |     5120 |
| 97 | classifier                    | DefaultClassifierHead |                                                  | (1, 512, 4, 4)   |         8192 | (1, 10)          |           10 |                0 |        0 |
+----+-------------------------------+-----------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-05-24 11:15:42,417][hannah.callbacks.summaries][INFO] - Total MACs: 555,422,720
[2024-05-24 11:15:42,417][hannah.callbacks.summaries][INFO] - Total Weights: 11,164,352
[2024-05-24 11:15:42,417][hannah.callbacks.summaries][INFO] - Total Activations: 2,813,972
[2024-05-24 11:15:42,417][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-05-24 11:15:42,418][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-24 11:15:42,418][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-24 11:15:42,981][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-24 11:15:43,089][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-05-24 11:15:43,347][hannah.train][INFO] - Averaged Result Metrics:
| Metric               |     Mean |   Std |   Count |
|----------------------|----------|-------|---------|
| test_classifier_loss | 0.312402 |     0 |       1 |
| test_accuracy        | 0.895733 |     0 |       1 |
| test_error           | 0.104267 |     0 |       1 |
| test_f1              | 0.895025 |     0 |       1 |
| test_precision       | 0.894755 |     0 |       1 |
| test_recall          | 0.895705 |     0 |       1 |
| test_loss            | 0.312402 |     0 |       1 |
[2024-05-24 11:15:43,359][hannah.train][INFO] - Averaged Result Metrics:
| Metric              |     Mean |   Std |   Count |
|---------------------|----------|-------|---------|
| val_classifier_loss | 0.315337 |     0 |       1 |
| val_accuracy        | 0.896434 |     0 |       1 |
| val_error           | 0.103566 |     0 |       1 |
| val_f1              | 0.89519  |     0 |       1 |
| val_precision       | 0.895069 |     0 |       1 |
| val_recall          | 0.895657 |     0 |       1 |
| val_loss            | 0.315337 |     0 |       1 |
