[2024-02-15 12:11:32,717][hannah.utils.utils][INFO] - Environment info:
[2024-02-15 12:11:32,717][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-02-15 12:11:32,717][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-02-15 12:11:32,718][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-02-15 12:11:32,718][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.11.1.el8_9.x86_64
[2024-02-15 12:11:32,718][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-02-15 12:11:32,718][hannah.utils.utils][INFO] -   PyTorch: 2.1.2+cu121
[2024-02-15 12:11:32,718][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.1.3
[2024-02-15 12:11:32,718][hannah.utils.utils][INFO] -   Numpy: 1.23.5
[2024-02-15 12:11:32,718][hannah.utils.utils][INFO] -   Hannah version info:
[2024-02-15 12:11:32,718][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-02-15 12:11:32,718][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train +experiment=sweep_models
[2024-02-15 12:11:32,718][hannah.utils.utils][INFO] -   
[2024-02-15 12:11:32,718][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-02-15 12:11:32,719][root][INFO] - Configuration: 
[2024-02-15 12:11:32,722][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.kakao_resnet.resnet8
  name: kakao_resnet8
  width_multiplier: 1.0
  input_kernel: 3
  input_stride: 1
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
  enable_model_summary: false
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: sweep_models
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-02-15 12:11:32,722][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8
[2024-02-15 12:11:32,728][root][ERROR] - Exception Message: Error locating target 'hannah.modules.vision.ImageClassifierModule', set env var HYDRA_FULL_ERROR=1 to see chained exception.
full_key: module
Traceback (most recent call last):
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 644, in _locate
    obj = getattr(obj, part)
          ^^^^^^^^^^^^^^^^^^
AttributeError: module 'hannah.modules' has no attribute 'vision'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 650, in _locate
    obj = import_module(mod)
          ^^^^^^^^^^^^^^^^^^
  File "/usr/lib64/python3.11/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1147, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/local/gerum/hannah/hannah/modules/vision/__init__.py", line 19, in <module>
    from .anomaly_detection import AnomalyDetectionModule
  File "/local/gerum/hannah/hannah/modules/vision/anomaly_detection.py", line 34, in <module>
    from .base import VisionBaseModule
  File "/local/gerum/hannah/hannah/modules/vision/base.py", line 24, in <module>
    import kornia
ModuleNotFoundError: No module named 'kornia'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 134, in _resolve_target
    target = _locate(target)
             ^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 653, in _locate
    raise ImportError(
ImportError: Error loading 'hannah.modules.vision.ImageClassifierModule':
ModuleNotFoundError("No module named 'kornia'")
Are you sure that 'vision' is importable from module 'hannah.modules'?

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 93, in train
    lit_module = instantiate(
                 ^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 226, in instantiate
    return instantiate_node(
           ^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 333, in instantiate_node
    _target_ = _resolve_target(node.get(_Keys.TARGET), full_key)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 139, in _resolve_target
    raise InstantiationException(msg) from e
hydra.errors.InstantiationException: Error locating target 'hannah.modules.vision.ImageClassifierModule', set env var HYDRA_FULL_ERROR=1 to see chained exception.
full_key: module
[2024-02-15 13:03:41,363][hannah.utils.utils][INFO] - Environment info:
[2024-02-15 13:03:41,363][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-02-15 13:03:41,363][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-02-15 13:03:41,363][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-02-15 13:03:41,363][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.11.1.el8_9.x86_64
[2024-02-15 13:03:41,363][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-02-15 13:03:41,363][hannah.utils.utils][INFO] -   PyTorch: 2.1.2+cu121
[2024-02-15 13:03:41,363][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.1.3
[2024-02-15 13:03:41,363][hannah.utils.utils][INFO] -   Numpy: 1.23.5
[2024-02-15 13:03:41,363][hannah.utils.utils][INFO] -   Hannah version info:
[2024-02-15 13:03:41,363][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-02-15 13:03:41,364][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train +experiment=sweep_models
[2024-02-15 13:03:41,364][hannah.utils.utils][INFO] -   
[2024-02-15 13:03:41,364][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-02-15 13:03:41,364][root][INFO] - Configuration: 
[2024-02-15 13:03:41,367][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.kakao_resnet.resnet8
  name: kakao_resnet8
  width_multiplier: 1.0
  input_kernel: 3
  input_stride: 1
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
  enable_model_summary: false
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: sweep_models
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-02-15 13:03:41,367][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8
[2024-02-15 13:03:41,374][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-02-15 13:03:41,374][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-02-15 13:03:41,378][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:558: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-02-15 13:03:41,379][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-02-15 13:03:41,385][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-02-15 13:03:41,385][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-02-15 13:03:41,385][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-02-15 13:03:41,385][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-02-15 13:03:41,385][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-02-15 13:03:41,385][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-02-15 13:03:41,385][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-02-15 13:03:41,385][root][INFO] - Starting training
[2024-02-15 13:03:42,627][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:66: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-02-15 13:03:42,628][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-02-15 13:03:42,628][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-02-15 13:03:42,628][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-02-15 13:03:42,628][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-02-15 13:03:42,628][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-02-15 13:03:42,628][hannah.modules.vision.base][INFO] - Setting up model kakao_resnet8
[2024-02-15 13:03:42,665][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)
[2024-02-15 13:03:42,670][hannah.modules.vision.base][INFO] - Running dummy forward to initialize lazy modules
[2024-02-15 13:03:42,946][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-02-15 13:03:42,947][pytorch_lightning.utilities.rank_zero][INFO] - Loading `train_dataloader` to estimate number of stepping batches.
[2024-02-15 13:03:42,947][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=191` in the `DataLoader` to improve performance.

[2024-02-15 13:03:42,956][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

[2024-02-15 13:03:43,183][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=191` in the `DataLoader` to improve performance.

[2024-02-15 13:03:43,507][hannah.callbacks.summaries][INFO] - 
+----+--------------+-------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name         | Type              | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+--------------+-------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | 0.0          | Conv2d            | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | 0.1          | BatchNorm2d       |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | 0.2          | ReLU              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | 0            | Sequential        |                                                  | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | 1.0          | Conv2d            | k=(5, 5), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |           204800 | 52428800 |
|  5 | 1.1          | BatchNorm2d       |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
|  6 | 1.2          | ReLU              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
|  7 | 1            | Sequential        |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
|  8 | 2.module.0.0 | Conv2d            | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
|  9 | 2.module.0.1 | BatchNorm2d       |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 10 | 2.module.0.2 | ReLU              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 11 | 2.module.0   | Sequential        |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 12 | 2.module.1.0 | Conv2d            | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 13 | 2.module.1.1 | BatchNorm2d       |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 14 | 2.module.1.2 | ReLU              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 15 | 2.module.1   | Sequential        |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 16 | 2.module     | Sequential        |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 17 | 2            | Residual          |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 18 | 3.0          | Conv2d            | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 16, 16) |        65536 |           294912 | 75497472 |
| 19 | 3.1          | BatchNorm2d       |                                                  | (1, 256, 16, 16) |        65536 | (1, 256, 16, 16) |        65536 |                0 |        0 |
| 20 | 3.2          | ReLU              |                                                  | (1, 256, 16, 16) |        65536 | (1, 256, 16, 16) |        65536 |                0 |        0 |
| 21 | 3            | Sequential        |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 16, 16) |        65536 |                0 |        0 |
| 22 | 4            | MaxPool2d         |                                                  | (1, 256, 16, 16) |        65536 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 23 | 5.module.0.0 | Conv2d            | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 24 | 5.module.0.1 | BatchNorm2d       |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 25 | 5.module.0.2 | ReLU              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 26 | 5.module.0   | Sequential        |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 27 | 5.module.1.0 | Conv2d            | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 28 | 5.module.1.1 | BatchNorm2d       |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 29 | 5.module.1.2 | ReLU              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 30 | 5.module.1   | Sequential        |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 31 | 5.module     | Sequential        |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 32 | 5            | Residual          |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 33 | 6.0          | Conv2d            | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 128, 6, 6)   |         4608 |           294912 | 10616832 |
| 34 | 6.1          | BatchNorm2d       |                                                  | (1, 128, 6, 6)   |         4608 | (1, 128, 6, 6)   |         4608 |                0 |        0 |
| 35 | 6.2          | ReLU              |                                                  | (1, 128, 6, 6)   |         4608 | (1, 128, 6, 6)   |         4608 |                0 |        0 |
| 36 | 6            | Sequential        |                                                  | (1, 256, 8, 8)   |        16384 | (1, 128, 6, 6)   |         4608 |                0 |        0 |
| 37 | 7            | AdaptiveMaxPool2d |                                                  | (1, 128, 6, 6)   |         4608 | (1, 128, 1, 1)   |          128 |                0 |        0 |
| 38 | 8            | Flatten           |                                                  | (1, 128, 1, 1)   |          128 | (1, 128)         |          128 |                0 |        0 |
| 39 | 9            | Linear            |                                                  | (1, 128)         |          128 | (1, 10)          |           10 |             1280 |     1280 |
| 40 | 10           | Mul               |                                                  | (1, 10)          |           10 | (1, 10)          |           10 |                0 |        0 |
+----+--------------+-------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-02-15 13:03:43,507][hannah.callbacks.summaries][INFO] - Total MACs: 291,308,800
[2024-02-15 13:03:43,507][hannah.callbacks.summaries][INFO] - Total Weights: 2,272,192
[2024-02-15 13:03:43,507][hannah.callbacks.summaries][INFO] - Total Activations: 1,185,044
[2024-02-15 13:03:43,507][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-02-15 13:03:46,332][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/autograd/__init__.py:251: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:71.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass

[2024-02-15 13:04:26,904][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 0, global step 21: 'val_error' reached 0.79761 (best 0.79761), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=0-step=21.ckpt' as top 1
[2024-02-15 13:05:02,955][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 1, global step 42: 'val_error' reached 0.66895 (best 0.66895), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=1-step=42.ckpt' as top 1
[2024-02-15 13:05:38,835][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 2, global step 63: 'val_error' reached 0.60034 (best 0.60034), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=2-step=63.ckpt' as top 1
[2024-02-15 13:06:08,440][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 3, global step 84: 'val_error' was not in top 1
[2024-02-15 13:06:33,011][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 4, global step 105: 'val_error' reached 0.53320 (best 0.53320), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=4-step=105.ckpt' as top 1
[2024-02-15 13:06:57,531][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 5, global step 126: 'val_error' reached 0.44336 (best 0.44336), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=5-step=126.ckpt' as top 1
[2024-02-15 13:07:18,566][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 6, global step 147: 'val_error' was not in top 1
[2024-02-15 13:07:47,358][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 7, global step 168: 'val_error' reached 0.37061 (best 0.37061), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=7-step=168.ckpt' as top 1
[2024-02-15 13:08:18,721][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 8, global step 189: 'val_error' was not in top 1
[2024-02-15 13:08:49,156][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 9, global step 210: 'val_error' reached 0.35938 (best 0.35938), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=9-step=210.ckpt' as top 1
[2024-02-15 13:09:21,568][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 10, global step 231: 'val_error' was not in top 1
[2024-02-15 13:09:54,490][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 11, global step 252: 'val_error' reached 0.26245 (best 0.26245), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=11-step=252.ckpt' as top 1
[2024-02-15 13:10:23,015][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 12, global step 273: 'val_error' reached 0.22803 (best 0.22803), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=12-step=273.ckpt' as top 1
[2024-02-15 13:10:44,257][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 13, global step 294: 'val_error' reached 0.21021 (best 0.21021), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=13-step=294.ckpt' as top 1
[2024-02-15 13:11:01,938][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 14, global step 315: 'val_error' reached 0.20557 (best 0.20557), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=14-step=315.ckpt' as top 1
[2024-02-15 13:11:32,764][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 15, global step 336: 'val_error' was not in top 1
[2024-02-15 13:12:05,013][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 16, global step 357: 'val_error' was not in top 1
[2024-02-15 13:12:35,484][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 17, global step 378: 'val_error' was not in top 1
[2024-02-15 13:13:04,815][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 18, global step 399: 'val_error' was not in top 1
[2024-02-15 13:13:32,838][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 19, global step 420: 'val_error' reached 0.17334 (best 0.17334), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=19-step=420.ckpt' as top 1
[2024-02-15 13:13:53,327][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 20, global step 441: 'val_error' reached 0.16431 (best 0.16431), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=20-step=441.ckpt' as top 1
[2024-02-15 13:14:13,990][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 21, global step 462: 'val_error' reached 0.15698 (best 0.15698), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=21-step=462.ckpt' as top 1
[2024-02-15 13:14:35,129][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 22, global step 483: 'val_error' reached 0.14551 (best 0.14551), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=22-step=483.ckpt' as top 1
[2024-02-15 13:14:55,801][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 23, global step 504: 'val_error' was not in top 1
[2024-02-15 13:15:23,321][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 24, global step 525: 'val_error' was not in top 1
[2024-02-15 13:15:52,809][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 25, global step 546: 'val_error' was not in top 1
[2024-02-15 13:16:24,486][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 26, global step 567: 'val_error' reached 0.13208 (best 0.13208), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=26-step=567.ckpt' as top 1
[2024-02-15 13:16:57,416][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 27, global step 588: 'val_error' was not in top 1
[2024-02-15 13:17:29,926][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 28, global step 609: 'val_error' was not in top 1
[2024-02-15 13:17:57,013][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 29, global step 630: 'val_error' was not in top 1
[2024-02-15 13:18:19,308][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 30, global step 651: 'val_error' reached 0.13184 (best 0.13184), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=30-step=651.ckpt' as top 1
[2024-02-15 13:18:40,936][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 31, global step 672: 'val_error' was not in top 1
[2024-02-15 13:19:03,137][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 32, global step 693: 'val_error' reached 0.12817 (best 0.12817), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=32-step=693.ckpt' as top 1
[2024-02-15 13:19:27,367][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 33, global step 714: 'val_error' reached 0.11450 (best 0.11450), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=33-step=714.ckpt' as top 1
[2024-02-15 13:20:01,730][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 34, global step 735: 'val_error' was not in top 1
[2024-02-15 13:20:34,516][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 35, global step 756: 'val_error' was not in top 1
[2024-02-15 13:21:10,739][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 36, global step 777: 'val_error' reached 0.11230 (best 0.11230), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=36-step=777.ckpt' as top 1
[2024-02-15 13:21:48,243][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 37, global step 798: 'val_error' reached 0.11133 (best 0.11133), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=37-step=798.ckpt' as top 1
[2024-02-15 13:22:22,747][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 38, global step 819: 'val_error' was not in top 1
[2024-02-15 13:22:48,121][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 39, global step 840: 'val_error' reached 0.10425 (best 0.10425), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=39-step=840.ckpt' as top 1
[2024-02-15 13:23:07,363][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 40, global step 861: 'val_error' reached 0.09937 (best 0.09937), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=40-step=861.ckpt' as top 1
[2024-02-15 13:23:26,960][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 41, global step 882: 'val_error' was not in top 1
[2024-02-15 13:23:42,919][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 42, global step 903: 'val_error' reached 0.09009 (best 0.09009), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=42-step=903.ckpt' as top 1
[2024-02-15 13:24:12,345][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 43, global step 924: 'val_error' reached 0.08643 (best 0.08643), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=43-step=924.ckpt' as top 1
[2024-02-15 13:24:42,742][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 44, global step 945: 'val_error' reached 0.08398 (best 0.08398), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=44-step=945.ckpt' as top 1
[2024-02-15 13:25:11,490][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 45, global step 966: 'val_error' reached 0.08154 (best 0.08154), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=45-step=966.ckpt' as top 1
[2024-02-15 13:25:39,654][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 46, global step 987: 'val_error' reached 0.08057 (best 0.08057), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=46-step=987.ckpt' as top 1
[2024-02-15 13:26:08,404][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 47, global step 1008: 'val_error' reached 0.07886 (best 0.07886), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=47-step=1008.ckpt' as top 1
[2024-02-15 13:26:33,087][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 48, global step 1029: 'val_error' was not in top 1
[2024-02-15 13:26:50,757][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 49, global step 1050: 'val_error' reached 0.07861 (best 0.07861), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=49-step=1050.ckpt' as top 1
[2024-02-15 13:26:50,791][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer.fit` stopped: `max_epochs=50` reached.
[2024-02-15 13:26:50,898][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-02-15 13:26:50,898][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-02-15 13:26:50,900][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=49-step=1050.ckpt
[2024-02-15 13:26:50,953][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-02-15 13:26:51,132][pytorch_lightning.utilities.rank_zero][INFO] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=49-step=1050.ckpt
[2024-02-15 13:26:51,379][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-02-15 13:26:51,379][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-02-15 13:26:51,380][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=49-step=1050.ckpt
[2024-02-15 13:26:51,396][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-02-15 13:26:51,585][pytorch_lightning.utilities.rank_zero][INFO] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=49-step=1050.ckpt
[2024-02-15 13:26:51,586][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=191` in the `DataLoader` to improve performance.

[2024-02-15 13:26:52,008][hannah.callbacks.summaries][INFO] - 
+----+--------------+-------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name         | Type              | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+--------------+-------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | 0.0          | Conv2d            | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | 0.1          | BatchNorm2d       |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | 0.2          | ReLU              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | 0            | Sequential        |                                                  | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | 1.0          | Conv2d            | k=(5, 5), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |           204800 | 52428800 |
|  5 | 1.1          | BatchNorm2d       |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
|  6 | 1.2          | ReLU              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
|  7 | 1            | Sequential        |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
|  8 | 2.module.0.0 | Conv2d            | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
|  9 | 2.module.0.1 | BatchNorm2d       |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 10 | 2.module.0.2 | ReLU              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 11 | 2.module.0   | Sequential        |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 12 | 2.module.1.0 | Conv2d            | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 13 | 2.module.1.1 | BatchNorm2d       |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 14 | 2.module.1.2 | ReLU              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 15 | 2.module.1   | Sequential        |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 16 | 2.module     | Sequential        |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 17 | 2            | Residual          |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 18 | 3.0          | Conv2d            | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 16, 16) |        65536 |           294912 | 75497472 |
| 19 | 3.1          | BatchNorm2d       |                                                  | (1, 256, 16, 16) |        65536 | (1, 256, 16, 16) |        65536 |                0 |        0 |
| 20 | 3.2          | ReLU              |                                                  | (1, 256, 16, 16) |        65536 | (1, 256, 16, 16) |        65536 |                0 |        0 |
| 21 | 3            | Sequential        |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 16, 16) |        65536 |                0 |        0 |
| 22 | 4            | MaxPool2d         |                                                  | (1, 256, 16, 16) |        65536 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 23 | 5.module.0.0 | Conv2d            | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 24 | 5.module.0.1 | BatchNorm2d       |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 25 | 5.module.0.2 | ReLU              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 26 | 5.module.0   | Sequential        |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 27 | 5.module.1.0 | Conv2d            | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 28 | 5.module.1.1 | BatchNorm2d       |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 29 | 5.module.1.2 | ReLU              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 30 | 5.module.1   | Sequential        |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 31 | 5.module     | Sequential        |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 32 | 5            | Residual          |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 33 | 6.0          | Conv2d            | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 128, 6, 6)   |         4608 |           294912 | 10616832 |
| 34 | 6.1          | BatchNorm2d       |                                                  | (1, 128, 6, 6)   |         4608 | (1, 128, 6, 6)   |         4608 |                0 |        0 |
| 35 | 6.2          | ReLU              |                                                  | (1, 128, 6, 6)   |         4608 | (1, 128, 6, 6)   |         4608 |                0 |        0 |
| 36 | 6            | Sequential        |                                                  | (1, 256, 8, 8)   |        16384 | (1, 128, 6, 6)   |         4608 |                0 |        0 |
| 37 | 7            | AdaptiveMaxPool2d |                                                  | (1, 128, 6, 6)   |         4608 | (1, 128, 1, 1)   |          128 |                0 |        0 |
| 38 | 8            | Flatten           |                                                  | (1, 128, 1, 1)   |          128 | (1, 128)         |          128 |                0 |        0 |
| 39 | 9            | Linear            |                                                  | (1, 128)         |          128 | (1, 10)          |           10 |             1280 |     1280 |
| 40 | 10           | Mul               |                                                  | (1, 10)          |           10 | (1, 10)          |           10 |                0 |        0 |
+----+--------------+-------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-02-15 13:26:52,009][hannah.callbacks.summaries][INFO] - Total MACs: 291,308,800
[2024-02-15 13:26:52,009][hannah.callbacks.summaries][INFO] - Total Weights: 2,272,192
[2024-02-15 13:26:52,009][hannah.callbacks.summaries][INFO] - Total Activations: 1,185,044
[2024-02-15 13:26:52,009][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-02-15 13:26:52,010][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-02-15 13:26:52,010][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-02-15 13:26:52,278][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: The ``compute`` method of metric MulticlassROC was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.
  warnings.warn(*args, **kwargs)  # noqa: B028

[2024-02-15 13:26:52,280][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-02-15 13:26:52,377][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: The ``compute`` method of metric MulticlassPrecisionRecallCurve was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.
  warnings.warn(*args, **kwargs)  # noqa: B028

[2024-02-15 13:26:52,378][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-02-15 13:26:52,512][hannah.train][INFO] - Averaged Result Metrics:
| Metric               |      Mean |   Std |   Count |
|----------------------|-----------|-------|---------|
| test_classifier_loss | 0.224195  |     0 |       1 |
| test_accuracy        | 0.922852  |     0 |       1 |
| test_error           | 0.0771484 |     0 |       1 |
| test_f1              | 0.923068  |     0 |       1 |
| test_precision       | 0.923175  |     0 |       1 |
| test_recall          | 0.92305   |     0 |       1 |
| test_loss            | 0.224195  |     0 |       1 |
[2024-02-15 13:26:52,524][hannah.train][INFO] - Averaged Result Metrics:
| Metric              |      Mean |   Std |   Count |
|---------------------|-----------|-------|---------|
| val_classifier_loss | 0.240081  |     0 |       1 |
| val_accuracy        | 0.921387  |     0 |       1 |
| val_error           | 0.0786133 |     0 |       1 |
| val_f1              | 0.920942  |     0 |       1 |
| val_precision       | 0.921227  |     0 |       1 |
| val_recall          | 0.920908  |     0 |       1 |
| val_loss            | 0.240081  |     0 |       1 |
[2024-02-29 14:21:21,599][hannah.utils.utils][INFO] - Environment info:
[2024-02-29 14:21:21,599][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-02-29 14:21:21,599][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-02-29 14:21:21,599][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-02-29 14:21:21,599][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.11.1.el8_9.x86_64
[2024-02-29 14:21:21,599][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-02-29 14:21:21,599][hannah.utils.utils][INFO] -   PyTorch: 2.1.2+cu121
[2024-02-29 14:21:21,599][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.1.3
[2024-02-29 14:21:21,599][hannah.utils.utils][INFO] -   Numpy: 1.23.5
[2024-02-29 14:21:21,599][hannah.utils.utils][INFO] -   Hannah version info:
[2024-02-29 14:21:21,599][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-02-29 14:21:21,599][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train +experiment=sweep_models
[2024-02-29 14:21:21,599][hannah.utils.utils][INFO] -   
[2024-02-29 14:21:21,600][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-02-29 14:21:21,604][root][INFO] - Configuration: 
[2024-02-29 14:21:21,607][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.kakao_resnet.resnet8
  name: kakao_resnet8
  width_multiplier: 1.0
  input_kernel: 3
  input_stride: 1
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
  enable_model_summary: false
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: sweep_models
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-02-29 14:21:21,607][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8
[2024-02-29 14:21:21,612][root][ERROR] - Exception Message: Error locating target 'hannah.modules.vision.ImageClassifierModule', set env var HYDRA_FULL_ERROR=1 to see chained exception.
full_key: module
Traceback (most recent call last):
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 644, in _locate
    obj = getattr(obj, part)
          ^^^^^^^^^^^^^^^^^^
AttributeError: module 'hannah' has no attribute 'modules'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/local/gerum/hannah/external/hannah-tvm/external/tvm/python/tvm/micro/session.py", line 40, in <module>
    from .base import _rpc_connect
ImportError: cannot import name '_rpc_connect' from 'tvm.micro.base' (/local/gerum/hannah/external/hannah-tvm/external/tvm/python/tvm/micro/base.py)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 650, in _locate
    obj = import_module(mod)
          ^^^^^^^^^^^^^^^^^^
  File "/usr/lib64/python3.11/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1147, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/local/gerum/hannah/hannah/modules/__init__.py", line 19, in <module>
    from .angle_classifier import (
  File "/local/gerum/hannah/hannah/modules/angle_classifier.py", line 44, in <module>
    from .classifier import StreamClassifierModule
  File "/local/gerum/hannah/hannah/modules/classifier.py", line 51, in <module>
    from .base import ClassifierModule
  File "/local/gerum/hannah/hannah/modules/base.py", line 46, in <module>
    from hannah_tvm.backend import export_relay
  File "/local/gerum/hannah/external/hannah-tvm/hannah_tvm/backend.py", line 31, in <module>
    from tvm.micro.testing.aot_test_utils import AOT_DEFAULT_RUNNER
  File "/local/gerum/hannah/external/hannah-tvm/external/tvm/python/tvm/micro/__init__.py", line 29, in <module>
    from .session import (
  File "/local/gerum/hannah/external/hannah-tvm/external/tvm/python/tvm/micro/session.py", line 42, in <module>
    raise ImportError("micro tvm is not enabled. Set USE_MICRO to ON in config.cmake")
ImportError: micro tvm is not enabled. Set USE_MICRO to ON in config.cmake

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 134, in _resolve_target
    target = _locate(target)
             ^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/utils.py", line 658, in _locate
    raise ImportError(
ImportError: Error loading 'hannah.modules.vision.ImageClassifierModule':
ImportError('micro tvm is not enabled. Set USE_MICRO to ON in config.cmake')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/local/gerum/hannah/hannah/tools/train.py", line 44, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/local/gerum/hannah/hannah/train.py", line 93, in train
    lit_module = instantiate(
                 ^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 226, in instantiate
    return instantiate_node(
           ^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 333, in instantiate_node
    _target_ = _resolve_target(node.get(_Keys.TARGET), full_key)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 139, in _resolve_target
    raise InstantiationException(msg) from e
hydra.errors.InstantiationException: Error locating target 'hannah.modules.vision.ImageClassifierModule', set env var HYDRA_FULL_ERROR=1 to see chained exception.
full_key: module
[2024-03-11 13:42:08,783][hannah.utils.utils][INFO] - Environment info:
[2024-03-11 13:42:08,783][hannah.utils.utils][INFO] -   Number of GPUs: 2
[2024-03-11 13:42:08,783][hannah.utils.utils][INFO] -   CUDA version: 12.1
[2024-03-11 13:42:08,783][hannah.utils.utils][INFO] -   CUDNN version: 8907
[2024-03-11 13:42:08,783][hannah.utils.utils][INFO] -   Kernel: 4.18.0-513.11.1.el8_9.x86_64
[2024-03-11 13:42:08,783][hannah.utils.utils][INFO] -   Python: 3.11.5 (main, Nov 15 2023, 03:52:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-20)]
[2024-03-11 13:42:08,783][hannah.utils.utils][INFO] -   PyTorch: 2.1.2+cu121
[2024-03-11 13:42:08,783][hannah.utils.utils][INFO] -   Pytorch Lightning: 2.1.3
[2024-03-11 13:42:08,783][hannah.utils.utils][INFO] -   Numpy: 1.23.5
[2024-03-11 13:42:08,783][hannah.utils.utils][INFO] -   Hannah version info:
[2024-03-11 13:42:08,783][hannah.utils.utils][INFO] -     Cannot find a Git repository.  You probably downloaded an archive
[2024-03-11 13:42:08,783][hannah.utils.utils][INFO] -   Command line: /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/bin/hannah-train +experiment=sweep_models
[2024-03-11 13:42:08,784][hannah.utils.utils][INFO] -   
[2024-03-11 13:42:08,784][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-03-11 13:42:08,784][root][INFO] - Configuration: 
[2024-03-11 13:42:08,787][root][INFO] - dataset:
  data_folder: ${hydra:runtime.cwd}/datasets/
  cls: hannah.datasets.vision.Cifar10Dataset
  dataset: cifar10
  val_percent: 0.1
features:
  _target_: torch.nn.Identity
model:
  _target_: hannah.models.kakao_resnet.resnet8
  name: kakao_resnet8
  width_multiplier: 1.0
  input_kernel: 3
  input_stride: 1
scheduler:
  _target_: torch.optim.lr_scheduler.OneCycleLR
  max_lr: ${optimizer.lr}
  pct_start: 0.3
  anneal_strategy: cos
  cycle_momentum: true
  base_momentum: 0.85
  max_momentum: 0.95
  div_factor: 25.0
  final_div_factor: 10000.0
  last_epoch: -1
optimizer:
  _target_: torch.optim.sgd.SGD
  lr: 0.3
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: false
module:
  _target_: hannah.modules.vision.ImageClassifierModule
  num_workers: 0
  batch_size: 2048
  shuffle_all_dataloaders: false
trainer:
  _target_: pytorch_lightning.trainer.Trainer
  accelerator: auto
  devices: 1
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 50
  default_root_dir: .
  fast_dev_run: false
  overfit_batches: 0.0
  benchmark: false
  deterministic: warn
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  plugins: null
  strategy: auto
  reload_dataloaders_every_n_epochs: 0
  precision: 16
checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  save_top_k: 1
  verbose: true
  monitor: val_error
  mode: min
  save_last: true
augmentation:
  batch_augment:
    pipeline: null
    transforms:
      RandomHorizontalFlip:
        p: 0.5
      RandomAffine:
        degrees:
        - -15
        - 15
        translate:
        - 0.1
        - 0.1
        scale:
        - 0.9
        - 1.1
        shear:
        - -5
        - 5
        p: 0.5
      RandomCrop:
        size:
        - 32
        - 32
        padding: 4
      RandomErasing:
        p: 0.5
experiment_id: sweep_models
output_dir: trained_models
auto_lr: false
resume: false
fx_mac_summary: false
skip_test: false
skip_val: false
seed:
- 1234
validate_output: false
monitor:
  metric: val_accuracy
  direction: maximize

[2024-03-11 13:42:08,787][root][INFO] - Current working directory /local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8
[2024-03-11 13:42:08,793][hannah.callbacks.optimization][INFO] - Monitoring the following values for optimization
[2024-03-11 13:42:08,793][hannah.callbacks.optimization][INFO] -   - val_accuracy direction: maximize(-1)
[2024-03-11 13:42:08,796][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/lightning_fabric/connector.py:558: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!

[2024-03-11 13:42:08,796][pytorch_lightning.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)
[2024-03-11 13:42:08,803][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2024-03-11 13:42:08,803][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-03-11 13:42:08,803][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-03-11 13:42:08,803][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-03-11 13:42:08,803][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
[2024-03-11 13:42:08,803][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2024-03-11 13:42:08,803][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..
[2024-03-11 13:42:08,804][root][INFO] - Starting training
[2024-03-11 13:42:09,997][py.warnings][WARNING] - /local/gerum/hannah/hannah/modules/vision/base.py:66: UserWarning: Vision datasets should return a length 4 tuple, will assume unlabeled data is None
  warnings.warn(

[2024-03-11 13:42:09,998][hannah.modules.vision.base][INFO] - Dataset lengths:
[2024-03-11 13:42:09,998][hannah.modules.vision.base][INFO] -   Train Set (Labeled): 45000
[2024-03-11 13:42:09,998][hannah.modules.vision.base][INFO] -   Train Set (Unlabled): 0
[2024-03-11 13:42:09,998][hannah.modules.vision.base][INFO] -   Dev Set: 5000
[2024-03-11 13:42:09,998][hannah.modules.vision.base][INFO] -   Test Set: 10000
[2024-03-11 13:42:09,998][hannah.modules.vision.base][INFO] - Setting up model kakao_resnet8
[2024-03-11 13:42:10,022][hannah.modules.vision.base][INFO] - Instantiating input Normalizer with mean: (0.491, 0.482, 0.446), std: (0.247, 0.243, 0.261)
[2024-03-11 13:42:10,027][hannah.modules.vision.base][INFO] - Running dummy forward to initialize lazy modules
[2024-03-11 13:42:10,038][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-03-11 13:42:10,039][pytorch_lightning.utilities.rank_zero][INFO] - Loading `train_dataloader` to estimate number of stepping batches.
[2024-03-11 13:42:10,040][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=191` in the `DataLoader` to improve performance.

[2024-03-11 13:42:10,040][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

[2024-03-11 13:42:10,056][pytorch_lightning.callbacks.model_summary][INFO] - 
   | Name                 | Type                           | Params | In sizes       | Out sizes
------------------------------------------------------------------------------------------------------
0  | val_metrics          | MetricCollection               | 0      | ?              | ?        
1  | test_metrics         | MetricCollection               | 0      | ?              | ?        
2  | train_metrics        | MetricCollection               | 0      | ?              | ?        
3  | model                | Sequential                     | 2.3 M  | [1, 3, 32, 32] | [1, 10]  
4  | input_normalizer     | Normalize                      | 0      | ?              | ?        
5  | default_augmentation | Sequential                     | 0      | ?              | ?        
6  | augmentations        | ModuleDict                     | 0      | ?              | ?        
7  | test_confusion       | MulticlassConfusionMatrix      | 0      | ?              | ?        
8  | test_roc             | MulticlassROC                  | 0      | ?              | ?        
9  | test_pr_curve        | MulticlassPrecisionRecallCurve | 0      | ?              | ?        
10 | metrics              | ModuleDict                     | 0      | ?              | ?        
------------------------------------------------------------------------------------------------------
2.3 M     Trainable params
0         Non-trainable params
2.3 M     Total params
9.100     Total estimated model params size (MB)
[2024-03-11 13:42:10,243][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=191` in the `DataLoader` to improve performance.

[2024-03-11 13:42:10,446][hannah.callbacks.summaries][INFO] - 
+----+--------------+-------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name         | Type              | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+--------------+-------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | 0.0          | Conv2d            | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | 0.1          | BatchNorm2d       |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | 0.2          | ReLU              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | 0            | Sequential        |                                                  | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | 1.0          | Conv2d            | k=(5, 5), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |           204800 | 52428800 |
|  5 | 1.1          | BatchNorm2d       |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
|  6 | 1.2          | ReLU              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
|  7 | 1            | Sequential        |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
|  8 | 2.module.0.0 | Conv2d            | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
|  9 | 2.module.0.1 | BatchNorm2d       |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 10 | 2.module.0.2 | ReLU              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 11 | 2.module.0   | Sequential        |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 12 | 2.module.1.0 | Conv2d            | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 13 | 2.module.1.1 | BatchNorm2d       |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 14 | 2.module.1.2 | ReLU              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 15 | 2.module.1   | Sequential        |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 16 | 2.module     | Sequential        |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 17 | 2            | Residual          |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 18 | 3.0          | Conv2d            | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 16, 16) |        65536 |           294912 | 75497472 |
| 19 | 3.1          | BatchNorm2d       |                                                  | (1, 256, 16, 16) |        65536 | (1, 256, 16, 16) |        65536 |                0 |        0 |
| 20 | 3.2          | ReLU              |                                                  | (1, 256, 16, 16) |        65536 | (1, 256, 16, 16) |        65536 |                0 |        0 |
| 21 | 3            | Sequential        |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 16, 16) |        65536 |                0 |        0 |
| 22 | 4            | MaxPool2d         |                                                  | (1, 256, 16, 16) |        65536 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 23 | 5.module.0.0 | Conv2d            | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 24 | 5.module.0.1 | BatchNorm2d       |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 25 | 5.module.0.2 | ReLU              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 26 | 5.module.0   | Sequential        |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 27 | 5.module.1.0 | Conv2d            | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 28 | 5.module.1.1 | BatchNorm2d       |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 29 | 5.module.1.2 | ReLU              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 30 | 5.module.1   | Sequential        |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 31 | 5.module     | Sequential        |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 32 | 5            | Residual          |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 33 | 6.0          | Conv2d            | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 128, 6, 6)   |         4608 |           294912 | 10616832 |
| 34 | 6.1          | BatchNorm2d       |                                                  | (1, 128, 6, 6)   |         4608 | (1, 128, 6, 6)   |         4608 |                0 |        0 |
| 35 | 6.2          | ReLU              |                                                  | (1, 128, 6, 6)   |         4608 | (1, 128, 6, 6)   |         4608 |                0 |        0 |
| 36 | 6            | Sequential        |                                                  | (1, 256, 8, 8)   |        16384 | (1, 128, 6, 6)   |         4608 |                0 |        0 |
| 37 | 7            | AdaptiveMaxPool2d |                                                  | (1, 128, 6, 6)   |         4608 | (1, 128, 1, 1)   |          128 |                0 |        0 |
| 38 | 8            | Flatten           |                                                  | (1, 128, 1, 1)   |          128 | (1, 128)         |          128 |                0 |        0 |
| 39 | 9            | Linear            |                                                  | (1, 128)         |          128 | (1, 10)          |           10 |             1280 |     1280 |
| 40 | 10           | Mul               |                                                  | (1, 10)          |           10 | (1, 10)          |           10 |                0 |        0 |
+----+--------------+-------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-03-11 13:42:10,447][hannah.callbacks.summaries][INFO] - Total MACs: 291,308,800
[2024-03-11 13:42:10,447][hannah.callbacks.summaries][INFO] - Total Weights: 2,272,192
[2024-03-11 13:42:10,447][hannah.callbacks.summaries][INFO] - Total Activations: 1,185,044
[2024-03-11 13:42:10,447][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-03-11 13:42:10,936][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib64/python3.11/site-packages/torch/autograd/__init__.py:251: UserWarning: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at ../aten/src/ATen/Context.cpp:71.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass

[2024-03-11 13:42:21,415][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 0, global step 21: 'val_error' reached 0.79761 (best 0.79761), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=0-step=21.ckpt' as top 1
[2024-03-11 13:42:32,292][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 1, global step 42: 'val_error' reached 0.66895 (best 0.66895), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=1-step=42.ckpt' as top 1
[2024-03-11 13:42:43,400][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 2, global step 63: 'val_error' reached 0.60034 (best 0.60034), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=2-step=63.ckpt' as top 1
[2024-03-11 13:42:54,282][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 3, global step 84: 'val_error' was not in top 1
[2024-03-11 13:43:05,417][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 4, global step 105: 'val_error' reached 0.53320 (best 0.53320), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=4-step=105.ckpt' as top 1
[2024-03-11 13:43:16,298][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 5, global step 126: 'val_error' reached 0.44336 (best 0.44336), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=5-step=126.ckpt' as top 1
[2024-03-11 13:43:27,413][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 6, global step 147: 'val_error' was not in top 1
[2024-03-11 13:43:38,305][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 7, global step 168: 'val_error' reached 0.37061 (best 0.37061), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=7-step=168.ckpt' as top 1
[2024-03-11 13:43:49,407][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 8, global step 189: 'val_error' was not in top 1
[2024-03-11 13:44:00,497][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 9, global step 210: 'val_error' reached 0.35938 (best 0.35938), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=9-step=210.ckpt' as top 1
[2024-03-11 13:44:11,360][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 10, global step 231: 'val_error' was not in top 1
[2024-03-11 13:44:22,399][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 11, global step 252: 'val_error' reached 0.26245 (best 0.26245), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=11-step=252.ckpt' as top 1
[2024-03-11 13:44:33,268][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 12, global step 273: 'val_error' reached 0.22803 (best 0.22803), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=12-step=273.ckpt' as top 1
[2024-03-11 13:44:44,378][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 13, global step 294: 'val_error' reached 0.21021 (best 0.21021), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=13-step=294.ckpt' as top 1
[2024-03-11 13:44:55,271][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 14, global step 315: 'val_error' reached 0.20557 (best 0.20557), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=14-step=315.ckpt' as top 1
[2024-03-11 13:45:06,324][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 15, global step 336: 'val_error' was not in top 1
[2024-03-11 13:45:17,397][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 16, global step 357: 'val_error' was not in top 1
[2024-03-11 13:45:28,204][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 17, global step 378: 'val_error' was not in top 1
[2024-03-11 13:45:39,260][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 18, global step 399: 'val_error' was not in top 1
[2024-03-11 13:45:50,103][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 19, global step 420: 'val_error' reached 0.17334 (best 0.17334), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=19-step=420.ckpt' as top 1
[2024-03-11 13:46:01,194][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 20, global step 441: 'val_error' reached 0.16431 (best 0.16431), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=20-step=441.ckpt' as top 1
[2024-03-11 13:46:12,072][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 21, global step 462: 'val_error' reached 0.15698 (best 0.15698), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=21-step=462.ckpt' as top 1
[2024-03-11 13:46:23,121][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 22, global step 483: 'val_error' reached 0.14551 (best 0.14551), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=22-step=483.ckpt' as top 1
[2024-03-11 13:46:34,214][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 23, global step 504: 'val_error' was not in top 1
[2024-03-11 13:46:45,041][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 24, global step 525: 'val_error' was not in top 1
[2024-03-11 13:46:56,083][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 25, global step 546: 'val_error' was not in top 1
[2024-03-11 13:47:06,920][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 26, global step 567: 'val_error' reached 0.13208 (best 0.13208), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=26-step=567.ckpt' as top 1
[2024-03-11 13:47:18,002][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 27, global step 588: 'val_error' was not in top 1
[2024-03-11 13:47:29,055][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 28, global step 609: 'val_error' was not in top 1
[2024-03-11 13:47:39,867][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 29, global step 630: 'val_error' was not in top 1
[2024-03-11 13:47:50,925][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 30, global step 651: 'val_error' reached 0.13184 (best 0.13184), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=30-step=651.ckpt' as top 1
[2024-03-11 13:48:01,843][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 31, global step 672: 'val_error' was not in top 1
[2024-03-11 13:48:12,932][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 32, global step 693: 'val_error' reached 0.12817 (best 0.12817), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=32-step=693.ckpt' as top 1
[2024-03-11 13:48:23,885][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 33, global step 714: 'val_error' reached 0.11450 (best 0.11450), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=33-step=714.ckpt' as top 1
[2024-03-11 13:48:34,963][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 34, global step 735: 'val_error' was not in top 1
[2024-03-11 13:48:45,880][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 35, global step 756: 'val_error' was not in top 1
[2024-03-11 13:48:56,916][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 36, global step 777: 'val_error' reached 0.11230 (best 0.11230), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=36-step=777.ckpt' as top 1
[2024-03-11 13:49:08,036][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 37, global step 798: 'val_error' reached 0.11133 (best 0.11133), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=37-step=798.ckpt' as top 1
[2024-03-11 13:49:18,955][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 38, global step 819: 'val_error' was not in top 1
[2024-03-11 13:49:29,982][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 39, global step 840: 'val_error' reached 0.10425 (best 0.10425), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=39-step=840.ckpt' as top 1
[2024-03-11 13:49:40,830][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 40, global step 861: 'val_error' reached 0.09937 (best 0.09937), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=40-step=861.ckpt' as top 1
[2024-03-11 13:49:51,868][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 41, global step 882: 'val_error' was not in top 1
[2024-03-11 13:50:02,734][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 42, global step 903: 'val_error' reached 0.09009 (best 0.09009), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=42-step=903.ckpt' as top 1
[2024-03-11 13:50:13,769][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 43, global step 924: 'val_error' reached 0.08643 (best 0.08643), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=43-step=924.ckpt' as top 1
[2024-03-11 13:50:24,621][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 44, global step 945: 'val_error' reached 0.08398 (best 0.08398), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=44-step=945.ckpt' as top 1
[2024-03-11 13:50:35,677][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 45, global step 966: 'val_error' reached 0.08154 (best 0.08154), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=45-step=966.ckpt' as top 1
[2024-03-11 13:50:46,716][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 46, global step 987: 'val_error' reached 0.08057 (best 0.08057), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=46-step=987.ckpt' as top 1
[2024-03-11 13:50:57,574][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 47, global step 1008: 'val_error' reached 0.07886 (best 0.07886), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=47-step=1008.ckpt' as top 1
[2024-03-11 13:51:08,658][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 48, global step 1029: 'val_error' was not in top 1
[2024-03-11 13:51:19,503][pytorch_lightning.utilities.rank_zero][INFO] - Epoch 49, global step 1050: 'val_error' reached 0.07861 (best 0.07861), saving model to '/local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=49-step=1050.ckpt' as top 1
[2024-03-11 13:51:19,535][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer.fit` stopped: `max_epochs=50` reached.
[2024-03-11 13:51:19,557][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-03-11 13:51:19,558][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.validate(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.validate(ckpt_path='best')` to use the best model or `.validate(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-03-11 13:51:19,560][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=49-step=1050.ckpt
[2024-03-11 13:51:19,574][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-03-11 13:51:19,753][pytorch_lightning.utilities.rank_zero][INFO] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=49-step=1050.ckpt
[2024-03-11 13:51:19,967][lightning.fabric.utilities.seed][INFO] - Seed set to 1234
[2024-03-11 13:51:19,967][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.

[2024-03-11 13:51:19,969][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=49-step=1050.ckpt
[2024-03-11 13:51:19,983][pytorch_lightning.accelerators.cuda][INFO] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
[2024-03-11 13:51:20,163][pytorch_lightning.utilities.rank_zero][INFO] - Loaded model weights from the checkpoint at /local/gerum/hannah/experiments/cifar10/trained_models/sweep_models/kakao_resnet8/checkpoints/epoch=49-step=1050.ckpt
[2024-03-11 13:51:20,164][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=191` in the `DataLoader` to improve performance.

[2024-03-11 13:51:20,753][hannah.callbacks.summaries][INFO] - 
+----+--------------+-------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
|    | Name         | Type              | Attrs                                            | IFM              |   IFM volume | OFM              |   OFM volume |   Weights volume |     MACs |
|----+--------------+-------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------|
|  0 | 0.0          | Conv2d            | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |             1728 |  1769472 |
|  1 | 0.1          | BatchNorm2d       |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  2 | 0.2          | ReLU              |                                                  | (1, 64, 32, 32)  |        65536 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  3 | 0            | Sequential        |                                                  | (1, 3, 32, 32)   |         3072 | (1, 64, 32, 32)  |        65536 |                0 |        0 |
|  4 | 1.0          | Conv2d            | k=(5, 5), s=(2, 2), g=(1), dsc=(False), d=(1, 1) | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |           204800 | 52428800 |
|  5 | 1.1          | BatchNorm2d       |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
|  6 | 1.2          | ReLU              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
|  7 | 1            | Sequential        |                                                  | (1, 64, 32, 32)  |        65536 | (1, 128, 16, 16) |        32768 |                0 |        0 |
|  8 | 2.module.0.0 | Conv2d            | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
|  9 | 2.module.0.1 | BatchNorm2d       |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 10 | 2.module.0.2 | ReLU              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 11 | 2.module.0   | Sequential        |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 12 | 2.module.1.0 | Conv2d            | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |           147456 | 37748736 |
| 13 | 2.module.1.1 | BatchNorm2d       |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 14 | 2.module.1.2 | ReLU              |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 15 | 2.module.1   | Sequential        |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 16 | 2.module     | Sequential        |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 17 | 2            | Residual          |                                                  | (1, 128, 16, 16) |        32768 | (1, 128, 16, 16) |        32768 |                0 |        0 |
| 18 | 3.0          | Conv2d            | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 128, 16, 16) |        32768 | (1, 256, 16, 16) |        65536 |           294912 | 75497472 |
| 19 | 3.1          | BatchNorm2d       |                                                  | (1, 256, 16, 16) |        65536 | (1, 256, 16, 16) |        65536 |                0 |        0 |
| 20 | 3.2          | ReLU              |                                                  | (1, 256, 16, 16) |        65536 | (1, 256, 16, 16) |        65536 |                0 |        0 |
| 21 | 3            | Sequential        |                                                  | (1, 128, 16, 16) |        32768 | (1, 256, 16, 16) |        65536 |                0 |        0 |
| 22 | 4            | MaxPool2d         |                                                  | (1, 256, 16, 16) |        65536 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 23 | 5.module.0.0 | Conv2d            | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 24 | 5.module.0.1 | BatchNorm2d       |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 25 | 5.module.0.2 | ReLU              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 26 | 5.module.0   | Sequential        |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 27 | 5.module.1.0 | Conv2d            | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |           589824 | 37748736 |
| 28 | 5.module.1.1 | BatchNorm2d       |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 29 | 5.module.1.2 | ReLU              |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 30 | 5.module.1   | Sequential        |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 31 | 5.module     | Sequential        |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 32 | 5            | Residual          |                                                  | (1, 256, 8, 8)   |        16384 | (1, 256, 8, 8)   |        16384 |                0 |        0 |
| 33 | 6.0          | Conv2d            | k=(3, 3), s=(1, 1), g=(1), dsc=(False), d=(1, 1) | (1, 256, 8, 8)   |        16384 | (1, 128, 6, 6)   |         4608 |           294912 | 10616832 |
| 34 | 6.1          | BatchNorm2d       |                                                  | (1, 128, 6, 6)   |         4608 | (1, 128, 6, 6)   |         4608 |                0 |        0 |
| 35 | 6.2          | ReLU              |                                                  | (1, 128, 6, 6)   |         4608 | (1, 128, 6, 6)   |         4608 |                0 |        0 |
| 36 | 6            | Sequential        |                                                  | (1, 256, 8, 8)   |        16384 | (1, 128, 6, 6)   |         4608 |                0 |        0 |
| 37 | 7            | AdaptiveMaxPool2d |                                                  | (1, 128, 6, 6)   |         4608 | (1, 128, 1, 1)   |          128 |                0 |        0 |
| 38 | 8            | Flatten           |                                                  | (1, 128, 1, 1)   |          128 | (1, 128)         |          128 |                0 |        0 |
| 39 | 9            | Linear            |                                                  | (1, 128)         |          128 | (1, 10)          |           10 |             1280 |     1280 |
| 40 | 10           | Mul               |                                                  | (1, 10)          |           10 | (1, 10)          |           10 |                0 |        0 |
+----+--------------+-------------------+--------------------------------------------------+------------------+--------------+------------------+--------------+------------------+----------+
[2024-03-11 13:51:20,753][hannah.callbacks.summaries][INFO] - Total MACs: 291,308,800
[2024-03-11 13:51:20,753][hannah.callbacks.summaries][INFO] - Total Weights: 2,272,192
[2024-03-11 13:51:20,753][hannah.callbacks.summaries][INFO] - Total Activations: 1,185,044
[2024-03-11 13:51:20,753][hannah.callbacks.summaries][INFO] - Estimated Activations: 131,072
[2024-03-11 13:51:20,754][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-03-11 13:51:20,754][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-03-11 13:51:20,985][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: The ``compute`` method of metric MulticlassROC was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.
  warnings.warn(*args, **kwargs)  # noqa: B028

[2024-03-11 13:51:20,986][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-03-11 13:51:21,079][py.warnings][WARNING] - /local/gerum/.cache/pypoetry/virtualenvs/hannah-8Yp6PnCx-py3.11/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: The ``compute`` method of metric MulticlassPrecisionRecallCurve was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.
  warnings.warn(*args, **kwargs)  # noqa: B028

[2024-03-11 13:51:21,080][hannah.datasets.base][WARNING] - Datasets class names contain classes that are longer than the recommended lenght of 5 characters, consider implementing class_names_abbreviated in your dataset
[2024-03-11 13:51:21,199][hannah.train][INFO] - Averaged Result Metrics:
| Metric               |      Mean |   Std |   Count |
|----------------------|-----------|-------|---------|
| test_classifier_loss | 0.224195  |     0 |       1 |
| test_accuracy        | 0.922852  |     0 |       1 |
| test_error           | 0.0771484 |     0 |       1 |
| test_f1              | 0.923068  |     0 |       1 |
| test_precision       | 0.923175  |     0 |       1 |
| test_recall          | 0.92305   |     0 |       1 |
| test_loss            | 0.224195  |     0 |       1 |
[2024-03-11 13:51:21,210][hannah.train][INFO] - Averaged Result Metrics:
| Metric              |      Mean |   Std |   Count |
|---------------------|-----------|-------|---------|
| val_classifier_loss | 0.240081  |     0 |       1 |
| val_accuracy        | 0.921387  |     0 |       1 |
| val_error           | 0.0786133 |     0 |       1 |
| val_f1              | 0.920942  |     0 |       1 |
| val_precision       | 0.921227  |     0 |       1 |
| val_recall          | 0.920908  |     0 |       1 |
| val_loss            | 0.240081  |     0 |       1 |
